{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author Quote Model Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate\n",
    "from sklearn.feature_selection import SelectFpr, SelectKBest\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from sklearn import decomposition\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from gensim import corpora, models\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for accessing datasets, running gridsearch pipelines and reviewing model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path= ../datasets\n",
      "Available datasets: dict_keys(['authors', 'bible', 'bible_target', 'mark_twain', 'quotes', 'script_org_sw_proverbs', 'scripture', 'scripture_original_sw', 'twain_target'])\n"
     ]
    }
   ],
   "source": [
    "def create_datasets_from_csv_files(directory_):\n",
    "    path = directory_\n",
    "    print('path=', path)\n",
    "    allFiles = glob.glob(path + '/*.csv')\n",
    "    file_dict = {}\n",
    "    for file_ in allFiles:\n",
    "        filename = file_.split('/')[2].split('.')[0]\n",
    "        df = pd.read_csv(file_,index_col=None, header=0)\n",
    "        file_dict[filename] = df\n",
    "    return file_dict\n",
    "\n",
    "dataset_dict = create_datasets_from_csv_files('../datasets')\n",
    "print(\"Available datasets:\", dataset_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_gridsearch_pipeline(stages, params, X_train, X_test, y_train, y_test):\n",
    "    pipeline = Pipeline(stages)\n",
    "    estimator = GridSearchCV(pipeline, params)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best params = \", estimator.best_params_)\n",
    "    print(\"Best score = \", estimator.best_score_)\n",
    "    preds = estimator.predict(X_test)\n",
    "    print('Accuracy score = ', accuracy_score(y_test, preds))\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_pipeline_results(estimator_, model, dataset_name, text_description, X_test, y_test, df):\n",
    "    results = estimator_.best_params_\n",
    "    results['model'] = model\n",
    "    results['dataset'] = dataset_name\n",
    "    results['ml_steps'] = list(estimator_.best_estimator_.named_steps)\n",
    "    results['text_description'] = text_description\n",
    "    results['best_score'] = estimator_.best_score_\n",
    "    results['estimator_score']  = estimator_.score(X_test, y_test)\n",
    "    df = df.append(results, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_topic(quotes, num_topics_=5, passes_ = 5, min_proba=.5):\n",
    "    dictionary = corpora.Dictionary(quotes)\n",
    "    \n",
    "    corpus = [dictionary.doc2bow(q) for q in quotes]\n",
    "    \n",
    "    ldamodel = models.ldamodel.LdaModel(corpus, \n",
    "                                        id2word = dictionary, \n",
    "                                        num_topics = num_topics_, \n",
    "                                        passes = passes_, \n",
    "                                        minimum_probability=min_proba)  \n",
    "    return ldamodel, corpus, dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_top_models(df_model_data, dataset, model=None, limit=3):\n",
    "    if df_model_data.empty:\n",
    "        print(\"Modeling dataframe is empty. Trying run some gridsearches...\")\n",
    "        return\n",
    "    else: \n",
    "        group_by_ = [\"model\", \"dataset\", \"estimator_score\", \"text_description\", \"ml_steps\"]\n",
    "        dataset_filter = df_model_data[\"dataset\"].str.lower() == dataset.lower()\n",
    "        \n",
    "        if model is None:\n",
    "            filter_ = dataset_filter\n",
    "        else:\n",
    "            filter_ = (dataset_filter) & (df_model_data[\"model\"].str.lower() == model.lower())\n",
    "            \n",
    "        df_scores = pd.DataFrame(df_model_data[filter_].groupby(group_by_).size()).reset_index()\n",
    "   \n",
    "        return df_scores.sort_values('estimator_score', ascending=False).head(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path= ../gridsearch_results/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>estimator_score</th>\n",
       "      <th>logit__multi_class</th>\n",
       "      <th>logit__solver</th>\n",
       "      <th>ml_steps</th>\n",
       "      <th>model</th>\n",
       "      <th>text_description</th>\n",
       "      <th>vec__lowercase</th>\n",
       "      <th>vec__max_df</th>\n",
       "      <th>...</th>\n",
       "      <th>pca__n_components</th>\n",
       "      <th>pca__svd_solver</th>\n",
       "      <th>mnclf__alpha</th>\n",
       "      <th>mnclf__fit_prior</th>\n",
       "      <th>vec__min_df</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>skbest__k</th>\n",
       "      <th>rfclf__criterion</th>\n",
       "      <th>rfclf__max_features</th>\n",
       "      <th>rfclf__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.886306</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.9</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>['vec', 'logit']</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   best_score    dataset  estimator_score logit__multi_class logit__solver  \\\n",
       "0    0.886306  scripture              0.9        multinomial     newton-cg   \n",
       "\n",
       "           ml_steps               model text_description  vec__lowercase  \\\n",
       "0  ['vec', 'logit']  LogisticRegression     no_stopwords             0.0   \n",
       "\n",
       "   vec__max_df         ...           pca__n_components pca__svd_solver  \\\n",
       "0          0.5         ...                         NaN             NaN   \n",
       "\n",
       "   mnclf__alpha  mnclf__fit_prior  vec__min_df cvec__min_df  skbest__k  \\\n",
       "0           NaN               NaN          NaN          NaN        NaN   \n",
       "\n",
       "  rfclf__criterion  rfclf__max_features  rfclf__n_estimators  \n",
       "0              NaN                  NaN                  NaN  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_dir = \"../gridsearch_results/\"\n",
    "if not os.path.exists(gridsearch_dir ):\n",
    "    os.makedirs(gridsearch_dir )\n",
    "    print(gridsearch_dir , ' created!')\n",
    "    df_gs_results = pd.DataFrame()\n",
    "else:\n",
    "    df_gs_results = (create_datasets_from_csv_files(gridsearch_dir))[\"gs_results\"]\n",
    "    \n",
    "df_gs_results.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>estimator_score</th>\n",
       "      <th>text_description</th>\n",
       "      <th>ml_steps</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>['vec', 'mnclf']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>['cvec', 'logit']</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.918182</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>['cvec', 'todense', 'pca', 'logit']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model    dataset  estimator_score text_description  \\\n",
       "11       MultinomialNB  scripture         0.945455     no_stopwords   \n",
       "10  LogisticRegression  scripture         0.931818       lemmatized   \n",
       "9   LogisticRegression  scripture         0.918182       lemmatized   \n",
       "\n",
       "                               ml_steps  0  \n",
       "11                     ['vec', 'mnclf']  3  \n",
       "10                    ['cvec', 'logit']  3  \n",
       "9   ['cvec', 'todense', 'pca', 'logit']  1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top models for scriptures\n",
    "\n",
    "df_top_smodels = find_top_models(df_gs_results, \"scripture\")\n",
    "\n",
    "# Top scores for specific model (i.e \"MultinomialNB\", LogisticRegression\", \"RandomForestClassifier\")\n",
    "#df_top_smodels = find_top_models(df_gs_results, \"scripture\", \"RandomForestClassifier\", 3)\n",
    "\n",
    "df_top_smodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>estimator_score</th>\n",
       "      <th>text_description</th>\n",
       "      <th>ml_steps</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.604331</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>['cvec', 'mnclf']</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.602362</td>\n",
       "      <td>stemmed</td>\n",
       "      <td>['cvec', 'mnclf']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.600394</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>['cvec', 'mnclf']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>['vec', 'mnclf']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.594488</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>['vec', 'mnclf']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  dataset  estimator_score text_description  \\\n",
       "10  MultinomialNB  authors         0.604331     no_stopwords   \n",
       "9   MultinomialNB  authors         0.602362          stemmed   \n",
       "8   MultinomialNB  authors         0.600394       lemmatized   \n",
       "7   MultinomialNB  authors         0.598425     no_stopwords   \n",
       "6   MultinomialNB  authors         0.594488       lemmatized   \n",
       "\n",
       "             ml_steps  0  \n",
       "10  ['cvec', 'mnclf']  2  \n",
       "9   ['cvec', 'mnclf']  1  \n",
       "8   ['cvec', 'mnclf']  1  \n",
       "7    ['vec', 'mnclf']  1  \n",
       "6    ['vec', 'mnclf']  1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top models for authors\n",
    "df_top_amodels = find_top_models(df_gs_results, \"authors\", None, 5)\n",
    "\n",
    "# Top scores for specific model (i.e \"MultinomialNB\", LogisticRegression\", \"RandomForestClassifier\")\n",
    "#df_top_amodels = find_top_models(df_gs_results, \"authors\", \"LogisticRegression\", 3)\n",
    "\n",
    "df_top_amodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Random Seed for Model consitency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure we get reproducible results\n",
    "# needed because models are generated from random selection of words\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Scripture Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2199, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>quote</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>And Adam was not deceived, but the woman being...</td>\n",
       "      <td>Adam deceived woman deceived transgression</td>\n",
       "      <td>Adam deceive woman deceive transgression</td>\n",
       "      <td>adam deceiv woman deceiv transgress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>All these trust to their hands: and every one ...</td>\n",
       "      <td>trust hands every one wise work</td>\n",
       "      <td>trust hand every one wise work</td>\n",
       "      <td>trust hand everi one wise work</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author                                              quote  \\\n",
       "0  Bible Bible  And Adam was not deceived, but the woman being...   \n",
       "1  Bible Bible  All these trust to their hands: and every one ...   \n",
       "\n",
       "                                 no_stopwords  \\\n",
       "0  Adam deceived woman deceived transgression   \n",
       "1             trust hands every one wise work   \n",
       "\n",
       "                                 lemmatized  \\\n",
       "0  Adam deceive woman deceive transgression   \n",
       "1            trust hand every one wise work   \n",
       "\n",
       "                               stemmed  \n",
       "0  adam deceiv woman deceiv transgress  \n",
       "1       trust hand everi one wise work  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_script = dataset_dict['scripture']\n",
    "#dataset_dict['scripture_original_sw']\n",
    "#dataset_dict['scripture']\n",
    "print(df_script.shape)\n",
    "df_script.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verify Author labels: [0 2 1]\n"
     ]
    }
   ],
   "source": [
    "df_smodel = df_script.copy()\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "lbl.fit(list(df_smodel['author'].values)) \n",
    "df_smodel['auth_label'] = lbl.transform(df_smodel['author'].values)\n",
    "print(\"Verify Author labels:\", df_smodel['auth_label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author        auth_label\n",
       "Bible Bible   0             1139\n",
       "Granth Sahib  1              574\n",
       "quran quran   2              486\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smodel.groupby(['author', 'auth_label']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline = 0.517962710323\n"
     ]
    }
   ],
   "source": [
    "baseline = df_smodel['author'].value_counts().values[0]/df_smodel.shape[0]\n",
    "print('Baseline =', baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params =  {'mnclf__alpha': 0.2, 'mnclf__fit_prior': False, 'vec__lowercase': False, 'vec__max_df': 0.5, 'vec__max_features': None, 'vec__ngram_range': (1, 2)}\n",
      "Best score =  0.931278423446\n",
      "Accuracy score =  0.945454545455\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>estimator_score</th>\n",
       "      <th>logit__multi_class</th>\n",
       "      <th>logit__solver</th>\n",
       "      <th>ml_steps</th>\n",
       "      <th>model</th>\n",
       "      <th>text_description</th>\n",
       "      <th>vec__lowercase</th>\n",
       "      <th>vec__max_df</th>\n",
       "      <th>...</th>\n",
       "      <th>pca__n_components</th>\n",
       "      <th>pca__svd_solver</th>\n",
       "      <th>mnclf__alpha</th>\n",
       "      <th>mnclf__fit_prior</th>\n",
       "      <th>vec__min_df</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>skbest__k</th>\n",
       "      <th>rfclf__criterion</th>\n",
       "      <th>rfclf__max_features</th>\n",
       "      <th>rfclf__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.931278</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['vec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.507440</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.604331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.931278</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[vec, mnclf]</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    best_score    dataset  estimator_score logit__multi_class logit__solver  \\\n",
       "50    0.931278  scripture         0.945455                NaN           NaN   \n",
       "51    0.507440    authors         0.604331                NaN           NaN   \n",
       "52    0.931278  scripture         0.945455                NaN           NaN   \n",
       "\n",
       "             ml_steps          model text_description  vec__lowercase  \\\n",
       "50   ['vec', 'mnclf']  MultinomialNB     no_stopwords             0.0   \n",
       "51  ['cvec', 'mnclf']  MultinomialNB     no_stopwords             NaN   \n",
       "52       [vec, mnclf]  MultinomialNB     no_stopwords             0.0   \n",
       "\n",
       "    vec__max_df         ...          pca__n_components pca__svd_solver  \\\n",
       "50          0.5         ...                        NaN             NaN   \n",
       "51          NaN         ...                        NaN             NaN   \n",
       "52          0.5         ...                        NaN             NaN   \n",
       "\n",
       "    mnclf__alpha  mnclf__fit_prior  vec__min_df cvec__min_df  skbest__k  \\\n",
       "50           0.2               0.0          NaN          NaN        NaN   \n",
       "51           0.2               1.0          NaN          1.0        NaN   \n",
       "52           0.2               0.0          NaN          NaN        NaN   \n",
       "\n",
       "   rfclf__criterion  rfclf__max_features  rfclf__n_estimators  \n",
       "50              NaN                  NaN                  NaN  \n",
       "51              NaN                  NaN                  NaN  \n",
       "52              NaN                  NaN                  NaN  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages_ = [('vec', TfidfVectorizer()), ('mnclf', MultinomialNB())] #TfidfVectorizer()\n",
    "    \n",
    "params_ = dict(\n",
    "    vec__max_features=[None, 1000, 2000], \n",
    "    vec__lowercase=[True, False],\n",
    "    vec__max_df=[0.5, 1.0],\n",
    "    #vec__min_df=[0.01, 0.02, 1],\n",
    "    vec__ngram_range=[(1,1),(1,2)],\n",
    "    mnclf__fit_prior=[True, False],\n",
    "    mnclf__alpha=[.05, 0.1, 0.2]\n",
    ")\n",
    "\n",
    "data_desc = 'no_stopwords'\n",
    "X = df_smodel[data_desc] # lemmatized # 'stemmed','no_stopwords'\n",
    "y = df_smodel['auth_label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "estimator = run_gridsearch_pipeline(stages_, params_, X_train, X_test, y_train, y_test )\n",
    "\n",
    "# store results and params so we have history\n",
    "df_gs_results = store_pipeline_results(estimator,'MultinomialNB', \n",
    "                                                 'scripture', data_desc, \n",
    "                                                 X_test, y_test, df_gs_results)\n",
    "\n",
    "df_gs_results.to_csv(gridsearch_dir + 'gs_results.csv', encoding='utf-8', index=False)\n",
    "df_gs_results.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review Prediction Probabilites for a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_bible</th>\n",
       "      <th>prob_granth</th>\n",
       "      <th>prob_quran</th>\n",
       "      <th>quote</th>\n",
       "      <th>author_label</th>\n",
       "      <th>author_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.962159</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>0.031827</td>\n",
       "      <td>Joseph saw Benjamin said ruler house Bring men...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.533405</td>\n",
       "      <td>0.174383</td>\n",
       "      <td>0.292212</td>\n",
       "      <td>Set affection things things earth Colossians 3 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.877100</td>\n",
       "      <td>0.038330</td>\n",
       "      <td>0.084569</td>\n",
       "      <td>riches might dwell together land wherein stran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.224860</td>\n",
       "      <td>0.571934</td>\n",
       "      <td>0.203206</td>\n",
       "      <td>pleases play music sing pleases bathe water</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.964565</td>\n",
       "      <td>0.012723</td>\n",
       "      <td>0.022713</td>\n",
       "      <td>shall return land Egypt Assyrian shall king re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prob_bible  prob_granth  prob_quran  \\\n",
       "0    0.962159     0.006014    0.031827   \n",
       "1    0.533405     0.174383    0.292212   \n",
       "2    0.877100     0.038330    0.084569   \n",
       "3    0.224860     0.571934    0.203206   \n",
       "4    0.964565     0.012723    0.022713   \n",
       "\n",
       "                                               quote  author_label  \\\n",
       "0  Joseph saw Benjamin said ruler house Bring men...             0   \n",
       "1   Set affection things things earth Colossians 3 2             0   \n",
       "2  riches might dwell together land wherein stran...             0   \n",
       "3        pleases play music sing pleases bathe water             1   \n",
       "4  shall return land Egypt Assyrian shall king re...             0   \n",
       "\n",
       "   author_prediction  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  0  "
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba_ = estimator.predict_proba(X_test)\n",
    "y_preds = estimator.predict(X_test)\n",
    "proba_df = pd.DataFrame(predict_proba_, columns = ['prob_bible','prob_granth','prob_quran']).reset_index(drop=True)\n",
    "quote_df = pd.DataFrame(list(X_test), columns=['quote']).reset_index(drop=True)\n",
    "pred_df = pd.DataFrame(list(y_preds), columns=['author_prediction']).reset_index(drop=True)\n",
    "author_df = pd.DataFrame(list(y_test), columns=['author_label']).reset_index(drop=True)\n",
    "#y_test.to_frame().reset_index(drop=True)\n",
    "df_predictions = pd.concat([proba_df, quote_df, author_df, pred_df ], axis = 1)\n",
    "df_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    124\n",
       "1     54\n",
       "2     42\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(y_test, columns=['y'])\n",
    "test.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     54\n",
       "2     36\n",
       "Name: y_preds, dtype: int64"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = pd.DataFrame(y_preds, columns=['y_preds'])\n",
    "test2.y_preds.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted     Bible  Granth Sahib  Quran  __all__\n",
      "Actual                                           \n",
      "Bible           121             2      1      124\n",
      "Granth Sahib      2            52      0       54\n",
      "Quran             7             0     35       42\n",
      "__all__         130            54     36      220\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAH+CAYAAABz8G+7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a626a0358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Bible', 'Granth Sahib', 'Quran']\n",
    "cm = ConfusionMatrix(y_test, y_preds, labels)\n",
    "print(cm)\n",
    "\n",
    "cm.plot()\n",
    "\n",
    "plt.title('Scripture Confusion Matrix')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review quotes for incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_bible</th>\n",
       "      <th>prob_granth</th>\n",
       "      <th>prob_quran</th>\n",
       "      <th>quote</th>\n",
       "      <th>author_label</th>\n",
       "      <th>author_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.409812</td>\n",
       "      <td>0.221262</td>\n",
       "      <td>0.368925</td>\n",
       "      <td>came evil generation neglected prayers followe...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.582111</td>\n",
       "      <td>0.288366</td>\n",
       "      <td>0.129524</td>\n",
       "      <td>relish delight continually bite bait trapped f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.076119</td>\n",
       "      <td>0.719795</td>\n",
       "      <td>0.204086</td>\n",
       "      <td>pride comes comes disgrace humility comes wisdom</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.850386</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>0.042375</td>\n",
       "      <td>wife yearns gold silver friends senses yearn g...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.154223</td>\n",
       "      <td>0.597512</td>\n",
       "      <td>0.248265</td>\n",
       "      <td>wait wind weather right never plant anything n...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.721843</td>\n",
       "      <td>0.135790</td>\n",
       "      <td>0.142367</td>\n",
       "      <td>bowl shall made go round water running springs...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.724102</td>\n",
       "      <td>0.135226</td>\n",
       "      <td>0.140672</td>\n",
       "      <td>Prayer carries us half way God fasting brings ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.470003</td>\n",
       "      <td>0.104623</td>\n",
       "      <td>0.425375</td>\n",
       "      <td>sold small price pieces silver showed desire</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.665707</td>\n",
       "      <td>0.095211</td>\n",
       "      <td>0.239082</td>\n",
       "      <td>shall see shall see afflicted madness</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.370079</td>\n",
       "      <td>0.179388</td>\n",
       "      <td>0.450533</td>\n",
       "      <td>wounded transgressions bruised iniquities chas...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.407289</td>\n",
       "      <td>0.274283</td>\n",
       "      <td>0.318428</td>\n",
       "      <td>shall food thorns neither fatten avail hunger</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.554082</td>\n",
       "      <td>0.149667</td>\n",
       "      <td>0.296251</td>\n",
       "      <td>made horses mules asses might ride upon orname...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     prob_bible  prob_granth  prob_quran  \\\n",
       "11     0.409812     0.221262    0.368925   \n",
       "46     0.582111     0.288366    0.129524   \n",
       "64     0.076119     0.719795    0.204086   \n",
       "66     0.850386     0.107239    0.042375   \n",
       "67     0.154223     0.597512    0.248265   \n",
       "72     0.721843     0.135790    0.142367   \n",
       "76     0.724102     0.135226    0.140672   \n",
       "96     0.470003     0.104623    0.425375   \n",
       "134    0.665707     0.095211    0.239082   \n",
       "158    0.370079     0.179388    0.450533   \n",
       "170    0.407289     0.274283    0.318428   \n",
       "182    0.554082     0.149667    0.296251   \n",
       "\n",
       "                                                 quote  author_label  \\\n",
       "11   came evil generation neglected prayers followe...             2   \n",
       "46   relish delight continually bite bait trapped f...             1   \n",
       "64    pride comes comes disgrace humility comes wisdom             0   \n",
       "66   wife yearns gold silver friends senses yearn g...             1   \n",
       "67   wait wind weather right never plant anything n...             0   \n",
       "72   bowl shall made go round water running springs...             2   \n",
       "76   Prayer carries us half way God fasting brings ...             2   \n",
       "96        sold small price pieces silver showed desire             2   \n",
       "134              shall see shall see afflicted madness             2   \n",
       "158  wounded transgressions bruised iniquities chas...             0   \n",
       "170      shall food thorns neither fatten avail hunger             2   \n",
       "182  made horses mules asses might ride upon orname...             2   \n",
       "\n",
       "     author_prediction  \n",
       "11                   0  \n",
       "46                   0  \n",
       "64                   1  \n",
       "66                   0  \n",
       "67                   1  \n",
       "72                   0  \n",
       "76                   0  \n",
       "96                   0  \n",
       "134                  0  \n",
       "158                  2  \n",
       "170                  0  \n",
       "182                  0  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions[df_predictions['author_label'] != df_predictions['author_prediction']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model against flash dataset of about 12 Bible quotes?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did it perform?  It baselined getting only 6 predictions correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_bible</th>\n",
       "      <th>prob_granth</th>\n",
       "      <th>prob_quran</th>\n",
       "      <th>author</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>author_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.387435</td>\n",
       "      <td>0.480418</td>\n",
       "      <td>0.132148</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>clothed strength dignity laughs without fear f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.250971</td>\n",
       "      <td>0.696775</td>\n",
       "      <td>0.052254</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>pain feeling compare joy coming</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.181718</td>\n",
       "      <td>0.572585</td>\n",
       "      <td>0.245697</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>bold brave courageous</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.485137</td>\n",
       "      <td>0.194057</td>\n",
       "      <td>0.320806</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>time everything reason every activity heavens</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.701112</td>\n",
       "      <td>0.100078</td>\n",
       "      <td>0.198810</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>afraid discouraged God strengthen help hold vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.722045</td>\n",
       "      <td>0.117413</td>\n",
       "      <td>0.160542</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>cover feathers wings find refuge faithfulness ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.566583</td>\n",
       "      <td>0.382475</td>\n",
       "      <td>0.050942</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>soul finds rest God alone salvation comes alon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.480930</td>\n",
       "      <td>0.158286</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>everything Christ gives strength</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.216498</td>\n",
       "      <td>0.518311</td>\n",
       "      <td>0.265191</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>cause pain without allowing something new born...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.670061</td>\n",
       "      <td>0.230680</td>\n",
       "      <td>0.099259</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>go deep waters</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.425112</td>\n",
       "      <td>0.220769</td>\n",
       "      <td>0.354119</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>Commit way Lord Trust act</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.166151</td>\n",
       "      <td>0.145387</td>\n",
       "      <td>0.688462</td>\n",
       "      <td>Bible Bible</td>\n",
       "      <td>know plans plans prosper harm plans give hope ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prob_bible  prob_granth  prob_quran       author  \\\n",
       "0     0.387435     0.480418    0.132148  Bible Bible   \n",
       "1     0.250971     0.696775    0.052254  Bible Bible   \n",
       "2     0.181718     0.572585    0.245697  Bible Bible   \n",
       "3     0.485137     0.194057    0.320806  Bible Bible   \n",
       "4     0.701112     0.100078    0.198810  Bible Bible   \n",
       "5     0.722045     0.117413    0.160542  Bible Bible   \n",
       "6     0.566583     0.382475    0.050942  Bible Bible   \n",
       "7     0.360784     0.480930    0.158286  Bible Bible   \n",
       "8     0.216498     0.518311    0.265191  Bible Bible   \n",
       "9     0.670061     0.230680    0.099259  Bible Bible   \n",
       "10    0.425112     0.220769    0.354119  Bible Bible   \n",
       "11    0.166151     0.145387    0.688462  Bible Bible   \n",
       "\n",
       "                                         no_stopwords  author_prediction  \n",
       "0   clothed strength dignity laughs without fear f...                  1  \n",
       "1                     pain feeling compare joy coming                  1  \n",
       "2                               bold brave courageous                  1  \n",
       "3       time everything reason every activity heavens                  0  \n",
       "4   afraid discouraged God strengthen help hold vi...                  0  \n",
       "5   cover feathers wings find refuge faithfulness ...                  0  \n",
       "6   soul finds rest God alone salvation comes alon...                  0  \n",
       "7                    everything Christ gives strength                  1  \n",
       "8   cause pain without allowing something new born...                  1  \n",
       "9                                      go deep waters                  0  \n",
       "10                          Commit way Lord Trust act                  0  \n",
       "11  know plans plans prosper harm plans give hope ...                  2  "
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bible_test = dataset_dict['bible_target']\n",
    "desc = \"no_stopwords\" #\"lemmatized\" #\"no_stopwords\"\n",
    "X_test2 = df_bible_test[desc] # results differ a bit depending on no_stopwords, lemmatized, or stemmed\n",
    "\n",
    "y_preds2 = estimator.predict(X_test2)\n",
    "    \n",
    "predict_proba2_ = estimator.predict_proba(X_test2)\n",
    "proba2_df = pd.DataFrame(predict_proba2_, columns = ['prob_bible','prob_granth','prob_quran']).reset_index(drop=True)\n",
    "pred2_df = pd.DataFrame(list(y_preds2), columns=['author_prediction']).reset_index(drop=True)\n",
    "pd.concat([proba2_df, df_bible_test[[\"author\", desc]], pred2_df ], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params =  {'cvec__lowercase': False, 'cvec__max_df': 0.5, 'cvec__max_features': 2000, 'cvec__ngram_range': (1, 1), 'rfclf__criterion': 'gini', 'rfclf__max_features': 0.01, 'rfclf__n_estimators': 20}\n",
      "Best score =  0.872662961091\n",
      "Accuracy score =  0.85\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>estimator_score</th>\n",
       "      <th>logit__multi_class</th>\n",
       "      <th>logit__solver</th>\n",
       "      <th>ml_steps</th>\n",
       "      <th>model</th>\n",
       "      <th>text_description</th>\n",
       "      <th>vec__lowercase</th>\n",
       "      <th>vec__max_df</th>\n",
       "      <th>...</th>\n",
       "      <th>pca__n_components</th>\n",
       "      <th>pca__svd_solver</th>\n",
       "      <th>mnclf__alpha</th>\n",
       "      <th>mnclf__fit_prior</th>\n",
       "      <th>vec__min_df</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>skbest__k</th>\n",
       "      <th>rfclf__criterion</th>\n",
       "      <th>rfclf__max_features</th>\n",
       "      <th>rfclf__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.854977</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.868182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cvec, rfclf]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.853967</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.877273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cvec, rfclf]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.870642</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.859091</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cvec, rfclf]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.859020</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cvec, rfclf]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.872663</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cvec, rfclf]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.01</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    best_score    dataset  estimator_score logit__multi_class logit__solver  \\\n",
       "42    0.854977  scripture         0.868182                NaN           NaN   \n",
       "43    0.853967  scripture         0.877273                NaN           NaN   \n",
       "44    0.870642  scripture         0.859091                NaN           NaN   \n",
       "45    0.859020  scripture         0.872727                NaN           NaN   \n",
       "46    0.872663  scripture         0.850000                NaN           NaN   \n",
       "\n",
       "         ml_steps                   model text_description  vec__lowercase  \\\n",
       "42  [cvec, rfclf]  RandomForestClassifier       lemmatized             NaN   \n",
       "43  [cvec, rfclf]  RandomForestClassifier     no_stopwords             NaN   \n",
       "44  [cvec, rfclf]  RandomForestClassifier     no_stopwords             NaN   \n",
       "45  [cvec, rfclf]  RandomForestClassifier     no_stopwords             NaN   \n",
       "46  [cvec, rfclf]  RandomForestClassifier     no_stopwords             NaN   \n",
       "\n",
       "    vec__max_df         ...          pca__n_components pca__svd_solver  \\\n",
       "42          NaN         ...                        NaN             NaN   \n",
       "43          NaN         ...                        NaN             NaN   \n",
       "44          NaN         ...                        NaN             NaN   \n",
       "45          NaN         ...                        NaN             NaN   \n",
       "46          NaN         ...                        NaN             NaN   \n",
       "\n",
       "    mnclf__alpha  mnclf__fit_prior vec__min_df cvec__min_df  skbest__k  \\\n",
       "42           NaN               NaN         NaN          NaN        NaN   \n",
       "43           NaN               NaN         NaN          NaN        NaN   \n",
       "44           NaN               NaN         NaN          NaN        NaN   \n",
       "45           NaN               NaN         NaN          NaN        NaN   \n",
       "46           NaN               NaN         NaN          NaN        NaN   \n",
       "\n",
       "   rfclf__criterion  rfclf__max_features  rfclf__n_estimators  \n",
       "42             gini                  NaN                  NaN  \n",
       "43             gini                 0.01                 10.0  \n",
       "44              NaN                 0.01                 15.0  \n",
       "45          entropy                 0.01                 15.0  \n",
       "46             gini                 0.01                 20.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages_ = [('cvec', CountVectorizer()), ('rfclf', RandomForestClassifier())] #TfidfVectorizer()\n",
    "    \n",
    "params_ = dict(\n",
    "    cvec__max_features=[None, 1000, 2000, 5000], \n",
    "    cvec__lowercase=[True, False],\n",
    "    cvec__max_df=[0.5, 1.0],\n",
    "    #vec__min_df=[0.01, 0.02, 1],\n",
    "    cvec__ngram_range=[(1,1),(1,2)],\n",
    "    rfclf__criterion = ['gini', 'entropy'],\n",
    "    rfclf__max_features = [0.01, 0.25, 0.50],\n",
    "    rfclf__n_estimators = [10, 15, 20]\n",
    ")\n",
    "\n",
    "data_desc = \"no_stopwords\"\n",
    "X = df_smodel[data_desc] # lemmatized # 'stemmed','no_stopwords'\n",
    "y = df_smodel['auth_label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "estimator = run_gridsearch_pipeline(stages_, params_, X_train, X_test, y_train, y_test )\n",
    "\n",
    "# store results and params so we have history\n",
    "df_gs_results = store_pipeline_results(estimator,'RandomForestClassifier', \n",
    "                                                 'scripture', data_desc, \n",
    "                                                 X_test, y_test, df_gs_results)\n",
    "\n",
    "df_gs_results.to_csv(gridsearch_dir + 'gs_results.csv', encoding='utf-8', index=False)\n",
    "df_gs_results.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params =  {'cvec__lowercase': False, 'cvec__max_df': 0.5, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1), 'logit__multi_class': 'multinomial', 'logit__solver': 'newton-cg'}\n",
      "Best score =  0.897928246589\n",
      "Accuracy score =  0.931818181818\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>estimator_score</th>\n",
       "      <th>logit__multi_class</th>\n",
       "      <th>logit__solver</th>\n",
       "      <th>ml_steps</th>\n",
       "      <th>model</th>\n",
       "      <th>text_description</th>\n",
       "      <th>vec__lowercase</th>\n",
       "      <th>vec__max_df</th>\n",
       "      <th>...</th>\n",
       "      <th>cvec__lowercase</th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__ngram_range</th>\n",
       "      <th>pca__n_components</th>\n",
       "      <th>pca__svd_solver</th>\n",
       "      <th>mnclf__alpha</th>\n",
       "      <th>mnclf__fit_prior</th>\n",
       "      <th>vec__min_df</th>\n",
       "      <th>cvec__min_df</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.936837</td>\n",
       "      <td>scripture_org_sw_no_proverbs</td>\n",
       "      <td>0.936364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.935321</td>\n",
       "      <td>scripture_org_sw_no_proverbs</td>\n",
       "      <td>0.927273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['vec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.907024</td>\n",
       "      <td>scripture_org_sw_no_proverbs</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>[cvec, logit]</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2000</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.908034</td>\n",
       "      <td>scripture_org_sw_no_proverbs</td>\n",
       "      <td>0.918182</td>\n",
       "      <td>ovr</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>[cvec, logit]</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.897928</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>[cvec, logit]</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    best_score                       dataset  estimator_score  \\\n",
       "20    0.936837  scripture_org_sw_no_proverbs         0.936364   \n",
       "21    0.935321  scripture_org_sw_no_proverbs         0.927273   \n",
       "22    0.907024  scripture_org_sw_no_proverbs         0.909091   \n",
       "23    0.908034  scripture_org_sw_no_proverbs         0.918182   \n",
       "24    0.897928                     scripture         0.931818   \n",
       "\n",
       "   logit__multi_class logit__solver           ml_steps               model  \\\n",
       "20                NaN           NaN  ['cvec', 'mnclf']       MultinomialNB   \n",
       "21                NaN           NaN   ['vec', 'mnclf']       MultinomialNB   \n",
       "22        multinomial     newton-cg      [cvec, logit]  LogisticRegression   \n",
       "23                ovr     newton-cg      [cvec, logit]  LogisticRegression   \n",
       "24        multinomial     newton-cg      [cvec, logit]  LogisticRegression   \n",
       "\n",
       "   text_description  vec__lowercase  vec__max_df      ...       \\\n",
       "20       lemmatized             NaN          NaN      ...        \n",
       "21       lemmatized             0.0          0.5      ...        \n",
       "22       lemmatized             NaN          NaN      ...        \n",
       "23       lemmatized             NaN          NaN      ...        \n",
       "24       lemmatized             NaN          NaN      ...        \n",
       "\n",
       "    cvec__lowercase cvec__max_df  cvec__max_features  cvec__ngram_range  \\\n",
       "20              0.0          0.5                 NaN             (1, 1)   \n",
       "21              NaN          NaN                 NaN                NaN   \n",
       "22              0.0          0.7                2000             (1, 1)   \n",
       "23              0.0          0.5                None             (1, 1)   \n",
       "24              0.0          0.5                None             (1, 1)   \n",
       "\n",
       "   pca__n_components pca__svd_solver  mnclf__alpha mnclf__fit_prior  \\\n",
       "20               NaN             NaN           0.2              1.0   \n",
       "21               NaN             NaN           0.1              1.0   \n",
       "22               NaN             NaN           NaN              NaN   \n",
       "23               NaN             NaN           NaN              NaN   \n",
       "24               NaN             NaN           NaN              NaN   \n",
       "\n",
       "    vec__min_df  cvec__min_df  \n",
       "20          NaN           1.0  \n",
       "21          1.0           NaN  \n",
       "22          NaN           1.0  \n",
       "23          NaN           1.0  \n",
       "24          NaN           1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages2_ = [('cvec', CountVectorizer()), # include to remove sparse error\n",
    "            #('denseto', DenseTransformer()),\n",
    "            #('pca', decomposition.PCA()),\n",
    "            ('logit', LogisticRegression())] # CountVectorizer, TfidfVectorizer\n",
    "    \n",
    "params2_ = dict(\n",
    "    #pca__n_components=[700, 1000],\n",
    "    #pca__svd_solver=['auto', 'arpack'],\n",
    "    cvec__max_features=[None, 1000, 2000], \n",
    "    cvec__lowercase=[True, False],\n",
    "    cvec__max_df=[0.5, 0.7, 1.0],\n",
    "    cvec__min_df=[0.01, 0.02, 1],\n",
    "    cvec__ngram_range=[(1,1),(1,2)],\n",
    "    logit__multi_class= ['ovr', 'multinomial'],\n",
    "    logit__solver= ['newton-cg','lbfgs']\n",
    ")\n",
    "\n",
    "data_desc = 'lemmatized'\n",
    "X = df_smodel[data_desc] # lemmatized # 'stemmed','no_stopwords'\n",
    "y = df_smodel['auth_label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "estimator2 = run_gridsearch_pipeline(stages2_, params2_, X_train, X_test, y_train, y_test )\n",
    "\n",
    "# store results and params so we have history\n",
    "df_gs_results = store_pipeline_results(estimator2,'LogisticRegression', \n",
    "                                                 'scripture', data_desc, \n",
    "                                                 X_test, y_test, df_gs_results)\n",
    "\n",
    "df_gs_results.to_csv(gridsearch_dir + 'gs_results.csv', encoding='utf-8', index=False)\n",
    "df_gs_results.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Author Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5078, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>quote</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ambrose Gwinett Bierce</td>\n",
       "      <td>RECRUIT, n. A person distinguishable from a ci...</td>\n",
       "      <td>RECRUIT n person distinguishable civilian unif...</td>\n",
       "      <td>RECRUIT n person distinguishable civilian unif...</td>\n",
       "      <td>recruit n person distinguish civilian uniform ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambrose Gwinett Bierce</td>\n",
       "      <td>RANK, n. Relative elevation in the scale of hu...</td>\n",
       "      <td>RANK n Relative elevation scale human worth</td>\n",
       "      <td>RANK n Relative elevation scale human worth</td>\n",
       "      <td>rank n relat elev scale human worth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   author                                              quote  \\\n",
       "0  Ambrose Gwinett Bierce  RECRUIT, n. A person distinguishable from a ci...   \n",
       "1  Ambrose Gwinett Bierce  RANK, n. Relative elevation in the scale of hu...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  RECRUIT n person distinguishable civilian unif...   \n",
       "1        RANK n Relative elevation scale human worth   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  RECRUIT n person distinguishable civilian unif...   \n",
       "1        RANK n Relative elevation scale human worth   \n",
       "\n",
       "                                             stemmed  \n",
       "0  recruit n person distinguish civilian uniform ...  \n",
       "1                rank n relat elev scale human worth  "
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auths = dataset_dict['authors']\n",
    "print(df_auths.shape)\n",
    "df_auths.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verify Author labels: [1 0 7 8 2 9 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "df_amodel = df_auths.copy()\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "lbl.fit(list(df_amodel['author'].values)) \n",
    "df_amodel['auth_label'] = lbl.transform(df_amodel['author'].values)\n",
    "print(\"Verify Author labels:\", df_amodel['auth_label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                       auth_label\n",
       "Albert Einstein              0             485\n",
       "Ambrose Gwinett Bierce       1             398\n",
       "Friedrich Wilhelm Nietzsche  2             393\n",
       "George Bernard Shaw          3             402\n",
       "Henry David Thoreau          4             396\n",
       "Mark Twain                   5             679\n",
       "Oscar Wilde                  6             509\n",
       "Ralph Waldo Emerson          7             888\n",
       "Scott McClellan              8             354\n",
       "William Shakespeare          9             574\n",
       "dtype: int64"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amodel.groupby([\"author\", \"auth_label\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline = 0.174871996849\n"
     ]
    }
   ],
   "source": [
    "baseline = df_amodel['author'].value_counts().values[0]/df_amodel.shape[0]\n",
    "print('Baseline =', baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayes MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params =  {'cvec__lowercase': True, 'cvec__max_df': 0.5, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'mnclf__alpha': 0.2, 'mnclf__fit_prior': True}\n",
      "Best score =  0.507439824945\n",
      "Accuracy score =  0.604330708661\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>estimator_score</th>\n",
       "      <th>logit__multi_class</th>\n",
       "      <th>logit__solver</th>\n",
       "      <th>ml_steps</th>\n",
       "      <th>model</th>\n",
       "      <th>text_description</th>\n",
       "      <th>vec__lowercase</th>\n",
       "      <th>vec__max_df</th>\n",
       "      <th>...</th>\n",
       "      <th>pca__n_components</th>\n",
       "      <th>pca__svd_solver</th>\n",
       "      <th>mnclf__alpha</th>\n",
       "      <th>mnclf__fit_prior</th>\n",
       "      <th>vec__min_df</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>skbest__k</th>\n",
       "      <th>rfclf__criterion</th>\n",
       "      <th>rfclf__max_features</th>\n",
       "      <th>rfclf__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.431947</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.503937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['vec', 'rfclf']</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.931278</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['vec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.507440</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.604331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cvec, mnclf]</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    best_score    dataset  estimator_score logit__multi_class logit__solver  \\\n",
       "49    0.431947    authors         0.503937                NaN           NaN   \n",
       "50    0.931278  scripture         0.945455                NaN           NaN   \n",
       "51    0.507440    authors         0.604331                NaN           NaN   \n",
       "\n",
       "            ml_steps                   model text_description  vec__lowercase  \\\n",
       "49  ['vec', 'rfclf']  RandomForestClassifier     no_stopwords             1.0   \n",
       "50  ['vec', 'mnclf']           MultinomialNB     no_stopwords             0.0   \n",
       "51     [cvec, mnclf]           MultinomialNB     no_stopwords             NaN   \n",
       "\n",
       "    vec__max_df         ...           pca__n_components pca__svd_solver  \\\n",
       "49          0.5         ...                         NaN             NaN   \n",
       "50          0.5         ...                         NaN             NaN   \n",
       "51          NaN         ...                         NaN             NaN   \n",
       "\n",
       "    mnclf__alpha  mnclf__fit_prior vec__min_df cvec__min_df  skbest__k  \\\n",
       "49           NaN               NaN         NaN          NaN        NaN   \n",
       "50           0.2               0.0         NaN          NaN        NaN   \n",
       "51           0.2               1.0         NaN          1.0        NaN   \n",
       "\n",
       "   rfclf__criterion  rfclf__max_features  rfclf__n_estimators  \n",
       "49             gini                0.001                 20.0  \n",
       "50              NaN                  NaN                  NaN  \n",
       "51              NaN                  NaN                  NaN  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages_ = [('cvec', CountVectorizer()), ('mnclf', MultinomialNB())] #TfidfVectorizer()\n",
    "    \n",
    "params_ = dict(\n",
    "    cvec__max_features=[None, 1000, 5000], \n",
    "    cvec__lowercase=[True, False],\n",
    "    cvec__max_df=[0.5, 1.0],\n",
    "    cvec__min_df=[0.01, 0.02, 1],\n",
    "    cvec__ngram_range=[(1,1),(1,2)],\n",
    "    mnclf__fit_prior=[True, False],\n",
    "    mnclf__alpha=[0.1, 0.2, 0.5]\n",
    ")\n",
    "\n",
    "data_desc = 'no_stopwords'\n",
    "X = df_amodel[data_desc] # lemmatized # 'stemmed','no_stopwords'\n",
    "y = df_amodel['auth_label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "estimator = run_gridsearch_pipeline(stages_, params_, X_train, X_test, y_train, y_test )\n",
    "\n",
    "# store results and params so we have history\n",
    "df_gs_results = store_pipeline_results(estimator,'MultinomialNB', \n",
    "                                                 'authors', data_desc, \n",
    "                                                 X_test, y_test, df_gs_results)\n",
    "\n",
    "df_gs_results.to_csv(gridsearch_dir + 'gs_results.csv', encoding='utf-8', index=False)\n",
    "df_gs_results.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                       auth_label\n",
       "Albert Einstein              0             485\n",
       "Ambrose Gwinett Bierce       1             398\n",
       "Friedrich Wilhelm Nietzsche  2             393\n",
       "George Bernard Shaw          3             402\n",
       "Henry David Thoreau          4             396\n",
       "Mark Twain                   5             679\n",
       "Oscar Wilde                  6             509\n",
       "Ralph Waldo Emerson          7             888\n",
       "Scott McClellan              8             354\n",
       "William Shakespeare          9             574\n",
       "dtype: int64"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amodel.groupby([\"author\", \"auth_label\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_einstein</th>\n",
       "      <th>prob_bierce</th>\n",
       "      <th>prob_nietzsche</th>\n",
       "      <th>prob_shaw</th>\n",
       "      <th>prob_thoreau</th>\n",
       "      <th>prob_twain</th>\n",
       "      <th>prob_wilde</th>\n",
       "      <th>prob_emerson</th>\n",
       "      <th>prob_mcclellan</th>\n",
       "      <th>prob_shakespeare</th>\n",
       "      <th>quote</th>\n",
       "      <th>author_label</th>\n",
       "      <th>author_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023913</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>9.257845e-01</td>\n",
       "      <td>3.400744e-07</td>\n",
       "      <td>5.087905e-05</td>\n",
       "      <td>2.930345e-04</td>\n",
       "      <td>4.863942e-02</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>5.281015e-04</td>\n",
       "      <td>2.539920e-05</td>\n",
       "      <td>Talking much oneself also means conceal oneself</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>2.113690e-04</td>\n",
       "      <td>1.068432e-08</td>\n",
       "      <td>4.105720e-05</td>\n",
       "      <td>1.617115e-07</td>\n",
       "      <td>6.333032e-07</td>\n",
       "      <td>0.996677</td>\n",
       "      <td>2.510638e-11</td>\n",
       "      <td>8.202503e-05</td>\n",
       "      <td>Great men unknown generation fame among great ...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002832</td>\n",
       "      <td>0.991155</td>\n",
       "      <td>3.987051e-06</td>\n",
       "      <td>1.259827e-03</td>\n",
       "      <td>1.599242e-04</td>\n",
       "      <td>2.951732e-04</td>\n",
       "      <td>2.405127e-05</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>3.341945e-07</td>\n",
       "      <td>8.212272e-07</td>\n",
       "      <td>PHRENOLOGY n science picking pocket scalp cons...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037112</td>\n",
       "      <td>0.014311</td>\n",
       "      <td>3.538431e-02</td>\n",
       "      <td>1.559712e-01</td>\n",
       "      <td>3.570148e-02</td>\n",
       "      <td>1.816594e-01</td>\n",
       "      <td>1.585766e-01</td>\n",
       "      <td>0.156589</td>\n",
       "      <td>8.474898e-02</td>\n",
       "      <td>1.399459e-01</td>\n",
       "      <td>use</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>9.301271e-07</td>\n",
       "      <td>1.825923e-07</td>\n",
       "      <td>8.998849e-07</td>\n",
       "      <td>5.296771e-05</td>\n",
       "      <td>1.388937e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>6.309118e-07</td>\n",
       "      <td>9.999376e-01</td>\n",
       "      <td>Sweet uses adversity</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prob_einstein  prob_bierce  prob_nietzsche     prob_shaw  prob_thoreau  \\\n",
       "0       0.023913     0.000712    9.257845e-01  3.400744e-07  5.087905e-05   \n",
       "1       0.000059     0.002930    2.113690e-04  1.068432e-08  4.105720e-05   \n",
       "2       0.002832     0.991155    3.987051e-06  1.259827e-03  1.599242e-04   \n",
       "3       0.037112     0.014311    3.538431e-02  1.559712e-01  3.570148e-02   \n",
       "4       0.000002     0.000001    9.301271e-07  1.825923e-07  8.998849e-07   \n",
       "\n",
       "     prob_twain    prob_wilde  prob_emerson  prob_mcclellan  prob_shakespeare  \\\n",
       "0  2.930345e-04  4.863942e-02      0.000052    5.281015e-04      2.539920e-05   \n",
       "1  1.617115e-07  6.333032e-07      0.996677    2.510638e-11      8.202503e-05   \n",
       "2  2.951732e-04  2.405127e-05      0.004269    3.341945e-07      8.212272e-07   \n",
       "3  1.816594e-01  1.585766e-01      0.156589    8.474898e-02      1.399459e-01   \n",
       "4  5.296771e-05  1.388937e-07      0.000004    6.309118e-07      9.999376e-01   \n",
       "\n",
       "                                               quote  author_label  \\\n",
       "0    Talking much oneself also means conceal oneself             2   \n",
       "1  Great men unknown generation fame among great ...             4   \n",
       "2  PHRENOLOGY n science picking pocket scalp cons...             1   \n",
       "3                                                use             7   \n",
       "4                               Sweet uses adversity             9   \n",
       "\n",
       "   author_prediction  \n",
       "0                  2  \n",
       "1                  7  \n",
       "2                  1  \n",
       "3                  5  \n",
       "4                  9  "
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['prob_einstein','prob_bierce','prob_nietzsche','prob_shaw',\n",
    "        'prob_thoreau','prob_twain','prob_wilde','prob_emerson','prob_mcclellan', 'prob_shakespeare']\n",
    "predict_proba_ = estimator.predict_proba(X_test)\n",
    "y_preds = estimator.predict(X_test)\n",
    "proba_df = pd.DataFrame(predict_proba_, columns = cols).reset_index(drop=True)\n",
    "quote_df = pd.DataFrame(list(X_test), columns=['quote']).reset_index(drop=True)\n",
    "pred_df = pd.DataFrame(list(y_preds), columns=['author_prediction']).reset_index(drop=True)\n",
    "author_df = pd.DataFrame(list(y_test), columns=['author_label']).reset_index(drop=True)\n",
    "df_apredictions = pd.concat([proba_df, quote_df, author_df, pred_df ], axis = 1)\n",
    "df_apredictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_einstein</th>\n",
       "      <th>prob_bierce</th>\n",
       "      <th>prob_nietzsche</th>\n",
       "      <th>prob_shaw</th>\n",
       "      <th>prob_thoreau</th>\n",
       "      <th>prob_twain</th>\n",
       "      <th>prob_wilde</th>\n",
       "      <th>prob_emerson</th>\n",
       "      <th>prob_mcclellan</th>\n",
       "      <th>prob_shakespeare</th>\n",
       "      <th>quote</th>\n",
       "      <th>author_label</th>\n",
       "      <th>author_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.852435e-05</td>\n",
       "      <td>2.929637e-03</td>\n",
       "      <td>2.113690e-04</td>\n",
       "      <td>1.068432e-08</td>\n",
       "      <td>4.105720e-05</td>\n",
       "      <td>1.617115e-07</td>\n",
       "      <td>6.333032e-07</td>\n",
       "      <td>9.966766e-01</td>\n",
       "      <td>2.510638e-11</td>\n",
       "      <td>8.202503e-05</td>\n",
       "      <td>Great men unknown generation fame among great ...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.711178e-02</td>\n",
       "      <td>1.431108e-02</td>\n",
       "      <td>3.538431e-02</td>\n",
       "      <td>1.559712e-01</td>\n",
       "      <td>3.570148e-02</td>\n",
       "      <td>1.816594e-01</td>\n",
       "      <td>1.585766e-01</td>\n",
       "      <td>1.565893e-01</td>\n",
       "      <td>8.474898e-02</td>\n",
       "      <td>1.399459e-01</td>\n",
       "      <td>use</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.507947e-03</td>\n",
       "      <td>1.555661e-03</td>\n",
       "      <td>2.110696e-03</td>\n",
       "      <td>7.209069e-04</td>\n",
       "      <td>2.856822e-03</td>\n",
       "      <td>3.712881e-01</td>\n",
       "      <td>1.263401e-02</td>\n",
       "      <td>6.019714e-01</td>\n",
       "      <td>3.246440e-06</td>\n",
       "      <td>1.351199e-03</td>\n",
       "      <td>Every one master grief</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.966529e-07</td>\n",
       "      <td>9.999873e-01</td>\n",
       "      <td>1.125822e-05</td>\n",
       "      <td>7.946008e-08</td>\n",
       "      <td>9.174896e-08</td>\n",
       "      <td>8.167322e-09</td>\n",
       "      <td>2.977875e-07</td>\n",
       "      <td>9.399011e-09</td>\n",
       "      <td>4.004714e-10</td>\n",
       "      <td>4.865708e-10</td>\n",
       "      <td>country without rabbits partridges among simpl...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.440245e-02</td>\n",
       "      <td>2.510636e-04</td>\n",
       "      <td>4.125861e-04</td>\n",
       "      <td>1.956218e-05</td>\n",
       "      <td>1.466656e-04</td>\n",
       "      <td>3.653722e-01</td>\n",
       "      <td>2.777293e-01</td>\n",
       "      <td>3.413830e-01</td>\n",
       "      <td>2.831747e-04</td>\n",
       "      <td>4.037246e-08</td>\n",
       "      <td>striking result present system farming nationa...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.284770e-04</td>\n",
       "      <td>2.195709e-03</td>\n",
       "      <td>6.945355e-04</td>\n",
       "      <td>6.769273e-01</td>\n",
       "      <td>1.054729e-02</td>\n",
       "      <td>1.660966e-02</td>\n",
       "      <td>2.048292e-01</td>\n",
       "      <td>8.794751e-02</td>\n",
       "      <td>8.621894e-09</td>\n",
       "      <td>1.203370e-04</td>\n",
       "      <td>care flowers Calls rubbish tell one another th...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.407906e-04</td>\n",
       "      <td>9.984309e-01</td>\n",
       "      <td>8.202555e-05</td>\n",
       "      <td>2.241914e-06</td>\n",
       "      <td>4.525332e-05</td>\n",
       "      <td>2.451225e-04</td>\n",
       "      <td>8.524365e-06</td>\n",
       "      <td>7.050114e-04</td>\n",
       "      <td>7.891452e-09</td>\n",
       "      <td>3.401078e-04</td>\n",
       "      <td>Ignorance curse God knowledge wing wherewith f...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.303802e-01</td>\n",
       "      <td>2.959784e-04</td>\n",
       "      <td>6.879226e-03</td>\n",
       "      <td>1.447422e-02</td>\n",
       "      <td>7.404977e-05</td>\n",
       "      <td>5.644120e-02</td>\n",
       "      <td>6.369569e-02</td>\n",
       "      <td>2.706376e-02</td>\n",
       "      <td>2.658248e-04</td>\n",
       "      <td>4.297981e-04</td>\n",
       "      <td>hardest thing world think</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.395170e-07</td>\n",
       "      <td>2.300240e-06</td>\n",
       "      <td>4.048724e-04</td>\n",
       "      <td>3.126680e-05</td>\n",
       "      <td>4.422513e-05</td>\n",
       "      <td>2.027673e-04</td>\n",
       "      <td>4.099116e-04</td>\n",
       "      <td>1.050168e-02</td>\n",
       "      <td>6.942760e-09</td>\n",
       "      <td>9.884027e-01</td>\n",
       "      <td>Give love obey thy heart</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.373330e-02</td>\n",
       "      <td>9.529229e-02</td>\n",
       "      <td>3.297002e-02</td>\n",
       "      <td>9.679267e-03</td>\n",
       "      <td>1.402890e-02</td>\n",
       "      <td>3.239125e-01</td>\n",
       "      <td>1.270634e-04</td>\n",
       "      <td>5.018371e-01</td>\n",
       "      <td>6.725722e-03</td>\n",
       "      <td>1.693803e-03</td>\n",
       "      <td>E mc2 Energy equals mass times speed light squ...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.283527e-01</td>\n",
       "      <td>4.560246e-03</td>\n",
       "      <td>5.615353e-03</td>\n",
       "      <td>1.265484e-03</td>\n",
       "      <td>5.908134e-03</td>\n",
       "      <td>1.541463e-03</td>\n",
       "      <td>2.024270e-02</td>\n",
       "      <td>7.310974e-01</td>\n",
       "      <td>3.023802e-04</td>\n",
       "      <td>1.114180e-03</td>\n",
       "      <td>conforming outwardly living life inwardly high...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.320455e-02</td>\n",
       "      <td>1.313598e-01</td>\n",
       "      <td>6.599403e-04</td>\n",
       "      <td>6.962767e-02</td>\n",
       "      <td>4.057817e-02</td>\n",
       "      <td>7.421024e-02</td>\n",
       "      <td>2.428991e-02</td>\n",
       "      <td>5.001369e-01</td>\n",
       "      <td>1.148603e-04</td>\n",
       "      <td>8.581798e-02</td>\n",
       "      <td>time joint cursed spite ever born set right</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.774922e-02</td>\n",
       "      <td>1.054551e-02</td>\n",
       "      <td>3.051697e-01</td>\n",
       "      <td>2.273728e-01</td>\n",
       "      <td>1.904317e-02</td>\n",
       "      <td>2.128202e-02</td>\n",
       "      <td>1.278420e-01</td>\n",
       "      <td>2.294304e-01</td>\n",
       "      <td>1.532125e-02</td>\n",
       "      <td>2.624397e-02</td>\n",
       "      <td>Truths roses thorns</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6.554441e-05</td>\n",
       "      <td>2.859177e-03</td>\n",
       "      <td>3.637853e-02</td>\n",
       "      <td>1.042110e-02</td>\n",
       "      <td>1.825276e-03</td>\n",
       "      <td>4.850591e-02</td>\n",
       "      <td>3.588999e-01</td>\n",
       "      <td>5.316831e-01</td>\n",
       "      <td>5.479223e-06</td>\n",
       "      <td>9.355944e-03</td>\n",
       "      <td>Bad theaters mischievous bad schools</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.289360e-04</td>\n",
       "      <td>1.136189e-04</td>\n",
       "      <td>2.482435e-02</td>\n",
       "      <td>7.155880e-01</td>\n",
       "      <td>2.823174e-05</td>\n",
       "      <td>2.181209e-01</td>\n",
       "      <td>3.491794e-05</td>\n",
       "      <td>1.345723e-02</td>\n",
       "      <td>1.930508e-07</td>\n",
       "      <td>2.770370e-02</td>\n",
       "      <td>Reputation idle false imposition oft got witho...</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.145138e-03</td>\n",
       "      <td>2.731216e-01</td>\n",
       "      <td>1.402055e-02</td>\n",
       "      <td>6.943245e-03</td>\n",
       "      <td>4.232678e-03</td>\n",
       "      <td>3.031045e-01</td>\n",
       "      <td>6.467655e-03</td>\n",
       "      <td>1.619372e-01</td>\n",
       "      <td>1.614528e-01</td>\n",
       "      <td>6.357461e-02</td>\n",
       "      <td>HARANGUE n speech opponent known harrangue outang</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>9.912892e-03</td>\n",
       "      <td>8.711394e-01</td>\n",
       "      <td>2.000942e-03</td>\n",
       "      <td>1.337722e-02</td>\n",
       "      <td>1.186167e-02</td>\n",
       "      <td>1.085207e-02</td>\n",
       "      <td>5.399733e-02</td>\n",
       "      <td>9.142758e-03</td>\n",
       "      <td>1.519235e-03</td>\n",
       "      <td>1.619652e-02</td>\n",
       "      <td>Martyrdom covers multitude sins</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>8.989873e-04</td>\n",
       "      <td>4.198217e-09</td>\n",
       "      <td>8.107317e-06</td>\n",
       "      <td>6.157177e-05</td>\n",
       "      <td>9.772549e-01</td>\n",
       "      <td>1.308041e-05</td>\n",
       "      <td>2.136806e-02</td>\n",
       "      <td>9.774185e-09</td>\n",
       "      <td>1.658351e-15</td>\n",
       "      <td>3.952733e-04</td>\n",
       "      <td>Nothing truly valuable arises ambition mere se...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.948204e-07</td>\n",
       "      <td>3.750395e-05</td>\n",
       "      <td>8.772787e-03</td>\n",
       "      <td>1.065912e-08</td>\n",
       "      <td>1.324611e-04</td>\n",
       "      <td>2.697068e-09</td>\n",
       "      <td>8.970026e-07</td>\n",
       "      <td>9.908844e-01</td>\n",
       "      <td>4.356771e-19</td>\n",
       "      <td>1.713115e-04</td>\n",
       "      <td>advise love neighbor suggest rather escape nei...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>7.848132e-02</td>\n",
       "      <td>1.491256e-03</td>\n",
       "      <td>2.320986e-02</td>\n",
       "      <td>1.921135e-01</td>\n",
       "      <td>2.001295e-01</td>\n",
       "      <td>3.138782e-01</td>\n",
       "      <td>1.163829e-01</td>\n",
       "      <td>4.177772e-02</td>\n",
       "      <td>7.323562e-03</td>\n",
       "      <td>2.521212e-02</td>\n",
       "      <td>lost begin understand</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.633208e-03</td>\n",
       "      <td>7.457491e-05</td>\n",
       "      <td>6.066909e-04</td>\n",
       "      <td>2.266782e-04</td>\n",
       "      <td>6.526089e-03</td>\n",
       "      <td>9.592204e-01</td>\n",
       "      <td>3.693795e-04</td>\n",
       "      <td>3.881295e-04</td>\n",
       "      <td>2.598360e-02</td>\n",
       "      <td>9.712383e-04</td>\n",
       "      <td>Let keep mind hurricanes know instances floodi...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.150536e-01</td>\n",
       "      <td>2.482258e-03</td>\n",
       "      <td>2.259889e-02</td>\n",
       "      <td>8.339500e-04</td>\n",
       "      <td>1.160435e-01</td>\n",
       "      <td>1.294042e-02</td>\n",
       "      <td>1.148833e-01</td>\n",
       "      <td>1.143616e-01</td>\n",
       "      <td>1.180569e-04</td>\n",
       "      <td>6.844549e-04</td>\n",
       "      <td>Poetry implies whole truth philosophy expresse...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>8.354089e-05</td>\n",
       "      <td>3.912228e-02</td>\n",
       "      <td>1.140323e-04</td>\n",
       "      <td>7.838171e-04</td>\n",
       "      <td>6.689311e-04</td>\n",
       "      <td>3.006024e-03</td>\n",
       "      <td>1.099653e-04</td>\n",
       "      <td>3.628483e-04</td>\n",
       "      <td>8.183446e-05</td>\n",
       "      <td>9.556667e-01</td>\n",
       "      <td>Anger dwells bosom fools</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.613217e-02</td>\n",
       "      <td>1.076097e-03</td>\n",
       "      <td>6.467361e-05</td>\n",
       "      <td>2.506998e-03</td>\n",
       "      <td>6.922468e-03</td>\n",
       "      <td>9.726801e-01</td>\n",
       "      <td>3.052730e-04</td>\n",
       "      <td>2.947775e-04</td>\n",
       "      <td>1.711944e-05</td>\n",
       "      <td>3.409441e-07</td>\n",
       "      <td>HUMANITY n human race collectively exclusive a...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3.603661e-02</td>\n",
       "      <td>2.141077e-02</td>\n",
       "      <td>3.379596e-01</td>\n",
       "      <td>2.518035e-01</td>\n",
       "      <td>3.514886e-03</td>\n",
       "      <td>4.320933e-02</td>\n",
       "      <td>6.292371e-02</td>\n",
       "      <td>1.385903e-01</td>\n",
       "      <td>2.827914e-03</td>\n",
       "      <td>1.017234e-01</td>\n",
       "      <td>Cunning strength withheld</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.555595e-02</td>\n",
       "      <td>5.652729e-03</td>\n",
       "      <td>8.265600e-03</td>\n",
       "      <td>6.863712e-02</td>\n",
       "      <td>5.019698e-01</td>\n",
       "      <td>1.520180e-03</td>\n",
       "      <td>6.702133e-03</td>\n",
       "      <td>1.059729e-01</td>\n",
       "      <td>2.782193e-04</td>\n",
       "      <td>2.854454e-01</td>\n",
       "      <td>Every philosophy philosophy stage life</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.446714e-03</td>\n",
       "      <td>2.554623e-07</td>\n",
       "      <td>9.728919e-02</td>\n",
       "      <td>1.709628e-05</td>\n",
       "      <td>1.939705e-03</td>\n",
       "      <td>4.987714e-05</td>\n",
       "      <td>1.062516e-04</td>\n",
       "      <td>5.455625e-03</td>\n",
       "      <td>9.168194e-11</td>\n",
       "      <td>8.936953e-01</td>\n",
       "      <td>Today love love god could charge sin today kno...</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>3.346758e-09</td>\n",
       "      <td>1.488429e-05</td>\n",
       "      <td>1.892017e-03</td>\n",
       "      <td>4.293342e-01</td>\n",
       "      <td>3.568900e-06</td>\n",
       "      <td>1.032641e-05</td>\n",
       "      <td>3.760704e-01</td>\n",
       "      <td>1.925451e-01</td>\n",
       "      <td>2.724693e-09</td>\n",
       "      <td>1.294406e-04</td>\n",
       "      <td>Seasickness first sick afraid die sick afraid die</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4.715409e-02</td>\n",
       "      <td>8.297710e-05</td>\n",
       "      <td>8.347012e-03</td>\n",
       "      <td>9.706265e-03</td>\n",
       "      <td>6.928564e-02</td>\n",
       "      <td>2.066582e-01</td>\n",
       "      <td>1.946125e-04</td>\n",
       "      <td>6.581233e-01</td>\n",
       "      <td>8.841595e-06</td>\n",
       "      <td>4.391038e-04</td>\n",
       "      <td>thousand mysteries around us would trouble int...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>5.043422e-02</td>\n",
       "      <td>6.321416e-04</td>\n",
       "      <td>1.078792e-01</td>\n",
       "      <td>6.027560e-04</td>\n",
       "      <td>1.110255e-02</td>\n",
       "      <td>7.260961e-02</td>\n",
       "      <td>9.068693e-04</td>\n",
       "      <td>7.556835e-01</td>\n",
       "      <td>3.569191e-07</td>\n",
       "      <td>1.487866e-04</td>\n",
       "      <td>spirit God became man even becoming mob</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>9.825353e-01</td>\n",
       "      <td>1.987963e-08</td>\n",
       "      <td>1.644773e-02</td>\n",
       "      <td>1.875705e-08</td>\n",
       "      <td>3.327600e-09</td>\n",
       "      <td>5.008420e-08</td>\n",
       "      <td>2.689142e-05</td>\n",
       "      <td>9.895710e-04</td>\n",
       "      <td>1.647899e-08</td>\n",
       "      <td>4.150226e-07</td>\n",
       "      <td>thirst equality express either desire draw eve...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>2.019885e-07</td>\n",
       "      <td>2.097402e-03</td>\n",
       "      <td>6.293410e-01</td>\n",
       "      <td>1.394997e-01</td>\n",
       "      <td>2.383895e-04</td>\n",
       "      <td>9.297448e-04</td>\n",
       "      <td>4.435101e-07</td>\n",
       "      <td>1.466131e-01</td>\n",
       "      <td>1.941217e-06</td>\n",
       "      <td>8.127805e-02</td>\n",
       "      <td>Men naturally seek money power power good money</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>6.097157e-03</td>\n",
       "      <td>1.826641e-02</td>\n",
       "      <td>1.230726e-03</td>\n",
       "      <td>9.249833e-02</td>\n",
       "      <td>1.317951e-02</td>\n",
       "      <td>3.502486e-02</td>\n",
       "      <td>1.384534e-02</td>\n",
       "      <td>7.502794e-01</td>\n",
       "      <td>3.363989e-02</td>\n",
       "      <td>3.593835e-02</td>\n",
       "      <td>better grace natural</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>1.288229e-01</td>\n",
       "      <td>2.812304e-03</td>\n",
       "      <td>1.307096e-01</td>\n",
       "      <td>1.475902e-03</td>\n",
       "      <td>1.034211e-03</td>\n",
       "      <td>1.364315e-04</td>\n",
       "      <td>8.992433e-04</td>\n",
       "      <td>8.078409e-03</td>\n",
       "      <td>7.249656e-01</td>\n",
       "      <td>1.065374e-03</td>\n",
       "      <td>put boldly attempt posterior reconstruction ex...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>2.118575e-04</td>\n",
       "      <td>1.110979e-08</td>\n",
       "      <td>6.776535e-09</td>\n",
       "      <td>1.404369e-05</td>\n",
       "      <td>8.372157e-07</td>\n",
       "      <td>8.914663e-05</td>\n",
       "      <td>7.218159e-12</td>\n",
       "      <td>9.996841e-01</td>\n",
       "      <td>6.158688e-17</td>\n",
       "      <td>2.271812e-11</td>\n",
       "      <td>must annex people afflict wise beneficent gove...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2.087935e-04</td>\n",
       "      <td>3.204523e-03</td>\n",
       "      <td>2.451039e-04</td>\n",
       "      <td>9.003826e-05</td>\n",
       "      <td>3.724745e-04</td>\n",
       "      <td>1.606768e-04</td>\n",
       "      <td>9.954077e-01</td>\n",
       "      <td>3.086654e-04</td>\n",
       "      <td>1.084255e-06</td>\n",
       "      <td>9.187628e-07</td>\n",
       "      <td>perhaps possible two kinds civilization one ho...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>3.007481e-05</td>\n",
       "      <td>2.711267e-04</td>\n",
       "      <td>5.783187e-04</td>\n",
       "      <td>2.732289e-03</td>\n",
       "      <td>8.147470e-01</td>\n",
       "      <td>2.496467e-02</td>\n",
       "      <td>1.045091e-02</td>\n",
       "      <td>1.025688e-01</td>\n",
       "      <td>1.575059e-08</td>\n",
       "      <td>4.365683e-02</td>\n",
       "      <td>man rich enough buy back past</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>1.543029e-02</td>\n",
       "      <td>1.796535e-06</td>\n",
       "      <td>4.300117e-05</td>\n",
       "      <td>4.977354e-04</td>\n",
       "      <td>3.802503e-07</td>\n",
       "      <td>8.379765e-02</td>\n",
       "      <td>8.016156e-01</td>\n",
       "      <td>9.859938e-02</td>\n",
       "      <td>8.160752e-06</td>\n",
       "      <td>6.012257e-06</td>\n",
       "      <td>Fear defeats people one thing world</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>9.306235e-06</td>\n",
       "      <td>2.412336e-07</td>\n",
       "      <td>3.553036e-06</td>\n",
       "      <td>2.656249e-05</td>\n",
       "      <td>1.045493e-06</td>\n",
       "      <td>9.945347e-01</td>\n",
       "      <td>4.490392e-07</td>\n",
       "      <td>9.090585e-07</td>\n",
       "      <td>5.423206e-03</td>\n",
       "      <td>4.390842e-09</td>\n",
       "      <td>June 10 2004 Bush responded affirmatively aske...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>2.621785e-02</td>\n",
       "      <td>1.525306e-03</td>\n",
       "      <td>2.452685e-03</td>\n",
       "      <td>7.918363e-04</td>\n",
       "      <td>3.355849e-07</td>\n",
       "      <td>5.382458e-01</td>\n",
       "      <td>3.707453e-01</td>\n",
       "      <td>5.996011e-02</td>\n",
       "      <td>4.545570e-05</td>\n",
       "      <td>1.533534e-05</td>\n",
       "      <td>everything one thing impossible rationality</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>6.071188e-04</td>\n",
       "      <td>4.334373e-05</td>\n",
       "      <td>5.313359e-03</td>\n",
       "      <td>7.969420e-04</td>\n",
       "      <td>2.387130e-02</td>\n",
       "      <td>9.655234e-01</td>\n",
       "      <td>7.986078e-05</td>\n",
       "      <td>3.558822e-03</td>\n",
       "      <td>5.495673e-06</td>\n",
       "      <td>2.003843e-04</td>\n",
       "      <td>wish somewhere existed island wise goodwill pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>6.804930e-04</td>\n",
       "      <td>1.365873e-02</td>\n",
       "      <td>4.666108e-03</td>\n",
       "      <td>6.983850e-04</td>\n",
       "      <td>2.883421e-02</td>\n",
       "      <td>2.491469e-01</td>\n",
       "      <td>5.826027e-01</td>\n",
       "      <td>9.403243e-02</td>\n",
       "      <td>7.093615e-04</td>\n",
       "      <td>2.497068e-02</td>\n",
       "      <td>human intercourse tragedy begins misunderstand...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>1.874943e-01</td>\n",
       "      <td>1.348585e-01</td>\n",
       "      <td>6.417591e-06</td>\n",
       "      <td>6.381324e-01</td>\n",
       "      <td>3.124890e-03</td>\n",
       "      <td>1.851522e-02</td>\n",
       "      <td>3.173508e-04</td>\n",
       "      <td>1.692714e-02</td>\n",
       "      <td>5.291247e-04</td>\n",
       "      <td>9.465997e-05</td>\n",
       "      <td>COMPROMISE n adjustment conflicting interests ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>4.369355e-03</td>\n",
       "      <td>9.290378e-04</td>\n",
       "      <td>1.156261e-02</td>\n",
       "      <td>8.926796e-03</td>\n",
       "      <td>1.113098e-01</td>\n",
       "      <td>5.580482e-02</td>\n",
       "      <td>3.045104e-03</td>\n",
       "      <td>7.453650e-01</td>\n",
       "      <td>6.764534e-05</td>\n",
       "      <td>5.861986e-02</td>\n",
       "      <td>Virtue bold goodness never fearful</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>9.792303e-01</td>\n",
       "      <td>1.522826e-05</td>\n",
       "      <td>3.504697e-03</td>\n",
       "      <td>2.542940e-06</td>\n",
       "      <td>1.325612e-02</td>\n",
       "      <td>2.824132e-06</td>\n",
       "      <td>2.895964e-06</td>\n",
       "      <td>3.733349e-03</td>\n",
       "      <td>8.508796e-07</td>\n",
       "      <td>2.511912e-04</td>\n",
       "      <td>PRESENT n part eternity dividing domain disapp...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1.301750e-05</td>\n",
       "      <td>6.291000e-08</td>\n",
       "      <td>2.345025e-03</td>\n",
       "      <td>4.064076e-06</td>\n",
       "      <td>3.030200e-04</td>\n",
       "      <td>4.836050e-04</td>\n",
       "      <td>7.700976e-01</td>\n",
       "      <td>2.155799e-01</td>\n",
       "      <td>8.431858e-11</td>\n",
       "      <td>1.117369e-02</td>\n",
       "      <td>made happy reason discover occasion memory pas...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1.214142e-01</td>\n",
       "      <td>2.637741e-02</td>\n",
       "      <td>5.746224e-04</td>\n",
       "      <td>2.246639e-03</td>\n",
       "      <td>7.257528e-04</td>\n",
       "      <td>5.658151e-03</td>\n",
       "      <td>7.033161e-01</td>\n",
       "      <td>1.363393e-01</td>\n",
       "      <td>1.202284e-06</td>\n",
       "      <td>3.346615e-03</td>\n",
       "      <td>PANTOMIME n play story told without violence l...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>8.008307e-07</td>\n",
       "      <td>1.109124e-05</td>\n",
       "      <td>3.733896e-01</td>\n",
       "      <td>1.221717e-03</td>\n",
       "      <td>3.397276e-03</td>\n",
       "      <td>1.530735e-06</td>\n",
       "      <td>2.465650e-01</td>\n",
       "      <td>3.727636e-01</td>\n",
       "      <td>3.212617e-10</td>\n",
       "      <td>2.649405e-03</td>\n",
       "      <td>men women friendship possible passion enmity w...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1.290122e-01</td>\n",
       "      <td>1.565308e-04</td>\n",
       "      <td>1.472279e-03</td>\n",
       "      <td>4.788544e-03</td>\n",
       "      <td>1.016073e-03</td>\n",
       "      <td>6.152145e-04</td>\n",
       "      <td>8.592575e-01</td>\n",
       "      <td>1.852470e-03</td>\n",
       "      <td>3.321875e-05</td>\n",
       "      <td>1.795973e-03</td>\n",
       "      <td>unwise people love marry</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2.645433e-03</td>\n",
       "      <td>2.387125e-04</td>\n",
       "      <td>8.012385e-05</td>\n",
       "      <td>2.401867e-02</td>\n",
       "      <td>3.982450e-03</td>\n",
       "      <td>1.509316e-02</td>\n",
       "      <td>8.513520e-01</td>\n",
       "      <td>9.108111e-02</td>\n",
       "      <td>4.577898e-07</td>\n",
       "      <td>1.150792e-02</td>\n",
       "      <td>wise young say never live long</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>5.126493e-03</td>\n",
       "      <td>2.174572e-02</td>\n",
       "      <td>1.515239e-01</td>\n",
       "      <td>5.152143e-03</td>\n",
       "      <td>4.931679e-03</td>\n",
       "      <td>6.799808e-01</td>\n",
       "      <td>5.877013e-03</td>\n",
       "      <td>4.605246e-02</td>\n",
       "      <td>4.154073e-03</td>\n",
       "      <td>7.545577e-02</td>\n",
       "      <td>lie throat</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1.827614e-02</td>\n",
       "      <td>6.339802e-01</td>\n",
       "      <td>3.187633e-02</td>\n",
       "      <td>1.154712e-03</td>\n",
       "      <td>1.601377e-03</td>\n",
       "      <td>2.518679e-02</td>\n",
       "      <td>3.401996e-03</td>\n",
       "      <td>1.565547e-01</td>\n",
       "      <td>1.247772e-02</td>\n",
       "      <td>1.154901e-01</td>\n",
       "      <td>lean low abilityI lend something</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1.462211e-02</td>\n",
       "      <td>6.418123e-02</td>\n",
       "      <td>9.472287e-03</td>\n",
       "      <td>1.046266e-01</td>\n",
       "      <td>1.037594e-02</td>\n",
       "      <td>2.477433e-01</td>\n",
       "      <td>5.898893e-02</td>\n",
       "      <td>4.290467e-01</td>\n",
       "      <td>9.380777e-04</td>\n",
       "      <td>6.000489e-02</td>\n",
       "      <td>hero without coward</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>6.634265e-02</td>\n",
       "      <td>8.133622e-03</td>\n",
       "      <td>1.391873e-01</td>\n",
       "      <td>2.207452e-02</td>\n",
       "      <td>3.445974e-02</td>\n",
       "      <td>1.363671e-01</td>\n",
       "      <td>1.618100e-01</td>\n",
       "      <td>3.563886e-01</td>\n",
       "      <td>5.499491e-02</td>\n",
       "      <td>2.024165e-02</td>\n",
       "      <td>giving vein day</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2.571678e-04</td>\n",
       "      <td>1.074109e-04</td>\n",
       "      <td>1.301170e-04</td>\n",
       "      <td>1.350774e-06</td>\n",
       "      <td>7.503118e-03</td>\n",
       "      <td>6.115185e-02</td>\n",
       "      <td>1.195547e-04</td>\n",
       "      <td>5.721352e-02</td>\n",
       "      <td>4.615852e-10</td>\n",
       "      <td>8.735159e-01</td>\n",
       "      <td>many things wise man might wish ignorant</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>3.519812e-02</td>\n",
       "      <td>4.050632e-02</td>\n",
       "      <td>4.748787e-03</td>\n",
       "      <td>8.634649e-01</td>\n",
       "      <td>3.377054e-04</td>\n",
       "      <td>1.196322e-02</td>\n",
       "      <td>3.318500e-02</td>\n",
       "      <td>1.035209e-02</td>\n",
       "      <td>7.425799e-05</td>\n",
       "      <td>1.695850e-04</td>\n",
       "      <td>Bigot One obstinately zealously attached opini...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>6.724225e-04</td>\n",
       "      <td>1.217589e-03</td>\n",
       "      <td>3.218131e-04</td>\n",
       "      <td>7.128641e-01</td>\n",
       "      <td>1.892084e-03</td>\n",
       "      <td>2.721018e-01</td>\n",
       "      <td>6.037738e-03</td>\n",
       "      <td>4.014703e-03</td>\n",
       "      <td>3.164528e-06</td>\n",
       "      <td>8.745351e-04</td>\n",
       "      <td>Truth mighty prevail nothing wrong except</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>7.989238e-03</td>\n",
       "      <td>1.073070e-05</td>\n",
       "      <td>9.686537e-04</td>\n",
       "      <td>1.256932e-03</td>\n",
       "      <td>4.203015e-03</td>\n",
       "      <td>3.284864e-03</td>\n",
       "      <td>1.616927e-04</td>\n",
       "      <td>9.810943e-01</td>\n",
       "      <td>3.435528e-05</td>\n",
       "      <td>9.962045e-04</td>\n",
       "      <td>Live beliefs turn world around</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2.129947e-02</td>\n",
       "      <td>5.284837e-01</td>\n",
       "      <td>8.824562e-02</td>\n",
       "      <td>1.935699e-01</td>\n",
       "      <td>9.122068e-03</td>\n",
       "      <td>3.373103e-03</td>\n",
       "      <td>2.902025e-02</td>\n",
       "      <td>8.762206e-02</td>\n",
       "      <td>1.941193e-06</td>\n",
       "      <td>3.926190e-02</td>\n",
       "      <td>brotherhood man mere poet dream depressing hum...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>4.800724e-07</td>\n",
       "      <td>3.094496e-05</td>\n",
       "      <td>3.127727e-08</td>\n",
       "      <td>5.625046e-07</td>\n",
       "      <td>8.114454e-06</td>\n",
       "      <td>9.995849e-01</td>\n",
       "      <td>5.788833e-07</td>\n",
       "      <td>3.713687e-04</td>\n",
       "      <td>5.287014e-08</td>\n",
       "      <td>2.933446e-06</td>\n",
       "      <td>Day n period twenty four hours mostly misspent</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prob_einstein   prob_bierce  prob_nietzsche     prob_shaw  prob_thoreau  \\\n",
       "1     5.852435e-05  2.929637e-03    2.113690e-04  1.068432e-08  4.105720e-05   \n",
       "3     3.711178e-02  1.431108e-02    3.538431e-02  1.559712e-01  3.570148e-02   \n",
       "5     5.507947e-03  1.555661e-03    2.110696e-03  7.209069e-04  2.856822e-03   \n",
       "10    9.966529e-07  9.999873e-01    1.125822e-05  7.946008e-08  9.174896e-08   \n",
       "11    1.440245e-02  2.510636e-04    4.125861e-04  1.956218e-05  1.466656e-04   \n",
       "14    1.284770e-04  2.195709e-03    6.945355e-04  6.769273e-01  1.054729e-02   \n",
       "18    1.407906e-04  9.984309e-01    8.202555e-05  2.241914e-06  4.525332e-05   \n",
       "19    8.303802e-01  2.959784e-04    6.879226e-03  1.447422e-02  7.404977e-05   \n",
       "20    2.395170e-07  2.300240e-06    4.048724e-04  3.126680e-05  4.422513e-05   \n",
       "23    1.373330e-02  9.529229e-02    3.297002e-02  9.679267e-03  1.402890e-02   \n",
       "32    2.283527e-01  4.560246e-03    5.615353e-03  1.265484e-03  5.908134e-03   \n",
       "33    7.320455e-02  1.313598e-01    6.599403e-04  6.962767e-02  4.057817e-02   \n",
       "34    1.774922e-02  1.054551e-02    3.051697e-01  2.273728e-01  1.904317e-02   \n",
       "36    6.554441e-05  2.859177e-03    3.637853e-02  1.042110e-02  1.825276e-03   \n",
       "37    1.289360e-04  1.136189e-04    2.482435e-02  7.155880e-01  2.823174e-05   \n",
       "40    5.145138e-03  2.731216e-01    1.402055e-02  6.943245e-03  4.232678e-03   \n",
       "41    9.912892e-03  8.711394e-01    2.000942e-03  1.337722e-02  1.186167e-02   \n",
       "45    8.989873e-04  4.198217e-09    8.107317e-06  6.157177e-05  9.772549e-01   \n",
       "46    5.948204e-07  3.750395e-05    8.772787e-03  1.065912e-08  1.324611e-04   \n",
       "48    7.848132e-02  1.491256e-03    2.320986e-02  1.921135e-01  2.001295e-01   \n",
       "50    5.633208e-03  7.457491e-05    6.066909e-04  2.266782e-04  6.526089e-03   \n",
       "51    6.150536e-01  2.482258e-03    2.259889e-02  8.339500e-04  1.160435e-01   \n",
       "55    8.354089e-05  3.912228e-02    1.140323e-04  7.838171e-04  6.689311e-04   \n",
       "58    1.613217e-02  1.076097e-03    6.467361e-05  2.506998e-03  6.922468e-03   \n",
       "59    3.603661e-02  2.141077e-02    3.379596e-01  2.518035e-01  3.514886e-03   \n",
       "61    1.555595e-02  5.652729e-03    8.265600e-03  6.863712e-02  5.019698e-01   \n",
       "63    1.446714e-03  2.554623e-07    9.728919e-02  1.709628e-05  1.939705e-03   \n",
       "65    3.346758e-09  1.488429e-05    1.892017e-03  4.293342e-01  3.568900e-06   \n",
       "69    4.715409e-02  8.297710e-05    8.347012e-03  9.706265e-03  6.928564e-02   \n",
       "73    5.043422e-02  6.321416e-04    1.078792e-01  6.027560e-04  1.110255e-02   \n",
       "..             ...           ...             ...           ...           ...   \n",
       "434   9.825353e-01  1.987963e-08    1.644773e-02  1.875705e-08  3.327600e-09   \n",
       "437   2.019885e-07  2.097402e-03    6.293410e-01  1.394997e-01  2.383895e-04   \n",
       "439   6.097157e-03  1.826641e-02    1.230726e-03  9.249833e-02  1.317951e-02   \n",
       "440   1.288229e-01  2.812304e-03    1.307096e-01  1.475902e-03  1.034211e-03   \n",
       "441   2.118575e-04  1.110979e-08    6.776535e-09  1.404369e-05  8.372157e-07   \n",
       "444   2.087935e-04  3.204523e-03    2.451039e-04  9.003826e-05  3.724745e-04   \n",
       "448   3.007481e-05  2.711267e-04    5.783187e-04  2.732289e-03  8.147470e-01   \n",
       "449   1.543029e-02  1.796535e-06    4.300117e-05  4.977354e-04  3.802503e-07   \n",
       "452   9.306235e-06  2.412336e-07    3.553036e-06  2.656249e-05  1.045493e-06   \n",
       "455   2.621785e-02  1.525306e-03    2.452685e-03  7.918363e-04  3.355849e-07   \n",
       "457   6.071188e-04  4.334373e-05    5.313359e-03  7.969420e-04  2.387130e-02   \n",
       "462   6.804930e-04  1.365873e-02    4.666108e-03  6.983850e-04  2.883421e-02   \n",
       "467   1.874943e-01  1.348585e-01    6.417591e-06  6.381324e-01  3.124890e-03   \n",
       "468   4.369355e-03  9.290378e-04    1.156261e-02  8.926796e-03  1.113098e-01   \n",
       "469   9.792303e-01  1.522826e-05    3.504697e-03  2.542940e-06  1.325612e-02   \n",
       "473   1.301750e-05  6.291000e-08    2.345025e-03  4.064076e-06  3.030200e-04   \n",
       "474   1.214142e-01  2.637741e-02    5.746224e-04  2.246639e-03  7.257528e-04   \n",
       "476   8.008307e-07  1.109124e-05    3.733896e-01  1.221717e-03  3.397276e-03   \n",
       "479   1.290122e-01  1.565308e-04    1.472279e-03  4.788544e-03  1.016073e-03   \n",
       "482   2.645433e-03  2.387125e-04    8.012385e-05  2.401867e-02  3.982450e-03   \n",
       "486   5.126493e-03  2.174572e-02    1.515239e-01  5.152143e-03  4.931679e-03   \n",
       "489   1.827614e-02  6.339802e-01    3.187633e-02  1.154712e-03  1.601377e-03   \n",
       "491   1.462211e-02  6.418123e-02    9.472287e-03  1.046266e-01  1.037594e-02   \n",
       "492   6.634265e-02  8.133622e-03    1.391873e-01  2.207452e-02  3.445974e-02   \n",
       "493   2.571678e-04  1.074109e-04    1.301170e-04  1.350774e-06  7.503118e-03   \n",
       "496   3.519812e-02  4.050632e-02    4.748787e-03  8.634649e-01  3.377054e-04   \n",
       "500   6.724225e-04  1.217589e-03    3.218131e-04  7.128641e-01  1.892084e-03   \n",
       "502   7.989238e-03  1.073070e-05    9.686537e-04  1.256932e-03  4.203015e-03   \n",
       "506   2.129947e-02  5.284837e-01    8.824562e-02  1.935699e-01  9.122068e-03   \n",
       "507   4.800724e-07  3.094496e-05    3.127727e-08  5.625046e-07  8.114454e-06   \n",
       "\n",
       "       prob_twain    prob_wilde  prob_emerson  prob_mcclellan  \\\n",
       "1    1.617115e-07  6.333032e-07  9.966766e-01    2.510638e-11   \n",
       "3    1.816594e-01  1.585766e-01  1.565893e-01    8.474898e-02   \n",
       "5    3.712881e-01  1.263401e-02  6.019714e-01    3.246440e-06   \n",
       "10   8.167322e-09  2.977875e-07  9.399011e-09    4.004714e-10   \n",
       "11   3.653722e-01  2.777293e-01  3.413830e-01    2.831747e-04   \n",
       "14   1.660966e-02  2.048292e-01  8.794751e-02    8.621894e-09   \n",
       "18   2.451225e-04  8.524365e-06  7.050114e-04    7.891452e-09   \n",
       "19   5.644120e-02  6.369569e-02  2.706376e-02    2.658248e-04   \n",
       "20   2.027673e-04  4.099116e-04  1.050168e-02    6.942760e-09   \n",
       "23   3.239125e-01  1.270634e-04  5.018371e-01    6.725722e-03   \n",
       "32   1.541463e-03  2.024270e-02  7.310974e-01    3.023802e-04   \n",
       "33   7.421024e-02  2.428991e-02  5.001369e-01    1.148603e-04   \n",
       "34   2.128202e-02  1.278420e-01  2.294304e-01    1.532125e-02   \n",
       "36   4.850591e-02  3.588999e-01  5.316831e-01    5.479223e-06   \n",
       "37   2.181209e-01  3.491794e-05  1.345723e-02    1.930508e-07   \n",
       "40   3.031045e-01  6.467655e-03  1.619372e-01    1.614528e-01   \n",
       "41   1.085207e-02  5.399733e-02  9.142758e-03    1.519235e-03   \n",
       "45   1.308041e-05  2.136806e-02  9.774185e-09    1.658351e-15   \n",
       "46   2.697068e-09  8.970026e-07  9.908844e-01    4.356771e-19   \n",
       "48   3.138782e-01  1.163829e-01  4.177772e-02    7.323562e-03   \n",
       "50   9.592204e-01  3.693795e-04  3.881295e-04    2.598360e-02   \n",
       "51   1.294042e-02  1.148833e-01  1.143616e-01    1.180569e-04   \n",
       "55   3.006024e-03  1.099653e-04  3.628483e-04    8.183446e-05   \n",
       "58   9.726801e-01  3.052730e-04  2.947775e-04    1.711944e-05   \n",
       "59   4.320933e-02  6.292371e-02  1.385903e-01    2.827914e-03   \n",
       "61   1.520180e-03  6.702133e-03  1.059729e-01    2.782193e-04   \n",
       "63   4.987714e-05  1.062516e-04  5.455625e-03    9.168194e-11   \n",
       "65   1.032641e-05  3.760704e-01  1.925451e-01    2.724693e-09   \n",
       "69   2.066582e-01  1.946125e-04  6.581233e-01    8.841595e-06   \n",
       "73   7.260961e-02  9.068693e-04  7.556835e-01    3.569191e-07   \n",
       "..            ...           ...           ...             ...   \n",
       "434  5.008420e-08  2.689142e-05  9.895710e-04    1.647899e-08   \n",
       "437  9.297448e-04  4.435101e-07  1.466131e-01    1.941217e-06   \n",
       "439  3.502486e-02  1.384534e-02  7.502794e-01    3.363989e-02   \n",
       "440  1.364315e-04  8.992433e-04  8.078409e-03    7.249656e-01   \n",
       "441  8.914663e-05  7.218159e-12  9.996841e-01    6.158688e-17   \n",
       "444  1.606768e-04  9.954077e-01  3.086654e-04    1.084255e-06   \n",
       "448  2.496467e-02  1.045091e-02  1.025688e-01    1.575059e-08   \n",
       "449  8.379765e-02  8.016156e-01  9.859938e-02    8.160752e-06   \n",
       "452  9.945347e-01  4.490392e-07  9.090585e-07    5.423206e-03   \n",
       "455  5.382458e-01  3.707453e-01  5.996011e-02    4.545570e-05   \n",
       "457  9.655234e-01  7.986078e-05  3.558822e-03    5.495673e-06   \n",
       "462  2.491469e-01  5.826027e-01  9.403243e-02    7.093615e-04   \n",
       "467  1.851522e-02  3.173508e-04  1.692714e-02    5.291247e-04   \n",
       "468  5.580482e-02  3.045104e-03  7.453650e-01    6.764534e-05   \n",
       "469  2.824132e-06  2.895964e-06  3.733349e-03    8.508796e-07   \n",
       "473  4.836050e-04  7.700976e-01  2.155799e-01    8.431858e-11   \n",
       "474  5.658151e-03  7.033161e-01  1.363393e-01    1.202284e-06   \n",
       "476  1.530735e-06  2.465650e-01  3.727636e-01    3.212617e-10   \n",
       "479  6.152145e-04  8.592575e-01  1.852470e-03    3.321875e-05   \n",
       "482  1.509316e-02  8.513520e-01  9.108111e-02    4.577898e-07   \n",
       "486  6.799808e-01  5.877013e-03  4.605246e-02    4.154073e-03   \n",
       "489  2.518679e-02  3.401996e-03  1.565547e-01    1.247772e-02   \n",
       "491  2.477433e-01  5.898893e-02  4.290467e-01    9.380777e-04   \n",
       "492  1.363671e-01  1.618100e-01  3.563886e-01    5.499491e-02   \n",
       "493  6.115185e-02  1.195547e-04  5.721352e-02    4.615852e-10   \n",
       "496  1.196322e-02  3.318500e-02  1.035209e-02    7.425799e-05   \n",
       "500  2.721018e-01  6.037738e-03  4.014703e-03    3.164528e-06   \n",
       "502  3.284864e-03  1.616927e-04  9.810943e-01    3.435528e-05   \n",
       "506  3.373103e-03  2.902025e-02  8.762206e-02    1.941193e-06   \n",
       "507  9.995849e-01  5.788833e-07  3.713687e-04    5.287014e-08   \n",
       "\n",
       "     prob_shakespeare                                              quote  \\\n",
       "1        8.202503e-05  Great men unknown generation fame among great ...   \n",
       "3        1.399459e-01                                                use   \n",
       "5        1.351199e-03                             Every one master grief   \n",
       "10       4.865708e-10  country without rabbits partridges among simpl...   \n",
       "11       4.037246e-08  striking result present system farming nationa...   \n",
       "14       1.203370e-04  care flowers Calls rubbish tell one another th...   \n",
       "18       3.401078e-04  Ignorance curse God knowledge wing wherewith f...   \n",
       "19       4.297981e-04                          hardest thing world think   \n",
       "20       9.884027e-01                           Give love obey thy heart   \n",
       "23       1.693803e-03  E mc2 Energy equals mass times speed light squ...   \n",
       "32       1.114180e-03  conforming outwardly living life inwardly high...   \n",
       "33       8.581798e-02        time joint cursed spite ever born set right   \n",
       "34       2.624397e-02                                Truths roses thorns   \n",
       "36       9.355944e-03               Bad theaters mischievous bad schools   \n",
       "37       2.770370e-02  Reputation idle false imposition oft got witho...   \n",
       "40       6.357461e-02  HARANGUE n speech opponent known harrangue outang   \n",
       "41       1.619652e-02                    Martyrdom covers multitude sins   \n",
       "45       3.952733e-04  Nothing truly valuable arises ambition mere se...   \n",
       "46       1.713115e-04  advise love neighbor suggest rather escape nei...   \n",
       "48       2.521212e-02                              lost begin understand   \n",
       "50       9.712383e-04  Let keep mind hurricanes know instances floodi...   \n",
       "51       6.844549e-04  Poetry implies whole truth philosophy expresse...   \n",
       "55       9.556667e-01                           Anger dwells bosom fools   \n",
       "58       3.409441e-07  HUMANITY n human race collectively exclusive a...   \n",
       "59       1.017234e-01                          Cunning strength withheld   \n",
       "61       2.854454e-01             Every philosophy philosophy stage life   \n",
       "63       8.936953e-01  Today love love god could charge sin today kno...   \n",
       "65       1.294406e-04  Seasickness first sick afraid die sick afraid die   \n",
       "69       4.391038e-04  thousand mysteries around us would trouble int...   \n",
       "73       1.487866e-04            spirit God became man even becoming mob   \n",
       "..                ...                                                ...   \n",
       "434      4.150226e-07  thirst equality express either desire draw eve...   \n",
       "437      8.127805e-02    Men naturally seek money power power good money   \n",
       "439      3.593835e-02                               better grace natural   \n",
       "440      1.065374e-03  put boldly attempt posterior reconstruction ex...   \n",
       "441      2.271812e-11  must annex people afflict wise beneficent gove...   \n",
       "444      9.187628e-07  perhaps possible two kinds civilization one ho...   \n",
       "448      4.365683e-02                      man rich enough buy back past   \n",
       "449      6.012257e-06                Fear defeats people one thing world   \n",
       "452      4.390842e-09  June 10 2004 Bush responded affirmatively aske...   \n",
       "455      1.533534e-05        everything one thing impossible rationality   \n",
       "457      2.003843e-04  wish somewhere existed island wise goodwill pl...   \n",
       "462      2.497068e-02  human intercourse tragedy begins misunderstand...   \n",
       "467      9.465997e-05  COMPROMISE n adjustment conflicting interests ...   \n",
       "468      5.861986e-02                 Virtue bold goodness never fearful   \n",
       "469      2.511912e-04  PRESENT n part eternity dividing domain disapp...   \n",
       "473      1.117369e-02  made happy reason discover occasion memory pas...   \n",
       "474      3.346615e-03  PANTOMIME n play story told without violence l...   \n",
       "476      2.649405e-03  men women friendship possible passion enmity w...   \n",
       "479      1.795973e-03                           unwise people love marry   \n",
       "482      1.150792e-02                     wise young say never live long   \n",
       "486      7.545577e-02                                         lie throat   \n",
       "489      1.154901e-01                   lean low abilityI lend something   \n",
       "491      6.000489e-02                                hero without coward   \n",
       "492      2.024165e-02                                    giving vein day   \n",
       "493      8.735159e-01           many things wise man might wish ignorant   \n",
       "496      1.695850e-04  Bigot One obstinately zealously attached opini...   \n",
       "500      8.745351e-04          Truth mighty prevail nothing wrong except   \n",
       "502      9.962045e-04                     Live beliefs turn world around   \n",
       "506      3.926190e-02  brotherhood man mere poet dream depressing hum...   \n",
       "507      2.933446e-06     Day n period twenty four hours mostly misspent   \n",
       "\n",
       "     author_label  author_prediction  \n",
       "1               4                  7  \n",
       "3               7                  5  \n",
       "5               9                  7  \n",
       "10              4                  1  \n",
       "11              3                  5  \n",
       "14              5                  3  \n",
       "18              9                  1  \n",
       "19              7                  0  \n",
       "20              7                  9  \n",
       "23              0                  7  \n",
       "32              4                  7  \n",
       "33              9                  7  \n",
       "34              4                  2  \n",
       "36              3                  7  \n",
       "37              9                  3  \n",
       "40              1                  5  \n",
       "41              5                  1  \n",
       "45              0                  4  \n",
       "46              2                  7  \n",
       "48              4                  5  \n",
       "50              8                  5  \n",
       "51              4                  0  \n",
       "55              0                  9  \n",
       "58              1                  5  \n",
       "59              7                  2  \n",
       "61              2                  4  \n",
       "63              2                  9  \n",
       "65              5                  3  \n",
       "69              2                  7  \n",
       "73              2                  7  \n",
       "..            ...                ...  \n",
       "434             2                  0  \n",
       "437             7                  2  \n",
       "439             9                  7  \n",
       "440             0                  8  \n",
       "441             5                  7  \n",
       "444             5                  6  \n",
       "448             6                  4  \n",
       "449             7                  6  \n",
       "452             8                  5  \n",
       "455             2                  5  \n",
       "457             0                  5  \n",
       "462             4                  6  \n",
       "467             1                  3  \n",
       "468             9                  7  \n",
       "469             1                  0  \n",
       "473             4                  6  \n",
       "474             1                  6  \n",
       "476             6                  2  \n",
       "479             3                  6  \n",
       "482             9                  6  \n",
       "486             9                  5  \n",
       "489             9                  1  \n",
       "491             3                  7  \n",
       "492             9                  7  \n",
       "493             7                  9  \n",
       "496             1                  3  \n",
       "500             5                  3  \n",
       "502             4                  7  \n",
       "506             6                  1  \n",
       "507             1                  5  \n",
       "\n",
       "[201 rows x 13 columns]"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_apredictions[df_apredictions['author_label'] != df_apredictions['author_prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted         prob_bierce  prob_einstein  prob_emerson  prob_mcclellan  \\\n",
      "Actual                                                                       \n",
      "prob_bierce                23              4             4               0   \n",
      "prob_einstein               0             50             6               1   \n",
      "prob_emerson                4              4            53               0   \n",
      "prob_mcclellan              0              0             0              31   \n",
      "prob_nietzsche              0              5             7               0   \n",
      "prob_shakespeare            3              0            12               0   \n",
      "prob_shaw                   2              1             7               0   \n",
      "prob_thoreau                1              1            10               1   \n",
      "prob_twain                  2              2            12               0   \n",
      "prob_wilde                  1              2             5               0   \n",
      "__all__                    36             69           116              33   \n",
      "\n",
      "Predicted         prob_nietzsche  prob_shakespeare  prob_shaw  prob_thoreau  \\\n",
      "Actual                                                                        \n",
      "prob_bierce                    0                 1          2             0   \n",
      "prob_einstein                  1                 1          0             1   \n",
      "prob_emerson                   3                 5          1             4   \n",
      "prob_mcclellan                 0                 0          0             0   \n",
      "prob_nietzsche                15                 1          0             2   \n",
      "prob_shakespeare               2                35          3             1   \n",
      "prob_shaw                      0                 2         16             0   \n",
      "prob_thoreau                   2                 1          1            12   \n",
      "prob_twain                     1                 1          5             1   \n",
      "prob_wilde                     3                 3          2             1   \n",
      "__all__                       27                50         30            22   \n",
      "\n",
      "Predicted         prob_twain  prob_wilde  __all__  \n",
      "Actual                                             \n",
      "prob_bierce                6           3       43  \n",
      "prob_einstein              3           0       63  \n",
      "prob_emerson               4           5       83  \n",
      "prob_mcclellan             2           0       33  \n",
      "prob_nietzsche             5           1       36  \n",
      "prob_shakespeare           6           1       63  \n",
      "prob_shaw                  6           2       36  \n",
      "prob_thoreau               1           2       32  \n",
      "prob_twain                43           5       72  \n",
      "prob_wilde                 1          29       47  \n",
      "__all__                   77          48      508  \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlIAAAIRCAYAAACBE1OxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a744ffdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm2 = ConfusionMatrix(y_test, y_preds, cols)\n",
    "print(cm2)\n",
    "\n",
    "cm2.plot()\n",
    "\n",
    "plt.title('Top 10 Authors Confusion Matrix')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params =  {'rfclf__criterion': 'gini', 'rfclf__max_features': 0.001, 'rfclf__n_estimators': 20, 'vec__lowercase': True, 'vec__max_df': 0.5, 'vec__max_features': None, 'vec__ngram_range': (1, 1)}\n",
      "Best score =  0.431947483589\n",
      "Accuracy score =  0.503937007874\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>estimator_score</th>\n",
       "      <th>logit__multi_class</th>\n",
       "      <th>logit__solver</th>\n",
       "      <th>ml_steps</th>\n",
       "      <th>model</th>\n",
       "      <th>text_description</th>\n",
       "      <th>vec__lowercase</th>\n",
       "      <th>vec__max_df</th>\n",
       "      <th>...</th>\n",
       "      <th>pca__n_components</th>\n",
       "      <th>pca__svd_solver</th>\n",
       "      <th>mnclf__alpha</th>\n",
       "      <th>mnclf__fit_prior</th>\n",
       "      <th>vec__min_df</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>skbest__k</th>\n",
       "      <th>rfclf__criterion</th>\n",
       "      <th>rfclf__max_features</th>\n",
       "      <th>rfclf__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.859020</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cvec, rfclf]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.010</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.872663</td>\n",
       "      <td>scripture</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cvec, rfclf]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.010</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.403501</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.476378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cvec, rfclf]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.414223</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.511811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[vec, rfclf]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.431947</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.503937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[vec, rfclf]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    best_score    dataset  estimator_score logit__multi_class logit__solver  \\\n",
       "45    0.859020  scripture         0.872727                NaN           NaN   \n",
       "46    0.872663  scripture         0.850000                NaN           NaN   \n",
       "47    0.403501    authors         0.476378                NaN           NaN   \n",
       "48    0.414223    authors         0.511811                NaN           NaN   \n",
       "49    0.431947    authors         0.503937                NaN           NaN   \n",
       "\n",
       "         ml_steps                   model text_description  vec__lowercase  \\\n",
       "45  [cvec, rfclf]  RandomForestClassifier     no_stopwords             NaN   \n",
       "46  [cvec, rfclf]  RandomForestClassifier     no_stopwords             NaN   \n",
       "47  [cvec, rfclf]  RandomForestClassifier       lemmatized             NaN   \n",
       "48   [vec, rfclf]  RandomForestClassifier     no_stopwords             1.0   \n",
       "49   [vec, rfclf]  RandomForestClassifier     no_stopwords             1.0   \n",
       "\n",
       "    vec__max_df         ...          pca__n_components pca__svd_solver  \\\n",
       "45          NaN         ...                        NaN             NaN   \n",
       "46          NaN         ...                        NaN             NaN   \n",
       "47          NaN         ...                        NaN             NaN   \n",
       "48          0.5         ...                        NaN             NaN   \n",
       "49          0.5         ...                        NaN             NaN   \n",
       "\n",
       "    mnclf__alpha  mnclf__fit_prior vec__min_df cvec__min_df  skbest__k  \\\n",
       "45           NaN               NaN         NaN          NaN        NaN   \n",
       "46           NaN               NaN         NaN          NaN        NaN   \n",
       "47           NaN               NaN         NaN          NaN        NaN   \n",
       "48           NaN               NaN         NaN          NaN        NaN   \n",
       "49           NaN               NaN         NaN          NaN        NaN   \n",
       "\n",
       "   rfclf__criterion  rfclf__max_features  rfclf__n_estimators  \n",
       "45          entropy                0.010                 15.0  \n",
       "46             gini                0.010                 20.0  \n",
       "47             gini                0.010                 10.0  \n",
       "48             gini                0.005                 15.0  \n",
       "49             gini                0.001                 20.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages_ = [('vec', TfidfVectorizer()), ('rfclf', RandomForestClassifier())] #TfidfVectorizer()\n",
    "    \n",
    "params_ = dict(\n",
    "    vec__max_features=[None, 2000, 5000], \n",
    "    vec__lowercase=[True, False],\n",
    "    vec__max_df=[0.5, 1.0],\n",
    "    #vec__min_df=[0.01, 0.02, 1],\n",
    "    vec__ngram_range=[(1,1),(1,2)],\n",
    "    rfclf__criterion = ['gini', 'entropy'],\n",
    "    rfclf__max_features = [0.001, 0.005],\n",
    "    rfclf__n_estimators = [15, 20]\n",
    ")\n",
    "\n",
    "data_desc = 'no_stopwords'\n",
    "X = df_amodel[data_desc] # lemmatized # 'stemmed','no_stopwords'\n",
    "y = df_amodel['auth_label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "estimator = run_gridsearch_pipeline(stages_, params_, X_train, X_test, y_train, y_test )\n",
    "\n",
    "# store results and params so we have history\n",
    "df_gs_results = store_pipeline_results(estimator,'RandomForestClassifier', \n",
    "                                                 'authors', data_desc, \n",
    "                                                 X_test, y_test, df_gs_results)\n",
    "\n",
    "df_gs_results.to_csv(gridsearch_dir + 'gs_results.csv', encoding='utf-8', index=False)\n",
    "df_gs_results.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>estimator_score</th>\n",
       "      <th>logit__multi_class</th>\n",
       "      <th>logit__solver</th>\n",
       "      <th>ml_steps</th>\n",
       "      <th>model</th>\n",
       "      <th>text_description</th>\n",
       "      <th>vec__lowercase</th>\n",
       "      <th>vec__max_df</th>\n",
       "      <th>...</th>\n",
       "      <th>pca__n_components</th>\n",
       "      <th>pca__svd_solver</th>\n",
       "      <th>mnclf__alpha</th>\n",
       "      <th>mnclf__fit_prior</th>\n",
       "      <th>vec__min_df</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>skbest__k</th>\n",
       "      <th>rfclf__criterion</th>\n",
       "      <th>rfclf__max_features</th>\n",
       "      <th>rfclf__n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.509628</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.598425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['vec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.513567</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.594488</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['vec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.516193</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.590551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['vec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>stemmed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.510503</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.602362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>stemmed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.507440</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.604331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.510722</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.600394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.405470</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.496063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'sfpr', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.428884</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.480315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'skbest', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.480306</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.555118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'skbest', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.492861</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.569882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.487965</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.578740</td>\n",
       "      <td>ovr</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>['cvec', 'logit']</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.403501</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.476378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'rfclf']</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.010</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.414223</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.511811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['vec', 'rfclf']</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.005</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.431947</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.503937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['vec', 'rfclf']</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    best_score  dataset  estimator_score logit__multi_class logit__solver  \\\n",
       "25    0.509628  authors         0.598425                NaN           NaN   \n",
       "26    0.513567  authors         0.594488                NaN           NaN   \n",
       "27    0.516193  authors         0.590551                NaN           NaN   \n",
       "28    0.510503  authors         0.602362                NaN           NaN   \n",
       "29    0.507440  authors         0.604331                NaN           NaN   \n",
       "30    0.510722  authors         0.600394                NaN           NaN   \n",
       "31    0.405470  authors         0.496063                NaN           NaN   \n",
       "32    0.428884  authors         0.480315                NaN           NaN   \n",
       "33    0.480306  authors         0.555118                NaN           NaN   \n",
       "34    0.492861  authors         0.569882                NaN           NaN   \n",
       "35    0.487965  authors         0.578740                ovr     newton-cg   \n",
       "47    0.403501  authors         0.476378                NaN           NaN   \n",
       "48    0.414223  authors         0.511811                NaN           NaN   \n",
       "49    0.431947  authors         0.503937                NaN           NaN   \n",
       "\n",
       "                       ml_steps                   model text_description  \\\n",
       "25             ['vec', 'mnclf']           MultinomialNB     no_stopwords   \n",
       "26             ['vec', 'mnclf']           MultinomialNB       lemmatized   \n",
       "27             ['vec', 'mnclf']           MultinomialNB          stemmed   \n",
       "28            ['cvec', 'mnclf']           MultinomialNB          stemmed   \n",
       "29            ['cvec', 'mnclf']           MultinomialNB     no_stopwords   \n",
       "30            ['cvec', 'mnclf']           MultinomialNB       lemmatized   \n",
       "31    ['cvec', 'sfpr', 'mnclf']           MultinomialNB     no_stopwords   \n",
       "32  ['cvec', 'skbest', 'mnclf']           MultinomialNB     no_stopwords   \n",
       "33  ['cvec', 'skbest', 'mnclf']           MultinomialNB     no_stopwords   \n",
       "34            ['cvec', 'mnclf']           MultinomialNB     no_stopwords   \n",
       "35            ['cvec', 'logit']      LogisticRegression       lemmatized   \n",
       "47            ['cvec', 'rfclf']  RandomForestClassifier       lemmatized   \n",
       "48             ['vec', 'rfclf']  RandomForestClassifier     no_stopwords   \n",
       "49             ['vec', 'rfclf']  RandomForestClassifier     no_stopwords   \n",
       "\n",
       "    vec__lowercase  vec__max_df         ...           pca__n_components  \\\n",
       "25             1.0          0.5         ...                         NaN   \n",
       "26             1.0          0.5         ...                         NaN   \n",
       "27             NaN          0.5         ...                         NaN   \n",
       "28             NaN          NaN         ...                         NaN   \n",
       "29             NaN          NaN         ...                         NaN   \n",
       "30             NaN          NaN         ...                         NaN   \n",
       "31             NaN          NaN         ...                         NaN   \n",
       "32             NaN          NaN         ...                         NaN   \n",
       "33             NaN          NaN         ...                         NaN   \n",
       "34             NaN          NaN         ...                         NaN   \n",
       "35             NaN          NaN         ...                         NaN   \n",
       "47             NaN          NaN         ...                         NaN   \n",
       "48             1.0          0.5         ...                         NaN   \n",
       "49             1.0          0.5         ...                         NaN   \n",
       "\n",
       "   pca__svd_solver  mnclf__alpha  mnclf__fit_prior  vec__min_df cvec__min_df  \\\n",
       "25             NaN           0.1               0.0          1.0          NaN   \n",
       "26             NaN           0.1               0.0          1.0          NaN   \n",
       "27             NaN           0.1               0.0          1.0          NaN   \n",
       "28             NaN           0.2               1.0          NaN          1.0   \n",
       "29             NaN           0.2               1.0          NaN          1.0   \n",
       "30             NaN           0.2               0.0          NaN          1.0   \n",
       "31             NaN           0.1               1.0          NaN          NaN   \n",
       "32             NaN           0.2               1.0          NaN          NaN   \n",
       "33             NaN           0.2               1.0          NaN          NaN   \n",
       "34             NaN           0.5               0.0          NaN          1.0   \n",
       "35             NaN           NaN               NaN          NaN          1.0   \n",
       "47             NaN           NaN               NaN          NaN          NaN   \n",
       "48             NaN           NaN               NaN          NaN          NaN   \n",
       "49             NaN           NaN               NaN          NaN          NaN   \n",
       "\n",
       "    skbest__k rfclf__criterion  rfclf__max_features  rfclf__n_estimators  \n",
       "25        NaN              NaN                  NaN                  NaN  \n",
       "26        NaN              NaN                  NaN                  NaN  \n",
       "27        NaN              NaN                  NaN                  NaN  \n",
       "28        NaN              NaN                  NaN                  NaN  \n",
       "29        NaN              NaN                  NaN                  NaN  \n",
       "30        NaN              NaN                  NaN                  NaN  \n",
       "31        NaN              NaN                  NaN                  NaN  \n",
       "32     2000.0              NaN                  NaN                  NaN  \n",
       "33     7000.0              NaN                  NaN                  NaN  \n",
       "34        NaN              NaN                  NaN                  NaN  \n",
       "35        NaN              NaN                  NaN                  NaN  \n",
       "47        NaN             gini                0.010                 10.0  \n",
       "48        NaN             gini                0.005                 15.0  \n",
       "49        NaN             gini                0.001                 20.0  \n",
       "\n",
       "[14 rows x 26 columns]"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gs_results[df_gs_results[\"dataset\"] == \"authors\"].tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params =  {'cvec__lowercase': True, 'cvec__max_df': 0.5, 'cvec__max_features': None, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'logit__multi_class': 'ovr', 'logit__solver': 'newton-cg'}\n",
      "Best score =  0.487964989059\n",
      "Accuracy score =  0.57874015748\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best_score</th>\n",
       "      <th>dataset</th>\n",
       "      <th>estimator_score</th>\n",
       "      <th>logit__multi_class</th>\n",
       "      <th>logit__solver</th>\n",
       "      <th>ml_steps</th>\n",
       "      <th>model</th>\n",
       "      <th>text_description</th>\n",
       "      <th>vec__lowercase</th>\n",
       "      <th>vec__max_df</th>\n",
       "      <th>...</th>\n",
       "      <th>cvec__max_df</th>\n",
       "      <th>cvec__max_features</th>\n",
       "      <th>cvec__ngram_range</th>\n",
       "      <th>pca__n_components</th>\n",
       "      <th>pca__svd_solver</th>\n",
       "      <th>mnclf__alpha</th>\n",
       "      <th>mnclf__fit_prior</th>\n",
       "      <th>vec__min_df</th>\n",
       "      <th>cvec__min_df</th>\n",
       "      <th>skbest__k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.405470</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.496063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'sfpr', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.428884</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.480315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'skbest', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.480306</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.555118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'skbest', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.492861</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.569882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cvec', 'mnclf']</td>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>no_stopwords</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.487965</td>\n",
       "      <td>authors</td>\n",
       "      <td>0.578740</td>\n",
       "      <td>ovr</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>[cvec, logit]</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>lemmatized</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    best_score  dataset  estimator_score logit__multi_class logit__solver  \\\n",
       "31    0.405470  authors         0.496063                NaN           NaN   \n",
       "32    0.428884  authors         0.480315                NaN           NaN   \n",
       "33    0.480306  authors         0.555118                NaN           NaN   \n",
       "34    0.492861  authors         0.569882                NaN           NaN   \n",
       "35    0.487965  authors         0.578740                ovr     newton-cg   \n",
       "\n",
       "                       ml_steps               model text_description  \\\n",
       "31    ['cvec', 'sfpr', 'mnclf']       MultinomialNB     no_stopwords   \n",
       "32  ['cvec', 'skbest', 'mnclf']       MultinomialNB     no_stopwords   \n",
       "33  ['cvec', 'skbest', 'mnclf']       MultinomialNB     no_stopwords   \n",
       "34            ['cvec', 'mnclf']       MultinomialNB     no_stopwords   \n",
       "35                [cvec, logit]  LogisticRegression       lemmatized   \n",
       "\n",
       "    vec__lowercase  vec__max_df    ...      cvec__max_df cvec__max_features  \\\n",
       "31             NaN          NaN    ...               0.5                NaN   \n",
       "32             NaN          NaN    ...               0.5                NaN   \n",
       "33             NaN          NaN    ...               NaN                NaN   \n",
       "34             NaN          NaN    ...               0.5                NaN   \n",
       "35             NaN          NaN    ...               0.5               None   \n",
       "\n",
       "    cvec__ngram_range  pca__n_components pca__svd_solver mnclf__alpha  \\\n",
       "31             (1, 2)                NaN             NaN          0.1   \n",
       "32             (1, 1)                NaN             NaN          0.2   \n",
       "33             (1, 1)                NaN             NaN          0.2   \n",
       "34             (1, 2)                NaN             NaN          0.5   \n",
       "35             (1, 2)                NaN             NaN          NaN   \n",
       "\n",
       "    mnclf__fit_prior vec__min_df  cvec__min_df  skbest__k  \n",
       "31               1.0         NaN           NaN        NaN  \n",
       "32               1.0         NaN           NaN     2000.0  \n",
       "33               1.0         NaN           NaN     7000.0  \n",
       "34               0.0         NaN           1.0        NaN  \n",
       "35               NaN         NaN           1.0        NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages2_ = [('cvec', CountVectorizer()), # include to remove sparse error\n",
    "            ('logit', LogisticRegression())] # CountVectorizer, TfidfVectorizer\n",
    "    \n",
    "params2_ = dict(\n",
    "    #pca__n_components=[700, 1000],\n",
    "    #pca__svd_solver=['auto', 'arpack'],\n",
    "    cvec__max_features=[None, 1000, 2000], \n",
    "    cvec__lowercase=[True, False],\n",
    "    cvec__max_df=[0.5, 0.7, 1.0],\n",
    "    cvec__min_df=[0.01, 0.02, 1],\n",
    "    cvec__ngram_range=[(1,1),(1,2)],\n",
    "    logit__multi_class= ['ovr', 'multinomial'],\n",
    "    logit__solver= ['newton-cg','lbfgs']\n",
    ")\n",
    "\n",
    "data_desc = 'lemmatized'\n",
    "X = df_amodel[data_desc] # lemmatized # 'stemmed','no_stopwords'\n",
    "y = df_amodel['auth_label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "estimator2 = run_gridsearch_pipeline(stages2_, params2_, X_train, X_test, y_train, y_test )\n",
    "\n",
    "# store results and params so we have history\n",
    "df_gs_results = store_pipeline_results(estimator2,'LogisticRegression', \n",
    "                                                 'authors', data_desc, \n",
    "                                                 X_test, y_test, df_gs_results)\n",
    "\n",
    "df_gs_results.to_csv(gridsearch_dir + 'gs_results.csv', encoding='utf-8', index=False)\n",
    "df_gs_results.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised learning: Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling for All Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102455, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>quote</th>\n",
       "      <th>no_stopwords</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alvar Aalto</td>\n",
       "      <td>Modern architecture does not mean the use of i...</td>\n",
       "      <td>Modern architecture mean use immature new mate...</td>\n",
       "      <td>Modern architecture mean use immature new mate...</td>\n",
       "      <td>modern architectur mean use immatur new materi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alvar Aalto</td>\n",
       "      <td>Building art is a synthesis of life in materia...</td>\n",
       "      <td>Building art synthesis life materialised form ...</td>\n",
       "      <td>Building art synthesis life materialise form t...</td>\n",
       "      <td>build art synthesi life materialis form tri br...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        author                                              quote  \\\n",
       "0  Alvar Aalto  Modern architecture does not mean the use of i...   \n",
       "1  Alvar Aalto  Building art is a synthesis of life in materia...   \n",
       "\n",
       "                                        no_stopwords  \\\n",
       "0  Modern architecture mean use immature new mate...   \n",
       "1  Building art synthesis life materialised form ...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  Modern architecture mean use immature new mate...   \n",
       "1  Building art synthesis life materialise form t...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  modern architectur mean use immatur new materi...  \n",
       "1  build art synthesi life materialis form tri br...  "
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quotes = dataset_dict['quotes']\n",
    "print(df_quotes.shape)\n",
    "df_quotes.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 102442 entries, 0 to 102454\n",
      "Data columns (total 5 columns):\n",
      "author          102442 non-null object\n",
      "quote           102442 non-null object\n",
      "no_stopwords    102442 non-null object\n",
      "lemmatized      102442 non-null object\n",
      "stemmed         102442 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_quotes.dropna(inplace=True)\n",
    "df_quotes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[modern, architecture, mean, use, immature, ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[building, art, synthesis, life, materialise, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[concentrate, work, separate, house, problem, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          lemmatized\n",
       "0  [modern, architecture, mean, use, immature, ne...\n",
       "1  [building, art, synthesis, life, materialise, ...\n",
       "2  [concentrate, work, separate, house, problem, ..."
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc = \"lemmatized\"\n",
    "df_corpus = pd.DataFrame(df_quotes[desc].str.lower()).reset_index(drop=True)\n",
    "df_corpus = pd.DataFrame(df_corpus[desc].str.split()).reset_index(drop=True)\n",
    "df_corpus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.021*\"think\" + 0.020*\"people\" + 0.018*\"go\" + 0.016*\"say\" + 0.016*\"make\"')\n",
      "(1, '0.009*\"new\" + 0.006*\"need\" + 0.006*\"people\" + 0.005*\"high\" + 0.005*\"u\"')\n",
      "(2, '0.010*\"human\" + 0.008*\"without\" + 0.008*\"power\" + 0.007*\"law\" + 0.007*\"must\"')\n",
      "(3, '0.028*\"get\" + 0.022*\"go\" + 0.020*\"play\" + 0.018*\"good\" + 0.018*\"year\"')\n",
      "(4, '0.022*\"one\" + 0.020*\"love\" + 0.018*\"life\" + 0.018*\"man\" + 0.012*\"live\"')\n"
     ]
    }
   ],
   "source": [
    "q_word_lsts = list(df_corpus[desc].values)\n",
    "ldamodel, corpus, dictionary = model_topic(q_word_lsts, num_topics_=5, passes_ = 50, min_proba=.05)\n",
    "_ = [print(i) for i in ldamodel.print_topics(num_topics=5, num_words=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scripture Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2199 entries, 0 to 2198\n",
      "Data columns (total 6 columns):\n",
      "author          2199 non-null object\n",
      "quote           2199 non-null object\n",
      "no_stopwords    2199 non-null object\n",
      "lemmatized      2199 non-null object\n",
      "stemmed         2199 non-null object\n",
      "auth_label      2199 non-null int64\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 103.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_smodel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.021*\"search\" + 0.021*\"write\" + 0.019*\"forehead\" + 0.015*\"one\" + 0.013*\"pride\"')\n",
      "(1, '0.041*\"body\" + 0.041*\"True\" + 0.037*\"mind\" + 0.025*\"Guru\" + 0.024*\"Name\"')\n",
      "(2, '0.040*\"Guru\" + 0.029*\"destiny\" + 0.024*\"True\" + 0.022*\"God\" + 0.022*\"body\"')\n",
      "(3, '0.025*\"Allah\" + 0.018*\"thou\" + 0.017*\"say\" + 0.015*\"good\" + 0.014*\"evil\"')\n",
      "(4, '0.030*\"mind\" + 0.025*\"God\" + 0.024*\"see\" + 0.021*\"body\" + 0.016*\"one\"')\n",
      "(5, '0.032*\"darkness\" + 0.030*\"desire\" + 0.020*\"Guru\" + 0.018*\"Maya\" + 0.018*\"pain\"')\n",
      "(6, '0.026*\"world\" + 0.018*\"poison\" + 0.017*\"u\" + 0.016*\"door\" + 0.015*\"open\"')\n",
      "(7, '0.041*\"shall\" + 0.016*\"land\" + 0.015*\"child\" + 0.015*\"Allah\" + 0.014*\"come\"')\n",
      "(8, '0.041*\"shall\" + 0.018*\"Destiny\" + 0.017*\"egotism\" + 0.016*\"beauty\" + 0.015*\"Siblings\"')\n",
      "(9, '0.037*\"shall\" + 0.024*\"body\" + 0.016*\"upon\" + 0.016*\"like\" + 0.014*\"mind\"')\n"
     ]
    }
   ],
   "source": [
    "df_scorpus = pd.DataFrame(df_smodel[\"lemmatized\"].str.split()).reset_index(drop=True)\n",
    "df_scorpus = df_scorpus[[\"lemmatized\"]]\n",
    "df_scorpus.head()\n",
    "\n",
    "# a list of each quote as a list of words \n",
    "q_sword_lsts = list(df_scorpus.lemmatized.values)\n",
    "q_sword_lsts\n",
    "sldamodel, scorpus, sdictionary = model_topic(q_sword_lsts, num_topics_=10, passes_ = 50, min_proba=.05)\n",
    "_ = [print(i) for i in sldamodel.print_topics(num_topics=10, num_words=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kjrunner/anaconda3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el100801140825905364323713315\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el100801140825905364323713315_data = {\"mdsDat\": {\"Freq\": [12.199331401024152, 10.52347789744334, 8.77756434231395, 7.9268252896598055, 7.4560080879646735, 6.99953098522325, 5.137310941016947, 5.046215072021953, 3.611599286512375, 3.598499069557131, 3.431417221485294, 3.2755235561705494, 3.1120115505519115, 3.0683464472025213, 3.0662789976615117, 2.795034418099613, 2.656017523505252, 2.642170585714275, 2.382011879552995, 2.294825447318501], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"x\": [-0.0200268760384282, -0.19363604443922175, -0.16922444490192273, -0.09574599920061537, -0.10250300754924532, -0.16128388256380155, -0.04769381409434576, -0.05234563750974479, 0.08669697138419202, 0.05833115317287113, -0.011399863461063461, -0.03574425603215968, 0.09349724530609897, 0.09142057655750115, 0.04902122075834706, 0.09331589398040768, 0.13435759397662367, -0.006842061813737384, 0.23606200618269496, 0.05374322628554848], \"y\": [0.22630168380250207, 0.12429578449092973, -0.06633698638465244, 0.047812947331802004, -0.04400506006275629, -0.03419678308766978, -0.035861521564742066, 0.04036318659016893, 0.066495235139419, -0.07982972098709698, -0.10900381389695846, 0.08252550071270492, 0.13296870807456765, -0.01955629202137322, -0.07281528051234692, -0.05614169615432929, -0.026685590085935542, -0.12178655845479391, 0.09200968282309907, -0.14655342575253724]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"Freq\": [196.0, 221.0, 472.0, 308.0, 168.0, 244.0, 167.0, 122.0, 114.0, 112.0, 142.0, 211.0, 174.0, 138.0, 83.0, 140.0, 92.0, 76.0, 50.0, 90.0, 152.0, 89.0, 91.0, 49.0, 67.0, 140.0, 80.0, 124.0, 97.0, 128.0, 111.63126740027019, 48.862680154544336, 45.13152377026858, 28.404000141306003, 28.261164279787494, 20.102671955471298, 18.870858547614333, 17.06781153151282, 15.960968652160751, 14.711289033629255, 14.711205007245411, 13.051023411563119, 12.229851339555392, 11.676429429194705, 11.123007416119309, 9.87332798466332, 9.873327973578332, 9.462741978732886, 181.16820699744963, 9.319906123121703, 9.319906116118633, 8.766484242823022, 8.355898223592602, 8.355898219141277, 8.3558944249336, 8.213062367676384, 8.213062364760722, 7.8024763305179565, 7.659640481092031, 7.6596404775981615, 11.780172058076289, 19.230320903872485, 19.746952838417013, 11.134868265967237, 50.98992744676988, 14.859200488925085, 20.648664200851375, 19.42203050150956, 42.58508141862601, 27.83387854485395, 21.499821561216756, 17.80774888953833, 62.82273055418556, 53.74800889248513, 44.51802257719565, 58.18337568259003, 27.283808495220853, 37.31861236159557, 37.76362902227857, 57.88186806132909, 85.08149587268083, 52.79657173675249, 24.5448052800359, 34.60072054495345, 23.76196595792674, 22.45937960054303, 21.835195230393783, 19.871373409204132, 47.04377052157112, 41.6321290270721, 34.51406282369686, 22.680450381701657, 20.951484100627102, 20.771824960126885, 18.683540369777695, 17.80778636720406, 15.899160937194193, 13.990534334640252, 11.206156025701826, 11.02649690961802, 10.330402027062881, 10.330402003804549, 10.330401963825, 9.813966315600128, 9.634307190779136, 9.634307189423918, 9.743343020793137, 8.938212328788785, 8.93821230526283, 8.938212299515715, 8.938212302217227, 8.421776618822188, 8.242117467710727, 8.242117460819799, 8.242117460819799, 8.242117460819799, 7.7256817515664045, 7.029586897332596, 30.20410638634772, 36.69132365157298, 14.836763962382165, 25.513351106750168, 78.97786248297626, 75.41187712720038, 82.50384128168935, 24.705826054276972, 15.790650123478693, 60.264754363173004, 61.93629367979371, 32.26756692622104, 129.22317691254293, 23.094118495204444, 18.313222121101298, 27.884469099938702, 42.17129244334812, 16.924573425733016, 40.3081699965572, 56.75615347056521, 32.44626361022444, 29.82408969522896, 36.44376415916183, 26.83206196678821, 23.196025738445616, 20.751248043898578, 25.757691761227196, 20.398881443258016, 21.038106440983707, 22.47780688016707, 19.64946125618993, 17.999646674921642, 17.656777867621294, 16.992550070213078, 16.32832226574906, 15.835528870294178, 11.18593425365984, 10.693140680675471, 10.521706463468888, 11.264359469140777, 10.028908704735228, 9.85747866338642, 9.857478650828838, 9.857478622573563, 9.193250838774526, 9.19325083103152, 9.193250803378938, 8.529023062306356, 8.529023061326889, 8.52902304914048, 8.529023049077413, 8.529023028900129, 8.529023020607593, 7.864795258795483, 7.8647952287016825, 7.371999305803933, 13.112408154726824, 6.707773974379641, 6.043546249097485, 10.693140849223012, 48.26003121204379, 39.58127815387902, 37.23153978710476, 57.01386150706299, 38.439649924422305, 34.68027114267777, 49.5529758603521, 12.556031023495475, 22.380618271262744, 35.74936844381073, 56.071659036779614, 18.79268935633848, 17.784707553942113, 57.85334697147496, 30.03517576583133, 33.159965988540705, 12.726382699344116, 22.149065038738815, 18.84869527895213, 19.612169032182543, 20.598710352984344, 28.461776415858154, 24.935615965950976, 35.641703818070525, 26.546026232245886, 27.602389710699047, 22.038648887762044, 20.94928999645773, 37.952105621117006, 19.40930877888127, 18.785407377045136, 16.590850966663837, 13.007162902262408, 12.383034050962124, 11.758894186542513, 10.510647505429318, 10.510647505081627, 9.423474839217912, 9.423474834152037, 9.262389803896447, 8.79934599210324, 8.638260956762107, 8.638260950774468, 8.638260944833872, 8.175217129176158, 8.014132107645322, 8.014132109374845, 8.014132107854206, 8.014132107845215, 8.014132106394324, 8.01413209356438, 8.014132093868108, 8.014132094824385, 8.014132064884624, 103.66794668662385, 7.390003264909896, 7.390003263315422, 7.390003263315422, 14.255420599139452, 9.35488419363678, 20.413716282407005, 18.629477095212778, 14.731170121764992, 11.18789836316636, 18.457878408325254, 23.174848963650984, 9.898101201738553, 16.68744280992845, 23.037516851146314, 15.966722121966125, 40.04054269054939, 18.938021818184026, 21.700901479923605, 17.36346824489062, 23.213574209232554, 22.445817536694356, 12.662758472012257, 22.57748073989052, 40.137337661498385, 20.54722962832931, 18.397828165495515, 19.690975051665028, 17.9991393153373, 15.961933503356272, 12.947172196144281, 13.197009415681007, 19.131538658376392, 19.131538645740644, 17.8803922232259, 15.37809932510278, 11.786117852814133, 11.160544635368801, 11.160544633122997, 9.90939819134574, 9.28382497762231, 9.2838249658096, 8.658251760597333, 8.658251740706474, 8.032678542403183, 8.032678535002391, 7.4071053260543005, 7.4071053260543005, 7.407105324566476, 7.407105324566476, 7.407105319301414, 7.407091099335327, 7.407091099335327, 7.407091099335327, 7.407091099335327, 7.407091099335327, 7.407091099335327, 6.942989905993265, 9.42386597509219, 6.3174166983315105, 5.06627026175051, 43.424999345233, 8.15257509737281, 69.42953961640688, 49.80204747680949, 16.73532893016442, 45.57901246096638, 23.944341238892203, 40.95686058213394, 46.52670705636527, 18.33604819005993, 22.896612326645947, 34.12239984846113, 13.632585574554668, 51.15834981839611, 12.385434619077602, 29.454466091852595, 12.192987262253693, 25.465119166172805, 30.575239092932897, 18.890917722069066, 24.204052046086364, 14.152332815712416, 16.324727560557207, 27.08135370351967, 17.061520826369414, 12.583760248102719, 12.424633309243704, 50.605791540621766, 18.406607673485755, 16.47465662298926, 12.132980339504346, 11.655206129699835, 11.488996637697468, 10.845012977194502, 21.58606597082471, 8.913061931376776, 8.435287723735017, 8.435287727880365, 8.43528723265019, 8.269078256278087, 8.269078247388242, 8.269078237188527, 8.269078209093145, 7.625094575240434, 7.625094575112984, 7.625094524812195, 7.625094524812195, 6.503335722858515, 5.212871950378699, 12.480678973047517, 4.5713856186366995, 4.571368469379622, 7.620255944025893, 22.7482839617289, 4.554975851642691, 9.608959476503033, 41.741241118238484, 22.825626923094998, 18.570572919385476, 18.705583533859695, 15.186689270435432, 30.334458389612333, 25.423672514961005, 16.795136589089804, 39.34912785830471, 10.151350271382958, 46.20233661314513, 26.45606393247882, 16.485067124258936, 31.63114399527895, 29.62363541834507, 18.74463276100775, 54.577901750339464, 21.196515166783556, 15.46044540570637, 20.019671389230062, 16.015292817702477, 20.06256546139079, 15.323891677647817, 13.654055719495872, 18.041924068401574, 16.943400888628965, 13.76059270898305, 24.787461352915727, 18.756976749480888, 12.35365531558804, 11.851114961493176, 9.970656930447094, 8.96557622004508, 7.960495457492226, 7.960495457069039, 7.960495454289524, 7.457955074249914, 12.974078227869514, 6.955414692816679, 6.955414689654948, 6.955414676952882, 6.9554146480257515, 6.582577859039345, 6.452874309995404, 6.452874309899181, 6.452874308886104, 6.452874287743718, 5.950333927891917, 5.950333927891917, 5.950333927195246, 5.95033392398318, 8.073056994796177, 20.263589583275017, 3.5673355673963334, 3.5673355644046185, 16.967197071320076, 2.5622548038367365, 8.551253615647674, 29.54892819107883, 14.619325212385315, 23.2834708675322, 25.25695348987443, 26.53421421099018, 17.429788461047284, 32.692213024904184, 23.164904688321883, 15.166296463247818, 10.267521998603616, 10.74555745501308, 19.164517939871956, 27.69008168980708, 9.898100701914077, 20.676063982892174, 19.814361978792142, 17.599092235811323, 11.831781100761773, 11.388444620626483, 10.938655006901461, 10.86116043283266, 14.155586003621503, 12.663503948689028, 10.426404440511853, 19.92056323541166, 19.833897027895723, 13.540537003812469, 12.868955288662445, 12.197373579531055, 9.261922102804377, 8.590340392531637, 8.254549536997786, 7.669634026584621, 6.326470612416777, 6.32647060819987, 5.990679760149639, 5.65488890575934, 5.319098053396694, 5.319098046436291, 5.319098045341202, 4.9833071980687675, 4.98330719819562, 4.983307197651473, 4.983307195233391, 4.983307188400423, 4.647516329475529, 4.647516312261485, 4.311725490721328, 4.311725489707295, 4.311725488376876, 4.311725481835778, 4.311725476000592, 4.311725454969171, 4.062600841489227, 23.231707807291837, 17.140773578704316, 17.51232586896544, 19.734544818521247, 15.495917502283833, 14.06935522229597, 26.091498631544802, 8.49607346657032, 43.36388094930749, 23.897937009312002, 8.981456169663675, 8.466253314864444, 74.68541313016391, 89.42248727108043, 15.18189097948224, 9.142340268844348, 16.002143636234965, 11.941349246854623, 16.33646737786734, 26.87645642596383, 21.00321734105778, 18.542419410764154, 24.35183114696037, 18.970355971448512, 10.711844729028158, 12.104899660747794, 11.867178054208233, 10.878370743808084, 11.837043481475016, 11.114958155954595, 21.405126791106493, 16.174616954231823, 10.345780971716568, 9.747454830511671, 7.952476397688119, 7.65331330169884, 7.354150244253155, 7.054987182788217, 6.533873762923254, 5.935547621112588, 5.636384544233329, 5.337207575797776, 5.038058396660389, 4.738895335278447, 4.73889533325066, 4.439732263031827, 4.439732258201173, 4.439732253817403, 4.439732255800759, 4.140569174470497, 3.8414061203660554, 3.841406119585666, 3.841406118389475, 3.8414061183165678, 3.8414061191263067, 3.8414061161881503, 3.8414061111065356, 3.542243048347167, 3.542243048347167, 3.5422430482439045, 3.5422430482439045, 3.5422430482439045, 11.93826497181842, 46.78025743115175, 13.382704354961751, 6.516120382322721, 6.6326630008181535, 7.9067954098751345, 8.543424392767033, 16.466454167597405, 12.412961292736439, 13.401663679661453, 52.79410468701252, 29.642872829535385, 26.863733224044164, 9.077902810691944, 12.5008812853849, 12.230830723112732, 15.779715562070512, 13.933067620662014, 20.55253943601977, 14.211388457610557, 18.74206745930625, 12.35666500617552, 8.900244133790068, 13.009415370103298, 11.23318784211395, 9.266076345443905, 8.076031197418029, 17.928463466530772, 17.212273468366828, 12.649461323890852, 10.95140913987473, 9.969546973582238, 9.519028967514389, 9.253356976330977, 8.444744179643934, 6.388597004945253, 6.0305020115516985, 5.314312020495872, 4.956217015062213, 4.956217001893842, 4.598122028638669, 4.59812202764054, 4.598122027794896, 4.598122021244565, 4.598122017422834, 4.240027032127135, 4.240027032042236, 4.240027031908033, 4.240027031908033, 4.2400270287167485, 4.240027024183102, 6.654661293512944, 16.837077608086148, 2.5419748577963093, 20.435128436833335, 6.347138823087701, 1.8257848666260061, 9.481483849659499, 28.734398858478972, 26.470721992714818, 28.68165245516511, 12.935496791660308, 21.455266796914678, 13.004691955721025, 18.73309924227258, 21.323695116204224, 34.71021785150621, 14.357599960077295, 14.767846017645367, 8.917215983043846, 14.86088768821447, 9.599447855765652, 11.667769024137446, 13.337546044135706, 12.253265872998337, 8.57346396565159, 6.989019041365943, 29.294749579619825, 20.889722808648138, 16.31640526769873, 7.169770834430061, 6.744025343365801, 6.318279845852175, 6.31827984531182, 6.318279828660998, 5.892534354879267, 5.466788860066116, 5.466788854365652, 5.041043364791186, 5.041043365223164, 5.041043362442595, 5.041043362442595, 5.041043363475371, 5.041043324119104, 3.3820717463773944, 1.7449625259504906, 1.7449625259806463, 1.744962523808753, 9.321257282507894, 1.3192170316551948, 1.3192170312209428, 1.319217030147818, 2.1707080215820582, 7.296926767732295, 12.833749786224226, 1.7448874978961093, 2.945053990286053, 10.040106187973652, 16.17608190635804, 14.498508630774635, 10.986309536065638, 8.346503566184447, 9.80723205512258, 5.660535479970116, 5.041043364436472, 8.2959647504325, 26.713661489888885, 18.71080236728459, 13.862174583449958, 10.465851673826675, 40.638575736619664, 8.534859479732042, 7.861537727096298, 15.973939761449813, 10.719199981340793, 11.821760718500217, 11.608058525315954, 7.419831609481622, 7.981534013818199, 7.530635920410796, 7.036331558894564, 6.9662036876513715, 28.5966747778353, 18.797879540927035, 11.843535100821292, 9.918389785234417, 9.583109844692638, 9.24782987137127, 8.912549956412127, 8.577270017550687, 8.24199007633568, 8.24199007426245, 6.987404650916658, 5.311004926849135, 4.975724999139269, 4.975724999006563, 4.640445057186489, 4.6404450571526725, 4.640445056893277, 4.640445056955508, 4.305165115665259, 4.305165114610748, 4.305165094630574, 4.305165080973542, 3.969885173831388, 3.969885173831388, 3.9698851737629464, 3.9698851737629464, 3.969885173746284, 3.969885173620245, 3.969885173620245, 3.9698851735629233, 41.076987553139205, 5.878212072873509, 64.94521043996548, 9.795546215126475, 6.552218592529718, 13.026406157656861, 7.42147071975636, 14.24554736427604, 18.932287386684106, 13.135187819021834, 5.646279541352613, 26.467846448207567, 12.42437544720815, 11.537369536961517, 8.241990065568551, 5.646267327143557, 6.19636228905635, 7.81208744702258, 6.0413664314999185, 5.973437247106998, 5.78474966170503, 27.4912586046749, 14.583637342705149, 13.484358977303298, 11.90637120936365, 11.906371206387817, 10.878022622078332, 10.532273251959946, 9.70747105608841, 8.404644446806678, 8.12982671031586, 7.030548343023677, 7.0305483410934615, 6.755728751144127, 6.755728739863542, 6.755728738229806, 6.277019348937655, 6.277019348968102, 4.628101800529318, 4.6281017991333435, 4.3532822085875935, 4.353282206049862, 4.07846261912279, 3.803643027980996, 3.8036430271928223, 3.803643002900722, 3.52882343728713, 3.528823433535285, 3.5288234321294665, 3.254003846028321, 3.2540038460074685, 10.807092821987553, 20.112677912500825, 11.655389843632758, 7.854957459054767, 8.126237658661644, 35.214487938450716, 22.59001006716365, 15.745495987278764, 10.433601617923719, 7.545165885886459, 9.52605894336371, 16.891642633318433, 15.524114892827715, 18.459682052016035, 10.794941248210622, 10.559341778503999, 8.817503681410525, 9.475702330124527, 7.810644338496657, 28.64820233313985, 19.333146852185326, 7.92989600501022, 7.631582373559279, 7.333268755188091, 7.333268752528367, 7.034955136561519, 13.941295680978847, 6.515321378113324, 4.7254396392535725, 4.42712601686269, 4.427126014498886, 4.427126012451136, 19.438357626515536, 4.128812386869589, 4.128812386125386, 3.830498769915263, 3.8304987698779946, 3.8304987686012995, 3.8304987619809623, 3.5321851463822496, 3.5321851460924734, 3.532185146036652, 3.532185145920155, 3.532185145837791, 3.532185145837791, 3.532185145837791, 3.532185145837791, 3.5321851392475634, 3.5321851392475634, 15.011403134151175, 8.526523257412169, 14.425308742140475, 9.179199491208205, 6.47239571271882, 22.06866044484714, 7.826587665816934, 7.034955138142779, 21.762876256622295, 21.728377647257048, 8.333053139215425, 29.538228884318087, 6.443877757491286, 24.877647723315235, 19.685317432214987, 7.746173604030207, 15.267722674849228, 8.707351177513976, 5.426752131823274, 10.51116934777387, 7.9144711413626805, 8.255143141492272, 8.404307716395323, 7.065634259672183, 15.47863572755535, 11.480291608535586, 11.15988139803503, 6.841126917990316, 6.409251467173974, 5.977376025982733, 5.97737602180956, 5.977376016231136, 5.977376002867635, 5.545500578764323, 5.545500570960019, 5.545500571634161, 5.225090350772607, 5.113625131317343, 5.113625131068172, 5.1136251306819105, 5.1136251306819105, 5.113625129761236, 5.113625128759107, 5.113625128759107, 5.113625128809751, 5.113625128809751, 21.76411273770169, 14.013737063029762, 2.200346300620281, 14.533592547356237, 1.7681864130809994, 8.080326446740711, 2.5793162808630665, 1.3382113334443595, 8.55656100454912, 37.978428868297236, 23.85137318148449, 11.048416152865409, 16.119456316989165, 20.008499935869406, 41.78581935089097, 6.409250720470352, 8.641426659245203, 12.420366169215145, 6.414891598304874, 6.1983524664568534, 7.713367584325284, 10.314239973106133, 7.45129489114103, 7.384641130388492, 6.080198560465725, 6.501759237822006, 6.076980349341454, 5.981090337462445, 5.977376026441505, 21.95407676272407, 11.759254409125067, 11.759254404330541, 8.46325873512302, 8.156423407183683, 7.849588085132101, 7.542752760242299, 6.087769037673947, 5.7809337120622635, 5.780933710223663, 4.246757084904782, 4.2467570803003385, 4.246757077250581, 3.9399217595805553, 3.9399217580364065, 3.633086435417357, 3.633086435417357, 3.633086435417357, 3.633086435244345, 3.633086435244345, 3.633086435244345, 3.633086435244345, 3.633086435244345, 3.6330864351647243, 3.6330864351647243, 3.6330864344366893, 3.6330864344366893, 3.6330864344366893, 3.6330864344366893, 6.358963200320946, 7.3151103409348375, 10.706952666727709, 7.236071313228337, 14.48292484885886, 8.647016366687307, 9.611759923164211, 13.758803402970901, 9.878453023471177, 50.159457967874665, 11.92027847291153, 21.879233047512834, 7.83816837688205, 25.857913980130842, 6.44087979041483, 24.7386542064693, 9.117165774013294, 8.123020806102826, 6.239521685075551, 9.628394647956346, 7.520262387948354, 6.900896752410078, 6.87219138687826, 6.473325856604338, 24.68872001338231, 21.626788325588166, 15.107488945484603, 11.416941155651747, 11.416941156784144, 9.297922024496241, 9.06317700544508, 8.436125809457737, 8.355004819545687, 7.726393361419429, 7.726393354030044, 6.550291426827491, 6.235985694315463, 5.921679962424254, 5.60737423206577, 5.607374230758052, 5.293068500619454, 5.293068496121868, 4.978762767910013, 4.9787627639592715, 4.97876276267308, 4.664457038508017, 4.664457036329254, 4.664457017975889, 4.350151300623073, 4.3501513003288625, 4.350151292849705, 4.035845574104076, 4.035845558267139, 3.721539844400701, 11.416941140700313, 12.002336429206224, 24.131599670098144, 6.86459715442909, 21.1268578023216, 21.093222150965673, 17.260187005152538, 8.809367442632034, 11.843328208591393, 6.741085727139906, 9.699651070588724, 7.784044300829127, 7.9875575179815295, 7.088408856379094, 7.525835580882331, 6.512470233490848, 49.19394593786237, 26.543889696321543, 17.779212740586434, 9.091260140459854, 8.199447573093666, 7.604905864732616, 7.307635002031893, 6.492546795946396, 5.89793751455037, 5.303463376152217, 5.303463371244616, 4.708921663291537, 4.114379945961947, 4.114379940210939, 3.8171090987558176, 3.8171090987106586, 3.81710909824605, 3.817109095907343, 3.817109094226406, 3.8171090899989397, 3.8171090918965653, 3.817109085031936, 3.817109082508676, 3.5198382431301627, 3.5198382431301627, 3.5198382431301627, 3.519838243120438, 3.519838242810128, 3.519838242666675, 3.519838242666675, 20.31159068699785, 6.90229074005283, 8.817367741548198, 14.221115633957064, 13.438822304468081, 9.028491395470107, 8.036818160182387, 15.736845091851098, 10.001200383085909, 5.863750532046009, 7.438262408106158, 8.568680201756093, 6.024012870922325, 5.193904740251797, 5.3954295822974485, 4.412161923395859, 4.875184618023607, 4.690485289291532, 4.598528053879788, 8.280423243350118, 8.280423240181609, 7.6322376685026905, 7.039816747391874, 5.095260024033972, 5.095260023444078, 4.286777245265935, 7.466689314194576, 8.721945712259236, 20.50165422569489, 3.422529810945673, 3.2064679534753258, 3.2064679458403607, 2.9904060958298446, 2.9904060949194893, 2.9904060940465267, 2.990406093014385, 2.9904060876152574, 2.990406064372402, 24.31484489036376, 2.774344237852691, 2.774344237518648, 2.7743442347899663, 2.7743442304466543, 2.774344229674848, 2.774344227559053, 2.5582823800424532, 2.5582823799654366, 2.5582823799654366, 2.558282379962699, 2.558282379962699, 3.4174842076977763, 6.146503703310982, 7.577447798356638, 37.32845649537339, 39.496332805019776, 5.558983924378855, 12.205466065898575, 11.032378485639056, 20.902339555688602, 5.743438614652011, 8.092277036984909, 13.063060260608541, 5.095260024505994, 9.06895971765504, 9.448201998199169, 9.553712509743411, 10.001727295906731, 7.099443693118076, 6.76964438204621, 5.516489680913988, 12.818272181755894, 12.563480384296179, 12.474842671892187, 8.44232621686905, 7.157245873870996, 6.47038684316356, 5.783527819492247, 5.783527818718681, 5.440098294170396, 5.09666878230927, 4.40980976511275, 4.409809764927649, 4.409809765018686, 4.409809764977545, 4.409809754091804, 4.066380251509997, 4.066380251509997, 4.066380251427679, 4.066380251156893, 4.066380251156893, 4.066380250980625, 4.066380242817236, 2.4378703923546703, 20.81116139945805, 11.037850729207042, 7.682782519307364, 9.549499345915919, 15.807901615246172, 1.0641523382993927, 4.066380252842087, 23.38707075840582, 31.304350704722207, 6.527915034411797, 9.765084883686217, 14.34210908280845, 11.811165032952076, 5.096668792133165, 5.592357202257111, 5.7276008779259415, 4.409809778774025, 4.7262675138838715, 5.309394637459143, 5.294070293714448, 5.665048079939516, 4.898381311770461, 4.6672659348208425, 4.695676363382532], \"Term\": [\"Allah\", \"mind\", \"shall\", \"body\", \"Guru\", \"God\", \"True\", \"desire\", \"child\", \"destiny\", \"make\", \"one\", \"say\", \"evil\", \"darkness\", \"give\", \"u\", \"Name\", \"consciousness\", \"within\", \"upon\", \"thou\", \"world\", \"anger\", \"love\", \"good\", \"heart\", \"man\", \"see\", \"soul\", \"destiny\", \"pre\", \"ordain\", \"perfect\", \"bestow\", \"trick\", \"punishment\", \"near\", \"Merciful\", \"condition\", \"Hands\", \"emancipate\", \"Apostle\", \"unjust\", \"communication\", \"feel\", \"virtue\", \"disbelieve\", \"Allah\", \"virtuous\", \"accept\", \"secure\", \"Forgiving\", \"reject\", \"painful\", \"Serve\", \"Boat\", \"guide\", \"vanish\", \"anywhere\", \"Holy\", \"Surely\", \"fill\", \"account\", \"meet\", \"hereafter\", \"else\", \"alone\", \"surely\", \"whose\", \"reward\", \"doubt\", \"evil\", \"give\", \"know\", \"True\", \"obtain\", \"people\", \"One\", \"one\", \"shall\", \"body\", \"believe\", \"Guru\", \"good\", \"soul\", \"desire\", \"heart\", \"write\", \"forehead\", \"do\", \"wall\", \"Father\", \"praise\", \"taste\", \"steal\", \"commit\", \"Son\", \"angel\", \"preserve\", \"care\", \"merchandise\", \"pilgrimage\", \"indeed\", \"gossip\", \"insipid\", \"rejoice\", \"bland\", \"blow\", \"difficult\", \"lowly\", \"wrath\", \"opportunity\", \"Salt\", \"mason\", \"temporary\", \"forbid\", \"inherit\", \"others\", \"deed\", \"reveal\", \"law\", \"good\", \"evil\", \"say\", \"hear\", \"deliver\", \"make\", \"upon\", \"heaven\", \"shall\", \"servant\", \"guard\", \"call\", \"man\", \"name\", \"soul\", \"God\", \"thing\", \"men\", \"come\", \"know\", \"Nanak\", \"hath\", \"one\", \"truth\", \"thou\", \"wife\", \"oil\", \"Jerusalem\", \"store\", \"cherish\", \"source\", \"whole\", \"trouble\", \"Abraham\", \"black\", \"honour\", \"field\", \"wither\", \"Kind\", \"possession\", \"furnace\", \"outside\", \"dear\", \"ghost\", \"fade\", \"Compassionate\", \"test\", \"Another\", \"brilliant\", \"scent\", \"finally\", \"David\", \"husband\", \"Babylon\", \"slew\", \"joy\", \"son\", \"house\", \"depart\", \"day\", \"also\", \"king\", \"bring\", \"beast\", \"forth\", \"dwell\", \"upon\", \"offer\", \"behold\", \"say\", \"father\", \"land\", \"year\", \"leave\", \"city\", \"home\", \"mother\", \"man\", \"men\", \"body\", \"go\", \"come\", \"u\", \"people\", \"selfishness\", \"three\", \"accord\", \"ignorant\", \"twenty\", \"Great\", \"weep\", \"perform\", \"eight\", \"tribe\", \"obey\", \"utter\", \"inheritance\", \"key\", \"pitch\", \"apply\", \"gate\", \"Keep\", \"Listen\", \"extinguish\", \"dreadful\", \"slip\", \"inclination\", \"Telling\", \"mix\", \"supply\", \"child\", \"eradicate\", \"abolish\", \"illness\", \"book\", \"lot\", \"five\", \"hundred\", \"ear\", \"Book\", \"door\", \"woman\", \"border\", \"foot\", \"eye\", \"sweet\", \"go\", \"lie\", \"truth\", \"city\", \"find\", \"place\", \"ten\", \"men\", \"shall\", \"within\", \"world\", \"come\", \"soul\", \"God\", \"peace\", \"land\", \"adorn\", \"watch\", \"ruby\", \"thirsty\", \"run\", \"direction\", \"discipline\", \"wild\", \"state\", \"waver\", \"sensual\", \"death\", \"naturally\", \"task\", \"intensive\", \"Someone\", \"relation\", \"repeat\", \"center\", \"diamond\", \"emerald\", \"gesture\", \"mosaic\", \"floor\", \"encase\", \"thank\", \"Joseph\", \"appear\", \"lip\", \"let\", \"Pharaoh\", \"u\", \"may\", \"flesh\", \"heart\", \"faith\", \"life\", \"man\", \"face\", \"hath\", \"thing\", \"family\", \"God\", \"put\", \"come\", \"cast\", \"say\", \"body\", \"see\", \"mind\", \"time\", \"father\", \"shall\", \"give\", \"understand\", \"every\", \"two\", \"produce\", \"record\", \"hour\", \"country\", \"bird\", \"stick\", \"friend\", \"clay\", \"overlay\", \"Jacob\", \"fight\", \"ninth\", \"Tell\", \"Primal\", \"hearth\", \"Filth\", \"Twenty\", \"limb\", \"Asleep\", \"horn\", \"inhabitant\", \"high\", \"abundance\", \"wherein\", \"sword\", \"awareness\", \"doth\", \"Behold\", \"night\", \"together\", \"kingdom\", \"return\", \"Home\", \"gold\", \"among\", \"destroy\", \"thou\", \"mountain\", \"make\", \"heaven\", \"four\", \"land\", \"thing\", \"brother\", \"shall\", \"without\", \"thereof\", \"dwell\", \"earth\", \"day\", \"sin\", \"shalt\", \"body\", \"one\", \"create\", \"false\", \"emotional\", \"cool\", \"cold\", \"moon\", \"happiness\", \"affect\", \"Baba\", \"desert\", \"bath\", \"tree\", \"handle\", \"mingle\", \"universe\", \"energy\", \"l\", \"fly\", \"Many\", \"Water\", \"something\", \"shore\", \"Attachment\", \"charm\", \"Eating\", \"manifest\", \"neither\", \"parable\", \"flame\", \"head\", \"purify\", \"must\", \"attachment\", \"rain\", \"pleasure\", \"turn\", \"enter\", \"ocean\", \"fire\", \"many\", \"food\", \"wash\", \"sun\", \"corruption\", \"darkness\", \"sign\", \"away\", \"see\", \"take\", \"way\", \"earth\", \"time\", \"king\", \"shall\", \"one\", \"water\", \"hold\", \"pride\", \"empty\", \"hop\", \"everyone\", \"companion\", \"wear\", \"suck\", \"deceit\", \"wickedness\", \"issue\", \"delight\", \"corn\", \"protect\", \"sinful\", \"heap\", \"pervade\", \"cave\", \"reincarnation\", \"entice\", \"filth\", \"steady\", \"cruel\", \"Show\", \"rot\", \"emerge\", \"tongs\", \"tax\", \"unstable\", \"unclean\", \"dust\", \"poison\", \"work\", \"clothe\", \"never\", \"right\", \"eat\", \"fool\", \"see\", \"speak\", \"behind\", \"mouth\", \"body\", \"shall\", \"long\", \"walk\", \"burn\", \"wealth\", \"hand\", \"mind\", \"soul\", \"One\", \"one\", \"go\", \"pure\", \"water\", \"love\", \"leave\", \"give\", \"bring\", \"conceit\", \"satisfy\", \"look\", \"astray\", \"bliss\", \"join\", \"elephant\", \"stable\", \"forty\", \"raise\", \"Almighty\", \"palace\", \"dog\", \"victory\", \"seventy\", \"point\", \"single\", \"Court\", \"Everything\", \"deserve\", \"collect\", \"satisfaction\", \"bother\", \"Darling\", \"blacken\", \"fort\", \"pierce\", \"huge\", \"puff\", \"Empire\", \"Authority\", \"Seat\", \"might\", \"Name\", \"forget\", \"throne\", \"smoke\", \"could\", \"sacrifice\", \"would\", \"forever\", \"serve\", \"True\", \"world\", \"Nanak\", \"Beloved\", \"peace\", \"time\", \"away\", \"without\", \"one\", \"life\", \"mind\", \"become\", \"ever\", \"upon\", \"go\", \"enter\", \"tell\", \"Friend\", \"contentment\", \"Best\", \"worship\", \"young\", \"poise\", \"gift\", \"survive\", \"Infinite\", \"Everyone\", \"since\", \"enjoyment\", \"detach\", \"influence\", \"Pleasure\", \"Companion\", \"Forever\", \"entangle\", \"mental\", \"Sublime\", \"decrease\", \"adore\", \"entanglement\", \"Truthfulness\", \"blame\", \"Fear\", \"appearance\", \"suffer\", \"star\", \"Timothy\", \"chant\", \"Without\", \"fear\", \"pain\", \"would\", \"even\", \"long\", \"like\", \"One\", \"God\", \"mother\", \"without\", \"power\", \"darkness\", \"prayer\", \"father\", \"Guru\", \"come\", \"desire\", \"True\", \"search\", \"pollute\", \"separation\", \"across\", \"weakness\", \"path\", \"merchant\", \"heavenly\", \"arrow\", \"idiotic\", \"intoxicate\", \"confuse\", \"Arising\", \"sixty\", \"handsome\", \"Flavor\", \"stain\", \"shame\", \"merciful\", \"slow\", \"Arioch\", \"carry\", \"sowest\", \"sharp\", \"wast\", \"glorify\", \"wicked\", \"youth\", \"multitude\", \"spirit\", \"union\", \"shalt\", \"age\", \"lose\", \"old\", \"well\", \"garment\", \"cure\", \"cry\", \"thou\", \"pain\", \"understand\", \"sweet\", \"body\", \"blood\", \"around\", \"mind\", \"Nanak\", \"come\", \"God\", \"tongue\", \"without\", \"love\", \"good\", \"know\", \"sexual\", \"low\", \"Sexual\", \"unite\", \"flower\", \"thirst\", \"lotus\", \"Wealth\", \"quench\", \"lily\", \"forsake\", \"Please\", \"Seek\", \"overflow\", \"counterfeit\", \"swan\", \"worry\", \"seduce\", \"Treasury\", \"Faith\", \"illumine\", \"acquire\", \"arrogance\", \"excessive\", \"Renounce\", \"eliminate\", \"compel\", \"Coming\", \"diffuse\", \"Touchstone\", \"anger\", \"increase\", \"desire\", \"try\", \"draw\", \"age\", \"drink\", \"burn\", \"place\", \"fire\", \"wine\", \"shall\", \"Nanak\", \"world\", \"beauty\", \"throughout\", \"fall\", \"upon\", \"save\", \"eye\", \"love\", \"Grace\", \"Power\", \"Glance\", \"Vision\", \"Creator\", \"Blessed\", \"Creative\", \"terrify\", \"kind\", \"Darshan\", \"sanctify\", \"class\", \"animal\", \"genuine\", \"sacred\", \"use\", \"sake\", \"Universe\", \"Praises\", \"contemplate\", \"glorious\", \"subject\", \"harvest\", \"None\", \"emperor\", \"owe\", \"shrine\", \"unlucky\", \"Body\", \"entertain\", \"Teachings\", \"seek\", \"think\", \"be\", \"still\", \"Guru\", \"world\", \"great\", \"ocean\", \"plant\", \"enjoy\", \"give\", \"soul\", \"God\", \"die\", \"create\", \"call\", \"good\", \"obtain\", \"egotism\", \"ignorance\", \"delay\", \"engross\", \"load\", \"snake\", \"plunder\", \"inner\", \"sing\", \"awake\", \"Value\", \"read\", \"wave\", \"greed\", \"Command\", \"ninety\", \"weigh\", \"moment\", \"famous\", \"eighty\", \"permit\", \"touchstone\", \"slanderous\", \"asset\", \"Cruelty\", \"material\", \"Falling\", \"tight\", \"demolish\", \"capture\", \"sit\", \"temple\", \"wisdom\", \"wind\", \"river\", \"like\", \"full\", \"asleep\", \"find\", \"within\", \"bed\", \"one\", \"command\", \"Guru\", \"True\", \"spiritual\", \"body\", \"depart\", \"fast\", \"know\", \"water\", \"dwell\", \"upon\", \"corruption\", \"thousand\", \"instant\", \"hard\", \"meditation\", \"Pure\", \"sense\", \"worldly\", \"assign\", \"object\", \"According\", \"sand\", \"conceited\", \"number\", \"untrue\", \"splendor\", \"Joining\", \"inscription\", \"decoration\", \"wail\", \"painfully\", \"wondrous\", \"fearless\", \"receive\", \"waste\", \"anoint\", \"self\", \"hat\", \"Love\", \"Woe\", \"hind\", \"Meeting\", \"love\", \"sin\", \"Like\", \"beauty\", \"believe\", \"God\", \"breath\", \"open\", \"life\", \"still\", \"honor\", \"many\", \"mind\", \"away\", \"know\", \"Beloved\", \"word\", \"corruption\", \"door\", \"heavy\", \"advice\", \"relative\", \"color\", \"belong\", \"social\", \"Practicing\", \"enshrine\", \"lead\", \"iron\", \"bow\", \"People\", \"fourth\", \"demon\", \"Pride\", \"personal\", \"Search\", \"check\", \"Restrain\", \"defect\", \"mud\", \"puddle\", \"frog\", \"appreciate\", \"objective\", \"conquest\", \"carriage\", \"ornate\", \"ignore\", \"impure\", \"8\", \"blind\", \"status\", \"4\", \"Let\", \"listen\", \"wander\", \"keep\", \"cry\", \"mind\", \"prayer\", \"within\", \"nothing\", \"give\", \"meditate\", \"body\", \"wealth\", \"Truth\", \"silver\", \"find\", \"word\", \"peace\", \"good\", \"speak\", \"comfort\", \"Giver\", \"conscious\", \"hungry\", \"action\", \"Peace\", \"cut\", \"remember\", \"Perfect\", \"infuse\", \"Creation\", \"mistake\", \"treasure\", \"talk\", \"past\", \"mere\", \"beg\", \"remembrance\", \"approve\", \"Feet\", \"tie\", \"karma\", \"worthless\", \"fine\", \"Honor\", \"entire\", \"air\", \"Engrossed\", \"dress\", \"unsatisfied\", \"intellect\", \"fulfil\", \"Maya\", \"strong\", \"make\", \"mind\", \"Guru\", \"remain\", \"within\", \"deep\", \"people\", \"Without\", \"pain\", \"please\", \"come\", \"desire\", \"consciousness\", \"Light\", \"focus\", \"speech\", \"merge\", \"expanse\", \"heat\", \"person\", \"third\", \"Divine\", \"burden\", \"silence\", \"will\", \"wive\", \"skepticism\", \"avarice\", \"shin\", \"fearlessly\", \"scorpion\", \"someone\", \"physician\", \"devotional\", \"Blessings\", \"instinct\", \"Consciousness\", \"violent\", \"nectar\", \"Deep\", \"Searching\", \"distract\", \"creation\", \"transitory\", \"four\", \"within\", \"heart\", \"earth\", \"remain\", \"one\", \"like\", \"practice\", \"wealth\", \"away\", \"light\", \"falsehood\", \"great\", \"sorrow\", \"understand\", \"pas\", \"live\", \"Master\", \"Sanctuary\", \"devotion\", \"Saints\", \"dye\", \"peaceful\", \"sustenance\", \"vain\", \"gather\", \"Siblings\", \"imbue\", \"Greatness\", \"Husband\", \"cross\", \"boat\", \"Sin\", \"Says\", \"guest\", \"mansion\", \"Destiny\", \"Source\", \"human\", \"sustain\", \"Nothing\", \"radiate\", \"defeat\", \"fascinate\", \"Enjoy\", \"Robe\", \"prisoner\", \"rival\", \"endure\", \"humble\", \"honor\", \"Guru\", \"mind\", \"strength\", \"create\", \"bless\", \"True\", \"be\", \"tongue\", \"Name\", \"asleep\", \"obtain\", \"meet\", \"may\", \"desire\", \"even\", \"One\", \"become\", \"conquer\", \"patience\", \"anxiety\", \"deception\", \"disease\", \"company\", \"compassion\", \"Give\", \"million\", \"close\", \"conflict\", \"carcass\", \"Protector\", \"sickness\", \"indulge\", \"Wind\", \"tolerance\", \"composure\", \"Understand\", \"Awareness\", \"article\", \"Cheating\", \"grave\", \"dispel\", \"ego\", \"dream\", \"wise\", \"light\", \"devote\", \"awaken\", \"die\", \"darkness\", \"forgiveness\", \"bless\", \"mind\", \"body\", \"heavy\", \"live\", \"fear\", \"birth\", \"wind\", \"earth\", \"home\", \"soul\", \"open\", \"rain\", \"water\"], \"Total\": [196.0, 221.0, 472.0, 308.0, 168.0, 244.0, 167.0, 122.0, 114.0, 112.0, 142.0, 211.0, 174.0, 138.0, 83.0, 140.0, 92.0, 76.0, 50.0, 90.0, 152.0, 89.0, 91.0, 49.0, 67.0, 140.0, 80.0, 124.0, 97.0, 128.0, 112.41946830829961, 49.650885000267785, 45.91974802899985, 29.192201051771963, 29.049365188972136, 20.89087287001163, 19.659109431972865, 17.856013549027743, 16.749169559205363, 15.499489944754067, 15.499447643176643, 13.839224314135254, 13.018052275988198, 12.464630403744419, 11.911208445782238, 10.661528896788544, 10.661528901542965, 10.250942881935298, 196.26262000436944, 10.10810702556362, 10.108107022211762, 9.554685147757363, 9.14409912571232, 9.144099124309637, 9.144098291055164, 9.001263268374506, 9.001263266962821, 8.590677249359473, 8.447841386872087, 8.44784138685934, 13.089548076921089, 21.702320402612557, 22.513593354309357, 12.395888781088399, 65.44603945776907, 17.53421189879151, 25.657485999826964, 24.64594417770633, 64.69257661753299, 39.08450729030657, 28.547047412081493, 22.673405821589412, 138.98141088664275, 140.71979565981553, 105.96970456452824, 167.79939947627238, 51.56792367836295, 90.92003224304476, 95.13425562892094, 211.2701892754085, 472.952469678686, 308.6047246683088, 62.005683990809345, 168.05320363721515, 140.05077227569078, 128.58097655501132, 122.58522798087971, 80.49090859142294, 47.81790318599382, 42.40626169439994, 35.288195661306126, 23.454583049900624, 21.725616772758755, 21.545957623792894, 19.457673037921364, 18.581919028033035, 16.67329359894452, 14.764667724257686, 11.980288711583395, 11.800629571017828, 11.104534699206438, 11.104534690870839, 11.104534655392884, 10.588098997900987, 10.408439850744637, 10.408439850193744, 10.552318826480136, 9.712344989224084, 9.712344976168026, 9.712344970254339, 9.712344974751693, 9.195909281232836, 9.016250128163245, 9.016250124407327, 9.016250124407327, 9.016250124407327, 8.49981441693237, 7.803719559346001, 34.89738605384568, 46.284707886387466, 17.325231846882552, 35.21901084988399, 140.05077227569078, 138.98141088664275, 174.65322634197398, 36.86039727476988, 20.812944935801987, 142.4709179513301, 152.34999064834662, 60.318831893313245, 472.952469678686, 37.766384184928754, 26.952488571474035, 54.46561928475557, 124.56159808778087, 25.951961997141737, 128.58097655501132, 244.98273506917047, 110.18141100807338, 98.27692041551516, 177.63213975360807, 105.96970456452824, 79.69070664254811, 50.992821968097616, 211.2701892754085, 52.15786620441184, 89.24710878903336, 23.255081790367093, 20.426736171840936, 18.776921582300147, 18.43405277929663, 17.769824979701355, 17.10559717581166, 16.612803778698286, 11.963209166442528, 11.470415762727145, 11.298981369606917, 12.13174298843869, 10.806188111259397, 10.634753568791256, 10.634753561917865, 10.634753557547203, 9.970525754806562, 9.970525752995488, 9.970525735369334, 9.306297967022031, 9.306297966589904, 9.306297959087129, 9.306297960445812, 9.306297949099845, 9.306297946846247, 8.6420701649465, 8.642070149744274, 8.149276609593096, 14.51385641328982, 7.4850489210535525, 6.820821159862404, 12.140975649203092, 59.76275166749165, 49.39564003927894, 50.375194901582, 82.43962413303593, 54.17497959608503, 53.261896364120396, 86.966279938295, 15.655136502991002, 34.63017345557839, 70.04711798035893, 152.34999064834662, 29.18317998193642, 27.060106612023777, 174.65322634197398, 70.87753768913004, 95.69444810906718, 16.996681355397325, 49.91208072298682, 36.927915830174086, 42.69670649777274, 53.26214698711981, 124.56159808778087, 98.27692041551516, 308.6047246683088, 134.30515820929742, 177.63213975360807, 92.18377889543143, 90.92003224304476, 38.73333448125893, 20.190753896508348, 19.566636449026344, 17.372079830720306, 13.788391761564759, 13.164262911245926, 12.540130669549479, 11.291876364136598, 11.291876366401073, 10.204703696202785, 10.204703694799864, 10.043618664373385, 9.580574846667394, 9.419489816631296, 9.419489812028017, 9.419489813282816, 8.956445992192496, 8.795360964537217, 8.795360967178997, 8.79536096552642, 8.795360965557807, 8.795360964892128, 8.795360956942332, 8.795360959335573, 8.795360964055448, 8.795360939359458, 114.08819584544865, 8.171232118383017, 8.171232117681738, 8.171232117681738, 15.888140449130873, 10.850869387250931, 28.29312801700037, 26.01143348749479, 19.38440317036376, 14.038804291778137, 28.679333711921224, 43.56701325436626, 12.121555891406167, 28.067972610065027, 48.814217067362655, 27.171822108225307, 134.30515820929742, 40.193667875168856, 52.15786620441184, 36.927915830174086, 78.24266889348159, 78.43471322999218, 21.76018281450255, 98.27692041551516, 472.952469678686, 90.88212973844907, 91.43256945806833, 177.63213975360807, 128.58097655501132, 244.98273506917047, 41.47736744561319, 95.69444810906718, 19.912625093061678, 19.912625088451094, 18.66147865639705, 16.159185771048747, 12.567204286419908, 11.941631068396118, 11.941631067529006, 10.690484628162686, 10.064911411925017, 10.06491140618122, 9.439338193807544, 9.439338182856188, 8.813764975476612, 8.813764971396253, 8.18819175810285, 8.18819175810285, 8.188191757418478, 8.188191757418478, 8.188191754463682, 8.188185167761901, 8.188185167761901, 8.188185167761901, 8.188185167761901, 8.188185167761901, 8.188185167761901, 7.724076349147671, 10.552239236679313, 7.098503134299586, 5.8473566977098, 50.82168237483185, 9.642018689995252, 92.18377889543143, 75.55299504165656, 22.388267095832163, 80.49090859142294, 39.882075094033105, 85.61263972964832, 124.56159808778087, 31.139819002967805, 50.992821968097616, 110.18141100807338, 23.1816579851066, 244.98273506917047, 23.038332587789494, 177.63213975360807, 24.908260877786702, 174.65322634197398, 308.6047246683088, 97.95999704366707, 221.72753462133778, 41.23748486391351, 70.87753768913004, 472.952469678686, 140.71979565981553, 39.93509249362886, 49.70825950350601, 51.385062719324814, 19.18587874817361, 17.253927704837587, 12.912251413720336, 12.434477209099878, 12.268267727668853, 11.62428405175626, 23.36768698118073, 9.692333006412893, 9.21455880039908, 9.214558805148824, 9.2145585785532, 9.048349328535597, 9.04834932387773, 9.048349318559149, 9.048349317977593, 8.404365647506987, 8.40436564740089, 8.404365623109113, 8.404365623109113, 7.282607731367327, 5.993295845537773, 14.591410769093237, 5.3506567068824396, 5.350655941773295, 9.177604547876008, 27.470379085131338, 5.555814409089067, 11.750405076910901, 51.0839660701769, 28.6803647549079, 23.240006496051357, 24.42611688862036, 19.65650813495221, 44.45959425210587, 36.364741236195364, 24.409516747893754, 89.24710878903336, 12.89088304903134, 142.4709179513301, 60.318831893313245, 30.20050140840205, 95.69444810906718, 110.18141100807338, 45.06986367153839, 472.952469678686, 69.9242962602429, 35.02575885494329, 70.04711798035893, 42.40816553209784, 82.43962413303593, 48.440541335448756, 30.56742815376676, 308.6047246683088, 211.2701892754085, 47.600613314449475, 25.580679416026094, 19.550194825743073, 13.146873394694031, 12.644333022416085, 10.763875064840756, 9.758794282896474, 8.753713518098438, 8.753713517932328, 8.753713517372315, 8.251173134924363, 14.426428140618823, 7.74863275257037, 7.7486327522821865, 7.7486327473524845, 7.7486327474760595, 7.375795926335793, 7.246092369885489, 7.246092369871718, 7.246092369220727, 7.246092367898383, 6.743551987208418, 6.743551987208418, 6.743551986924558, 6.743551985911449, 9.212991101249322, 23.94264843721732, 4.3605536313801405, 4.360553631062179, 21.55365557887173, 3.3554728650813983, 11.233469876205135, 39.54861983411201, 20.045945417989447, 40.231262849316195, 45.00276578560616, 49.36308437548439, 28.629509610817216, 68.06074643012867, 46.12026689306401, 25.037378845796542, 14.220287322173043, 15.760003130310245, 41.66033065315232, 83.21778527485371, 15.322108419346709, 71.99453357128411, 97.95999704366707, 76.766706787658, 27.009543337470607, 42.40816553209784, 41.23748486391351, 53.261896364120396, 472.952469678686, 211.2701892754085, 54.32079070855811, 20.7302236093285, 20.643557401841843, 14.350197370916824, 13.67861566023663, 13.007033949934552, 10.0715824673342, 9.400000758419395, 9.064209902998977, 8.479294401057079, 7.13613098535051, 7.136130981561772, 6.800340129975017, 6.464549274386208, 6.128758419073664, 6.128758420446927, 6.128758419616618, 5.792967563608088, 5.792967564520555, 5.79296756501811, 5.792967566026863, 5.792967565293313, 5.457176709070357, 5.457176705300277, 5.121385854646007, 5.12138585450454, 5.121385855747246, 5.121385853880498, 5.121385852842169, 5.121385855598548, 4.872261207231512, 28.14234289863069, 22.067559473353718, 24.224816064678322, 27.84968512312751, 21.52704622513648, 21.344848050456108, 45.85908525023552, 11.731424407967495, 97.95999704366707, 45.919550983693746, 13.002817327490144, 12.356339891309519, 308.6047246683088, 472.952469678686, 33.7062217137005, 15.992850415199921, 45.463997288497396, 32.656239034267465, 69.04657086593559, 221.72753462133778, 128.58097655501132, 95.13425562892094, 211.2701892754085, 134.30515820929742, 25.895360089200814, 54.32079070855811, 67.34458072235896, 49.91208072298682, 140.71979565981553, 86.966279938295, 22.21839883569685, 16.987888995994773, 11.159053016824087, 10.56072687040513, 8.765748438085199, 8.466585381622208, 8.167422292146304, 7.868259221357204, 7.347145810929985, 6.748819665054232, 6.449656591787879, 6.150495223175178, 5.851330448870811, 5.552167375700795, 5.552167376916895, 5.253004303399457, 5.2530043020148245, 5.253004301368625, 5.253004304996749, 4.953841231898703, 4.6546781584056, 4.654678158404019, 4.654678157960447, 4.654678158995234, 4.654678160237663, 4.654678158458917, 4.654678161964909, 4.355515086307015, 4.355515086307015, 4.355515086275318, 4.355515086275318, 4.355515086275318, 15.193813676633045, 76.0575628018638, 19.32934667816457, 8.617662565341186, 8.898444787339868, 11.080965174910737, 12.228271135713173, 30.179914952195084, 22.68912119946005, 25.432263676650223, 167.79939947627238, 91.43256945806833, 79.69070664254811, 15.92878842586575, 41.47736744561319, 41.23748486391351, 71.99453357128411, 69.9242962602429, 211.2701892754085, 85.61263972964832, 221.72753462133778, 64.03828399246026, 27.762795277300395, 152.34999064834662, 134.30515820929742, 49.36308437548439, 22.220617229805804, 18.73592453482352, 18.019734540057502, 13.456922394889746, 11.758870222818873, 10.777008048509156, 10.326490204583035, 10.06081805428031, 9.25220524842879, 7.196058081128016, 6.837963082930202, 6.1217730909437735, 5.763678091504904, 5.76367809016377, 5.405583096365799, 5.405583096020263, 5.40558309675557, 5.405583098567466, 5.405583094582434, 5.047488099823399, 5.04748809973117, 5.047488099711231, 5.047488099711231, 5.047488099660493, 5.047488098697147, 8.171510663530116, 21.625157912814526, 3.3494359285130924, 27.093143319452476, 8.87893754237728, 2.6332459346832127, 14.369126810022228, 46.901226038696464, 50.59421072355697, 56.1145014858809, 30.179914952195084, 73.12875976321197, 33.7062217137005, 65.3553205695903, 95.13425562892094, 244.98273506917047, 53.26214698711981, 69.9242962602429, 24.415569932903413, 83.21778527485371, 30.016045581192333, 70.87753768913004, 168.05320363721515, 177.63213975360807, 122.58522798087971, 167.79939947627238, 30.095539988864466, 21.6905132124608, 17.117195782120312, 7.970561242154686, 7.544815748524471, 7.119070253929008, 7.11907025400795, 7.11907025655548, 6.693324758845205, 6.267579264239965, 6.267579262460002, 5.8418337689358895, 5.841833769447227, 5.84183376894921, 5.84183376894921, 5.841833770579066, 5.841833760459521, 4.6815588060949045, 2.5457529308750093, 2.5457529309985527, 2.54575293188394, 14.191224177403159, 2.120007436052781, 2.1200074362128096, 2.1200074365440407, 3.5660401384958305, 12.21424430247979, 22.389152395893024, 3.0991973085462647, 5.314601229835429, 18.640195799388152, 30.56742815376676, 28.29264502587241, 22.232022491459336, 16.96331429463362, 20.770841429970012, 11.134992486853859, 9.874350223720262, 18.94518207159774, 89.24710878903336, 56.1145014858809, 39.93509249362886, 27.171822108225307, 308.6047246683088, 23.477438482617323, 22.157107493830207, 221.72753462133778, 79.69070664254811, 177.63213975360807, 244.98273506917047, 27.869314591904264, 69.9242962602429, 67.34458072235896, 140.05077227569078, 105.96970456452824, 29.40638552266855, 19.60759028591561, 12.65324584212404, 10.728100530812068, 10.392820589670995, 10.057540647553292, 9.722260704433214, 9.386980763504168, 9.051700821054862, 9.05170082105219, 7.7971153946825105, 6.120715681873593, 5.7854357414409545, 5.785435742100189, 5.450155799197652, 5.450155799435347, 5.4501557994437375, 5.450155799850968, 5.114875857157624, 5.1148758569627235, 5.11487586040085, 5.1148758540542465, 4.779595914926581, 4.779595914926581, 4.779595914935092, 4.779595914935092, 4.779595914927258, 4.779595915010272, 4.779595915010272, 4.779595915087296, 49.635796345626915, 7.3961779383610216, 122.58522798087971, 14.67111177726629, 9.552538147154065, 28.29264502587241, 12.30484075576208, 45.463997288497396, 78.43471322999218, 68.06074643012867, 9.777133454978976, 472.952469678686, 79.69070664254811, 91.43256945806833, 34.35071259958877, 10.243790403687251, 20.17194779007678, 152.34999064834662, 25.052674393130665, 48.814217067362655, 67.34458072235896, 28.306931034862426, 15.399309765993543, 14.300031400661958, 12.722043632014337, 12.722043632967665, 11.69369504712884, 11.347945675347397, 10.523413475629779, 9.220318889631267, 8.945499132716972, 7.846220767492349, 7.846220768691179, 7.5714011780262425, 7.571401179630054, 7.571401179280925, 7.092691774594583, 7.092691774900394, 5.4437742272586105, 5.443774226093999, 5.168954635474474, 5.168954637022252, 4.894135042652676, 4.619315451767015, 4.619315452868759, 4.619315453216832, 4.344495859569848, 4.34449585887749, 4.344495861185328, 4.069676267925638, 4.06967626802149, 15.53243162583867, 31.89929291230716, 24.789336671843184, 14.392830718079681, 15.314216711977535, 168.05320363721515, 91.43256945806833, 58.36244027204311, 28.629509610817216, 16.39296420038241, 28.523890508517308, 140.71979565981553, 128.58097655501132, 244.98273506917047, 51.40586629958591, 47.600613314449475, 54.46561928475557, 140.05077227569078, 51.56792367836295, 29.46155814035402, 20.14650265854751, 8.743251811387184, 8.444938184132567, 8.146624560614727, 8.146624565980266, 7.8483109387770345, 15.555712519508724, 7.328677180789842, 5.538795438947378, 5.2404818146689855, 5.240481815632093, 5.240481815549541, 23.14461299072922, 4.942168191124279, 4.9421681944369755, 4.643854567416351, 4.643854567519671, 4.64385456749341, 4.643854570931047, 4.345540943867582, 4.3455409439236155, 4.345540943885412, 4.345540943854571, 4.345540943965319, 4.345540943965319, 4.345540943965319, 4.345540943965319, 4.345540950054753, 4.345540950054753, 19.613578463761705, 13.75011240832476, 28.33845429460829, 15.74164203559003, 9.857175061075006, 65.3553205695903, 14.649594719079722, 12.92226622576937, 78.24266889348159, 90.88212973844907, 18.924601037691577, 211.2701892754085, 12.341142601113242, 168.05320363721515, 167.79939947627238, 20.245233994954418, 308.6047246683088, 50.375194901582, 10.389988414056697, 105.96970456452824, 54.32079070855811, 70.04711798035893, 152.34999064834662, 41.66033065315232, 16.278821814721464, 12.280477574856011, 11.960067364776572, 7.641312885114236, 7.209437434943019, 6.77756198824539, 6.777561987605596, 6.77756198579999, 6.777561983219448, 6.345686540131329, 6.345686539153128, 6.345686541390839, 6.025276325187878, 5.913811092248646, 5.91381109214506, 5.913811092001665, 5.913811092001665, 5.91381109193959, 5.913811092062402, 5.913811092062402, 5.913811092544143, 5.913811092544143, 27.248340179420776, 17.811944624790282, 3.0023813174485485, 20.331372893334713, 2.569738825638048, 12.093905257873322, 4.084049910065985, 2.13839729569809, 14.206132497718272, 67.34458072235896, 48.440541335448756, 20.312129142807436, 34.35071259958877, 62.005683990809345, 244.98273506917047, 10.985981662857723, 25.98657521838523, 85.61263972964832, 15.314216711977535, 14.55468864039059, 46.12026689306401, 221.72753462133778, 71.99453357128411, 105.96970456452824, 15.92878842586575, 37.59818403200269, 41.66033065315232, 28.679333711921224, 15.92543460679978, 22.766592281959447, 12.57176993185885, 12.571769930468669, 9.275774255265329, 8.968938930947502, 8.662103604700343, 8.355268278988337, 6.900284556844546, 6.5934492320746, 6.593449234136427, 5.059272603424057, 5.059272606324295, 5.059272608655203, 4.752437277653969, 4.752437279690925, 4.4456019520199925, 4.4456019520199925, 4.4456019520199925, 4.44560195203603, 4.44560195203603, 4.44560195203603, 4.44560195203603, 4.44560195203603, 4.445601952282425, 4.445601952282425, 4.445601952015902, 4.445601952015902, 4.445601952015902, 4.445601952015902, 8.085395101686776, 9.31670928254659, 15.963695841568052, 10.647495035469058, 26.139853851881462, 13.53084424257817, 15.98539401884582, 25.822835557336685, 18.94518207159774, 221.72753462133778, 30.016045581192333, 90.88212973844907, 16.967875946942947, 140.71979565981553, 15.021539385585811, 308.6047246683088, 32.656239034267465, 32.415154636477844, 15.479927965550292, 78.24266889348159, 37.59818403200269, 41.47736744561319, 140.05077227569078, 45.919550983693746, 25.500508176609255, 22.438567226231548, 15.91926785006084, 12.228720057675295, 12.228720059172085, 10.109700924604471, 9.876441010725618, 9.247904718477411, 9.166783728076249, 8.53817226870019, 8.538172267693678, 7.362070327324116, 7.047764596785129, 6.733458864943607, 6.41915313315855, 6.419153132647924, 6.104847401051314, 6.104847403730621, 5.7905416710996755, 5.790541670750418, 5.790541670350588, 5.476235937864321, 5.476235938444339, 5.476235937267866, 5.161930204459874, 5.161930205913213, 5.161930213804808, 4.84762447583356, 4.847624485979976, 4.533318743257622, 16.791532210471324, 18.482063990966473, 45.95369680922788, 11.696699122073927, 142.4709179513301, 221.72753462133778, 168.05320363721515, 32.92598026261891, 90.88212973844907, 19.308673188860652, 90.92003224304476, 46.901226038696464, 56.1145014858809, 50.34976781417053, 177.63213975360807, 122.58522798087971, 50.007404563402616, 27.357348319897614, 18.592671362718498, 9.90471876399233, 9.012906196730382, 8.418364485539259, 8.121093631210345, 7.306005421242637, 6.711538334640417, 6.116921996402481, 6.116921997469393, 5.522380285787776, 4.927838580655379, 4.927838587598669, 4.630567718104276, 4.6305677181516725, 4.630567718181197, 4.630567720518376, 4.630567720807339, 4.63056771801126, 4.630567720830429, 4.63056771701894, 4.630567720640389, 4.333296862463756, 4.333296862463756, 4.333296862463756, 4.333296862458589, 4.333296862579819, 4.333296862732416, 4.333296862732416, 29.549871044490384, 12.943798683191424, 30.20050140840205, 90.88212973844907, 80.49090859142294, 42.40816553209784, 32.92598026261891, 211.2701892754085, 65.3553205695903, 15.971434455162429, 32.656239034267465, 71.99453357128411, 27.626793495727846, 28.324361619110817, 58.36244027204311, 15.680688918024845, 39.93509249362886, 35.06852070197215, 34.51468289342615, 9.101889461373368, 9.101889462903458, 8.453703885540914, 7.861282967916393, 5.916726240928743, 5.916726242005837, 5.108243465838827, 9.013048642293656, 10.621201332002066, 25.37384586368306, 4.24399603140906, 4.02793417332914, 4.027934183461985, 3.8118723135709134, 3.8118723147696794, 3.811872314401989, 3.811872316191348, 3.811872326525523, 3.811872343237762, 31.02107401438461, 3.5958104552345636, 3.5958104548882996, 3.5958104555451906, 3.5958104574963388, 3.595810459070891, 3.5958104585594377, 3.3797485960338287, 3.379748596023398, 3.379748596023398, 3.3797485962065767, 3.3797485962065767, 4.67463818210263, 9.548445937687811, 14.55468864039059, 168.05320363721515, 221.72753462133778, 11.288282736680795, 47.600613314449475, 45.71872228735634, 167.79939947627238, 14.392830718079681, 27.869314591904264, 76.0575628018638, 12.92226622576937, 51.56792367836295, 65.44603945776907, 75.55299504165656, 122.58522798087971, 73.12875976321197, 95.13425562892094, 64.03828399246026, 13.627179343123656, 13.37238754054131, 13.2837498279993, 9.25123337605466, 7.966153031513348, 7.2792940039856004, 6.592434975576423, 6.592434975606492, 6.249005458635876, 5.905575948892994, 5.218716919474281, 5.218716919471204, 5.218716919700267, 5.218716919824801, 5.218716927506428, 4.875287405632772, 4.875287405632772, 4.875287405673516, 4.875287405618914, 4.875287405618914, 4.875287405558063, 4.875287405439425, 3.246777549138895, 28.787973575332465, 15.93188959078412, 11.287838954740673, 16.009974248770163, 27.626793495727846, 1.8730594930869955, 7.412265052237566, 51.40586629958591, 83.21778527485371, 16.65228992314191, 45.71872228735634, 221.72753462133778, 308.6047246683088, 15.92543460679978, 34.51468289342615, 50.59421072355697, 8.995261423548566, 15.74164203559003, 42.40816553209784, 42.69670649777274, 128.58097655501132, 25.98657521838523, 20.045945417989447, 54.32079070855811], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.0968, 2.0878, 2.0865, 2.0764, 2.0763, 2.0653, 2.0629, 2.0586, 2.0556, 2.0516, 2.0516, 2.0451, 2.0413, 2.0385, 2.0353, 2.027, 2.027, 2.0238, 2.0238, 2.0226, 2.0226, 2.0177, 2.0136, 2.0136, 2.0136, 2.0121, 2.0121, 2.0076, 2.0058, 2.0058, 1.9984, 1.9829, 1.9727, 1.9965, 1.8542, 1.9383, 1.8866, 1.8656, 1.6856, 1.7643, 1.8203, 1.8622, 1.3098, 1.1413, 1.2365, 1.0446, 1.4672, 1.2133, 1.1798, 0.8091, 0.3884, 0.3382, 1.1771, 0.5234, 0.3299, 0.3589, 0.3785, 0.7049, 2.2352, 2.2331, 2.2294, 2.218, 2.2153, 2.215, 2.211, 2.209, 2.204, 2.1977, 2.1848, 2.1837, 2.1793, 2.1793, 2.1793, 2.1756, 2.1743, 2.1743, 2.1718, 2.1685, 2.1685, 2.1685, 2.1685, 2.1636, 2.1618, 2.1618, 2.1618, 2.1618, 2.1561, 2.1471, 2.1071, 2.0193, 2.0965, 1.9292, 1.6787, 1.6402, 1.5016, 1.8515, 1.9754, 1.3912, 1.3515, 1.626, 0.9541, 1.7597, 1.8651, 1.5821, 1.1685, 1.8241, 1.0916, 0.7891, 1.029, 1.0591, 0.6676, 0.878, 1.0174, 1.3525, 0.1472, 1.3128, 0.8065, 2.399, 2.3942, 2.3907, 2.3899, 2.3882, 2.3865, 2.3851, 2.3658, 2.3628, 2.3617, 2.3588, 2.3583, 2.3571, 2.3571, 2.3571, 2.3518, 2.3518, 2.3518, 2.3458, 2.3458, 2.3458, 2.3458, 2.3458, 2.3458, 2.3387, 2.3387, 2.3327, 2.3314, 2.3233, 2.312, 2.306, 2.2192, 2.2115, 2.1306, 2.0642, 2.0898, 2.0039, 1.8705, 2.2124, 1.9964, 1.7603, 1.4334, 1.9928, 2.0132, 1.3281, 1.5744, 1.3732, 2.1436, 1.6205, 1.7604, 1.655, 1.483, 0.9567, 1.0615, 0.2744, 0.8117, 0.5712, 1.002, 0.9651, 2.5145, 2.4954, 2.4942, 2.4889, 2.4766, 2.4737, 2.4706, 2.4632, 2.4632, 2.4553, 2.4553, 2.4539, 2.4499, 2.4483, 2.4483, 2.4483, 2.4437, 2.4419, 2.4419, 2.4419, 2.4419, 2.4419, 2.4419, 2.4419, 2.4419, 2.4419, 2.4391, 2.4344, 2.4344, 2.4344, 2.4265, 2.3866, 2.2085, 2.2011, 2.2604, 2.3079, 2.0942, 1.9037, 2.3323, 2.0149, 1.784, 2.0032, 1.3247, 1.7824, 1.658, 1.7803, 1.3198, 1.2838, 1.9935, 1.0641, 0.0682, 1.0481, 0.9315, 0.3354, 0.5687, -0.1961, 1.3706, 0.5537, 2.5561, 2.5561, 2.5534, 2.5466, 2.532, 2.5285, 2.5285, 2.5203, 2.5154, 2.5154, 2.5098, 2.5098, 2.5034, 2.5034, 2.4959, 2.4959, 2.4959, 2.4959, 2.4959, 2.4959, 2.4959, 2.4959, 2.4959, 2.4959, 2.4959, 2.4895, 2.4831, 2.4796, 2.4528, 2.4389, 2.4284, 2.3127, 2.1794, 2.3051, 2.0275, 2.086, 1.8588, 1.6114, 2.0665, 1.7955, 1.424, 2.0653, 1.0299, 1.9755, 0.7993, 1.8818, 0.6707, 0.2843, 0.9503, 0.3812, 1.5267, 1.1279, -0.264, 0.4862, 1.4413, 1.2097, 2.644, 2.6179, 2.6131, 2.5971, 2.5946, 2.5937, 2.5899, 2.58, 2.5755, 2.571, 2.571, 2.571, 2.5693, 2.5693, 2.5693, 2.5693, 2.562, 2.562, 2.562, 2.562, 2.5462, 2.5198, 2.5031, 2.5019, 2.5019, 2.4734, 2.4707, 2.4607, 2.4581, 2.4573, 2.431, 2.435, 2.3925, 2.4013, 2.277, 2.3014, 2.2854, 1.8404, 2.4204, 1.5332, 1.8352, 2.0539, 1.5523, 1.3458, 1.782, 0.5, 1.4658, 1.8415, 1.4069, 1.6855, 1.2461, 1.5084, 1.8534, -0.18, 0.1361, 1.4183, 2.9371, 2.9272, 2.9064, 2.9039, 2.8921, 2.8839, 2.8737, 2.8737, 2.8737, 2.8676, 2.8625, 2.8606, 2.8606, 2.8606, 2.8606, 2.8549, 2.8527, 2.8527, 2.8527, 2.8527, 2.8435, 2.8435, 2.8435, 2.8435, 2.8366, 2.8018, 2.7679, 2.7679, 2.7294, 2.6989, 2.6958, 2.6772, 2.653, 2.4217, 2.391, 2.3479, 2.4724, 2.2354, 2.28, 2.4673, 2.643, 2.5857, 2.1922, 1.8683, 2.5317, 1.721, 1.3705, 1.4957, 2.1432, 1.6539, 1.6416, 1.3786, -0.5402, 0.1542, 1.3181, 2.9467, 2.9465, 2.9285, 2.9255, 2.9223, 2.9027, 2.8965, 2.893, 2.8862, 2.8661, 2.8661, 2.8598, 2.8527, 2.8448, 2.8448, 2.8448, 2.836, 2.836, 2.836, 2.836, 2.836, 2.8259, 2.8259, 2.8144, 2.8144, 2.8144, 2.8144, 2.8144, 2.8144, 2.8048, 2.7948, 2.7339, 2.6621, 2.6421, 2.6578, 2.5697, 2.4226, 2.6639, 2.1716, 2.3334, 2.6165, 2.6085, 1.5678, 1.3209, 2.189, 2.4273, 1.9423, 1.9805, 1.5452, 0.8763, 1.1746, 1.3513, 0.826, 1.0293, 2.1038, 1.4852, 1.2505, 1.463, 0.511, 0.9293, 3.2837, 3.272, 3.2453, 3.2409, 3.2237, 3.22, 3.2161, 3.2119, 3.2037, 3.1926, 3.1862, 3.1792, 3.1714, 3.1626, 3.1626, 3.1528, 3.1528, 3.1528, 3.1528, 3.1417, 3.129, 3.129, 3.129, 3.129, 3.129, 3.129, 3.129, 3.1143, 3.1143, 3.1143, 3.1143, 3.1143, 3.0799, 2.835, 2.9534, 3.0415, 3.0271, 2.9835, 2.9624, 2.7152, 2.7179, 2.6804, 2.1646, 2.1946, 2.2336, 2.7587, 2.1217, 2.1056, 1.8032, 1.7079, 0.9909, 1.5252, 0.8503, 1.6757, 2.1834, 0.8605, 0.8398, 1.6482, 2.3089, 3.2806, 3.2788, 3.2628, 3.2535, 3.2468, 3.2432, 3.241, 3.2333, 3.2056, 3.199, 3.1832, 3.1737, 3.1737, 3.1629, 3.1629, 3.1629, 3.1629, 3.1629, 3.1503, 3.1503, 3.1503, 3.1503, 3.1503, 3.1503, 3.1193, 3.0744, 3.0488, 3.0426, 2.989, 2.9584, 2.9089, 2.8347, 2.6769, 2.6535, 2.4775, 2.0984, 2.3723, 2.0751, 1.8292, 1.3705, 2.0137, 1.7697, 2.3174, 1.6019, 2.1846, 1.5205, 0.791, 0.6507, 0.6645, 0.1462, 3.3452, 3.3346, 3.3243, 3.2663, 3.26, 3.2529, 3.2529, 3.2529, 3.2448, 3.2355, 3.2355, 3.2248, 3.2248, 3.2248, 3.2248, 3.2248, 3.2248, 3.0471, 2.9945, 2.9945, 2.9945, 2.9519, 2.8978, 2.8978, 2.8978, 2.8758, 2.857, 2.8157, 2.7977, 2.7819, 2.7535, 2.7358, 2.7036, 2.6673, 2.663, 2.6218, 2.6956, 2.6999, 2.5464, 2.166, 2.2739, 2.3141, 2.4181, 1.3449, 2.3603, 2.336, 0.7417, 1.3661, 0.6624, 0.3227, 2.0488, 1.2019, 1.1814, 0.3813, 0.6501, 3.3908, 3.3765, 3.3526, 3.3402, 3.3376, 3.3348, 3.3317, 3.3285, 3.325, 3.325, 3.309, 3.2768, 3.2679, 3.2679, 3.2579, 3.2579, 3.2579, 3.2579, 3.2464, 3.2464, 3.2464, 3.2464, 3.2331, 3.2331, 3.2331, 3.2331, 3.2331, 3.2331, 3.2331, 3.2331, 3.2294, 3.189, 2.7834, 3.0147, 3.0417, 2.6431, 2.9131, 2.2582, 1.9973, 1.7736, 2.8696, 0.5356, 1.5602, 1.3487, 1.9913, 2.823, 2.2384, 0.4482, 1.9963, 1.318, 0.9641, 3.4407, 3.4155, 3.4112, 3.4036, 3.4036, 3.3976, 3.3953, 3.3892, 3.3773, 3.3743, 3.3601, 3.3601, 3.3559, 3.3559, 3.3559, 3.3477, 3.3477, 3.3076, 3.3076, 3.2982, 3.2982, 3.2876, 3.2756, 3.2756, 3.2756, 3.262, 3.262, 3.262, 3.2462, 3.2462, 3.1072, 3.0087, 2.7153, 2.8643, 2.8362, 1.9071, 2.0718, 2.1598, 2.4605, 2.694, 2.3732, 1.3499, 1.3557, 0.8843, 1.9092, 1.9641, 1.6491, 0.7766, 1.5825, 3.456, 3.4428, 3.3864, 3.3828, 3.3788, 3.3788, 3.3746, 3.3745, 3.3664, 3.3252, 3.3154, 3.3154, 3.3154, 3.3095, 3.3042, 3.3042, 3.2915, 3.2915, 3.2915, 3.2915, 3.2768, 3.2768, 3.2768, 3.2768, 3.2768, 3.2768, 3.2768, 3.2768, 3.2768, 3.2768, 3.2166, 3.0062, 2.8088, 2.9447, 3.0634, 2.3984, 2.8571, 2.876, 2.2044, 2.0531, 2.6638, 1.5166, 2.8342, 1.5737, 1.3411, 2.5233, 0.4777, 1.7287, 2.8345, 1.1733, 1.5578, 1.3457, 0.5866, 1.7097, 3.4343, 3.4173, 3.4155, 3.3741, 3.3671, 3.3591, 3.3591, 3.3591, 3.3591, 3.3499, 3.3499, 3.3499, 3.3422, 3.3393, 3.3393, 3.3393, 3.3393, 3.3393, 3.3393, 3.3393, 3.3393, 3.3393, 3.26, 3.2449, 3.1739, 3.149, 3.1109, 3.0814, 3.0251, 3.016, 2.9777, 2.9119, 2.7762, 2.8758, 2.7281, 2.3536, 1.7161, 2.9458, 2.3837, 1.5542, 2.6145, 2.6311, 1.6964, 0.4168, 1.2165, 0.821, 2.5216, 1.7298, 1.5597, 1.9171, 2.5048, 3.541, 3.5105, 3.5105, 3.4857, 3.4824, 3.4788, 3.475, 3.452, 3.4458, 3.4458, 3.4023, 3.4023, 3.4023, 3.3898, 3.3898, 3.3755, 3.3755, 3.3755, 3.3755, 3.3755, 3.3755, 3.3755, 3.3755, 3.3755, 3.3755, 3.3755, 3.3755, 3.3755, 3.3755, 3.3371, 3.3355, 3.1779, 3.1911, 2.9868, 3.1296, 3.0686, 2.9477, 2.9261, 2.0911, 2.6538, 2.1533, 2.805, 1.8832, 2.7305, 1.0536, 2.3014, 2.1934, 2.6687, 1.4822, 1.968, 1.7838, 0.5628, 1.6181, 3.596, 3.5915, 3.576, 3.5597, 3.5597, 3.5446, 3.5424, 3.5365, 3.5356, 3.5284, 3.5284, 3.5115, 3.506, 3.4999, 3.4931, 3.4931, 3.4857, 3.4857, 3.4773, 3.4773, 3.4773, 3.4679, 3.4679, 3.4679, 3.4572, 3.4572, 3.4572, 3.4451, 3.4451, 3.431, 3.2426, 3.1966, 2.9842, 3.0954, 1.7197, 1.2758, 1.3525, 2.3099, 1.5905, 2.576, 1.3905, 1.8324, 1.6788, 1.6678, 0.467, 0.6933, 3.6172, 3.6034, 3.5888, 3.5479, 3.539, 3.5319, 3.528, 3.5155, 3.5043, 3.4909, 3.4909, 3.4742, 3.4532, 3.4532, 3.4404, 3.4404, 3.4404, 3.4404, 3.4404, 3.4404, 3.4404, 3.4404, 3.4404, 3.4257, 3.4257, 3.4257, 3.4257, 3.4257, 3.4257, 3.4257, 3.2587, 3.0048, 2.4024, 1.7787, 1.8436, 2.0866, 2.2233, 1.0364, 1.7564, 2.6316, 2.1542, 1.5051, 2.1105, 1.9373, 1.2524, 2.3655, 1.5305, 1.6218, 1.6179, 3.6426, 3.6426, 3.635, 3.6269, 3.5878, 3.5878, 3.5619, 3.549, 3.5402, 3.524, 3.5221, 3.5091, 3.5091, 3.4945, 3.4945, 3.4945, 3.4945, 3.4945, 3.4945, 3.4936, 3.4779, 3.4779, 3.4779, 3.4779, 3.4779, 3.4779, 3.4588, 3.4588, 3.4588, 3.4588, 3.4588, 3.424, 3.2967, 3.0845, 2.2327, 2.012, 3.0289, 2.3763, 2.3156, 1.6543, 2.8186, 2.5006, 1.9755, 2.8066, 1.9992, 1.8018, 1.6693, 1.2312, 1.405, 1.0944, 1.2855, 3.7133, 3.7121, 3.7117, 3.683, 3.6674, 3.6567, 3.6436, 3.6436, 3.6359, 3.6272, 3.6061, 3.6061, 3.6061, 3.6061, 3.6061, 3.5931, 3.5931, 3.5931, 3.5931, 3.5931, 3.5931, 3.5931, 3.488, 3.45, 3.4075, 3.3898, 3.2578, 3.2162, 3.2091, 3.1741, 2.9869, 2.7968, 2.8381, 2.2308, 1.0363, 0.5115, 2.6352, 1.9545, 1.596, 3.0616, 2.5713, 1.6967, 1.687, 0.6523, 2.1058, 2.3171, 1.3262], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.3784, -4.2046, -4.2841, -4.7471, -4.7521, -5.0928, -5.156, -5.2564, -5.3235, -5.405, -5.405, -5.5248, -5.5898, -5.6361, -5.6846, -5.8038, -5.8038, -5.8463, -2.8942, -5.8615, -5.8615, -5.9227, -5.9707, -5.9707, -5.9707, -5.9879, -5.9879, -6.0392, -6.0577, -6.0577, -5.6272, -5.1371, -5.1106, -5.6836, -4.162, -5.395, -5.066, -5.1272, -4.3421, -4.7674, -5.0256, -5.214, -3.9533, -4.1093, -4.2977, -4.03, -4.7873, -4.4741, -4.4623, -4.0352, -3.65, -4.1272, -4.8931, -4.5498, -4.9255, -4.9819, -5.0101, -5.1044, -4.0948, -4.217, -4.4045, -4.8244, -4.9037, -4.9123, -5.0182, -5.0662, -5.1796, -5.3075, -5.5294, -5.5456, -5.6108, -5.6108, -5.6108, -5.6621, -5.6805, -5.6805, -5.6693, -5.7555, -5.7555, -5.7555, -5.7555, -5.815, -5.8366, -5.8366, -5.8366, -5.8366, -5.9013, -5.9957, -4.5379, -4.3433, -5.2488, -4.7067, -3.5767, -3.6229, -3.533, -4.7388, -5.1864, -3.8471, -3.8198, -4.4718, -3.0843, -4.8063, -5.0382, -4.6178, -4.2041, -5.1171, -4.2493, -3.9071, -4.4663, -4.5505, -4.3501, -4.6563, -4.8019, -4.9133, -4.6971, -4.9304, -4.8995, -4.6519, -4.7864, -4.8741, -4.8933, -4.9317, -4.9716, -5.0022, -5.3498, -5.3949, -5.411, -5.3428, -5.459, -5.4762, -5.4762, -5.4762, -5.546, -5.546, -5.546, -5.621, -5.621, -5.621, -5.621, -5.621, -5.621, -5.7021, -5.7021, -5.7668, -5.1909, -5.8612, -5.9655, -5.3949, -3.8879, -4.0861, -4.1473, -3.7212, -4.1154, -4.2183, -3.8614, -5.2343, -4.6563, -4.1879, -3.7378, -4.831, -4.8861, -3.7065, -4.3621, -4.2631, -5.2208, -4.6667, -4.828, -4.7883, -4.7392, -4.4159, -4.5482, -4.1909, -4.4856, -4.4466, -4.6717, -4.7223, -4.0262, -4.6968, -4.7294, -4.8537, -5.097, -5.1462, -5.1979, -5.3101, -5.3101, -5.4193, -5.4193, -5.4365, -5.4878, -5.5063, -5.5063, -5.5063, -5.5614, -5.5813, -5.5813, -5.5813, -5.5813, -5.5813, -5.5813, -5.5813, -5.5813, -5.5813, -3.0213, -5.6624, -5.6624, -5.6624, -5.0054, -5.4266, -4.6463, -4.7378, -4.9725, -5.2477, -4.747, -4.5194, -5.3702, -4.8479, -4.5254, -4.892, -3.9726, -4.7213, -4.5852, -4.8081, -4.5178, -4.5514, -5.1238, -4.5456, -3.9702, -4.6398, -4.7503, -4.6823, -4.7722, -4.8923, -5.1016, -5.0825, -4.6499, -4.6499, -4.7176, -4.8683, -5.1344, -5.1889, -5.1889, -5.3078, -5.373, -5.373, -5.4428, -5.4428, -5.5178, -5.5178, -5.5988, -5.5988, -5.5988, -5.5988, -5.5988, -5.5988, -5.5988, -5.5988, -5.5988, -5.5988, -5.5988, -5.6635, -5.358, -5.758, -5.9787, -3.8302, -5.5029, -3.361, -3.6932, -4.7838, -3.7818, -4.4255, -3.8888, -3.7612, -4.6924, -4.4703, -4.0713, -4.9888, -3.6663, -5.0848, -4.2184, -5.1004, -4.364, -4.1811, -4.6626, -4.4148, -4.9514, -4.8086, -4.3024, -4.7644, -5.0689, -5.0816, -3.614, -4.6254, -4.7363, -5.0422, -5.0823, -5.0967, -5.1544, -4.466, -5.3506, -5.4057, -5.4057, -5.4057, -5.4256, -5.4256, -5.4256, -5.4256, -5.5067, -5.5067, -5.5067, -5.5067, -5.6658, -5.887, -5.0139, -6.0183, -6.0183, -5.5073, -4.4136, -6.0219, -5.2754, -3.8066, -4.4102, -4.6165, -4.6093, -4.8177, -4.1258, -4.3024, -4.717, -3.8656, -5.2205, -3.7051, -4.2626, -4.7356, -4.084, -4.1495, -4.6072, -3.5385, -4.4843, -4.7998, -4.5414, -4.7646, -4.5392, -4.8087, -4.9241, -4.6454, -4.7082, -4.9163, -4.0184, -4.2972, -4.7148, -4.7564, -4.9291, -5.0354, -5.1543, -5.1543, -5.1543, -5.2195, -4.6658, -5.2893, -5.2893, -5.2893, -5.2893, -5.3444, -5.3643, -5.3643, -5.3643, -5.3643, -5.4453, -5.4453, -5.4453, -5.4453, -5.1403, -4.22, -5.957, -5.957, -4.3975, -6.2879, -5.0827, -3.8427, -4.5464, -4.081, -3.9997, -3.9503, -4.3706, -3.7416, -4.0861, -4.5097, -4.8998, -4.8543, -4.2757, -3.9077, -4.9364, -4.1998, -4.2424, -4.3609, -4.758, -4.7962, -4.8365, -4.8436, -4.5787, -4.6901, -4.8844, -4.2191, -4.2235, -4.6052, -4.6561, -4.7097, -4.985, -5.0603, -5.1001, -5.1736, -5.3662, -5.3662, -5.4207, -5.4784, -5.5396, -5.5396, -5.5396, -5.6048, -5.6048, -5.6048, -5.6048, -5.6048, -5.6746, -5.6746, -5.7496, -5.7496, -5.7496, -5.7496, -5.7496, -5.7496, -5.8091, -4.0654, -4.3694, -4.348, -4.2285, -4.4703, -4.5669, -3.9493, -5.0713, -3.4413, -4.0371, -5.0157, -5.0748, -2.8976, -2.7175, -4.4908, -4.998, -4.4382, -4.7309, -4.4175, -3.9196, -4.1662, -4.2908, -4.0183, -4.268, -4.8395, -4.7173, -4.7371, -4.8241, -4.7397, -4.8026, -3.8128, -4.093, -4.5398, -4.5994, -4.8029, -4.8413, -4.8811, -4.9227, -4.9994, -5.0954, -5.1472, -5.2017, -5.2594, -5.3206, -5.3206, -5.3858, -5.3858, -5.3858, -5.3858, -5.4556, -5.5306, -5.5306, -5.5306, -5.5306, -5.5306, -5.5306, -5.5306, -5.6116, -5.6116, -5.6116, -5.6116, -5.6116, -4.3967, -3.0309, -4.2824, -5.0021, -4.9844, -4.8087, -4.7312, -4.0751, -4.3577, -4.281, -2.91, -3.4872, -3.5856, -4.6706, -4.3506, -4.3724, -4.1177, -4.2421, -3.8534, -4.2224, -3.9456, -4.3622, -4.6903, -4.3107, -4.4575, -4.65, -4.7875, -3.9864, -4.0271, -4.3352, -4.4793, -4.5732, -4.6195, -4.6478, -4.7392, -5.0183, -5.0759, -5.2024, -5.2721, -5.2721, -5.3471, -5.3471, -5.3471, -5.3471, -5.3471, -5.4282, -5.4282, -5.4282, -5.4282, -5.4282, -5.4282, -4.9775, -4.0492, -5.9398, -3.8555, -5.0248, -6.2708, -4.6234, -3.5147, -3.5967, -3.5165, -4.3128, -3.8068, -4.3075, -3.9425, -3.813, -3.3257, -4.2085, -4.1803, -4.6848, -4.174, -4.6111, -4.4159, -4.2822, -4.367, -4.7241, -4.9284, -3.4478, -3.786, -4.0331, -4.8554, -4.9166, -4.9818, -4.9818, -4.9818, -5.0515, -5.1265, -5.1265, -5.2076, -5.2076, -5.2076, -5.2076, -5.2076, -5.2076, -5.6067, -6.2685, -6.2685, -6.2685, -4.5929, -6.5482, -6.5482, -6.5482, -6.0502, -4.8378, -4.2731, -6.2685, -5.7451, -4.5186, -4.0417, -4.1512, -4.4286, -4.7034, -4.5421, -5.0917, -5.2076, -4.7095, -3.5401, -3.8961, -4.1961, -4.4771, -3.1205, -4.6811, -4.7632, -4.0543, -4.4532, -4.3553, -4.3735, -4.8211, -4.7481, -4.8062, -4.8741, -4.8842, -3.4254, -3.845, -4.307, -4.4843, -4.5187, -4.5543, -4.5913, -4.6296, -4.6695, -4.6695, -4.8346, -5.109, -5.1742, -5.1742, -5.2439, -5.2439, -5.2439, -5.2439, -5.3189, -5.3189, -5.3189, -5.3189, -5.4, -5.4, -5.4, -5.4, -5.4, -5.4, -5.4, -5.4, -3.0633, -5.0075, -2.6052, -4.4968, -4.8989, -4.2118, -4.7744, -4.1223, -3.8379, -4.2034, -5.0477, -3.5028, -4.2591, -4.3331, -4.6695, -5.0477, -4.9548, -4.7231, -4.9801, -4.9914, -5.0235, -3.4137, -4.0476, -4.126, -4.2505, -4.2505, -4.3408, -4.3731, -4.4546, -4.5987, -4.632, -4.7773, -4.7773, -4.8171, -4.8171, -4.8171, -4.8906, -4.8906, -5.1954, -5.1954, -5.2566, -5.2566, -5.3218, -5.3916, -5.3916, -5.3916, -5.4666, -5.4666, -5.4666, -5.5476, -5.5476, -4.3473, -3.7262, -4.2718, -4.6664, -4.6324, -3.1661, -3.61, -3.971, -4.3825, -4.7066, -4.4735, -3.9007, -3.9851, -3.8119, -4.3484, -4.3705, -4.5508, -4.4788, -4.672, -3.3583, -3.7516, -4.6428, -4.6811, -4.721, -4.721, -4.7625, -4.0785, -4.8392, -5.1604, -5.2256, -5.2256, -5.2256, -3.7461, -5.2954, -5.2954, -5.3704, -5.3704, -5.3704, -5.3704, -5.4515, -5.4515, -5.4515, -5.4515, -5.4515, -5.4515, -5.4515, -5.4515, -5.4515, -5.4515, -4.0046, -4.5702, -4.0444, -4.4965, -4.8458, -3.6192, -4.6559, -4.7625, -3.6332, -3.6348, -4.5932, -3.3277, -4.8503, -3.4994, -3.7335, -4.6662, -3.9877, -4.5492, -5.0221, -4.361, -4.6447, -4.6026, -4.5846, -4.7582, -3.9733, -4.2721, -4.3004, -4.7898, -4.855, -4.9247, -4.9247, -4.9247, -4.9247, -4.9997, -4.9997, -4.9997, -5.0592, -5.0808, -5.0808, -5.0808, -5.0808, -5.0808, -5.0808, -5.0808, -5.0808, -5.0808, -3.6325, -4.0727, -5.9241, -4.0363, -6.1428, -4.6233, -5.7652, -6.4214, -4.566, -3.0757, -3.5409, -4.3104, -3.9327, -3.7166, -2.9802, -4.855, -4.5562, -4.1934, -4.8541, -4.8884, -4.6698, -4.3792, -4.7043, -4.7133, -4.9077, -4.8406, -4.9082, -4.9241, -4.9247, -3.5311, -4.1555, -4.1555, -4.4844, -4.5213, -4.5596, -4.5995, -4.8138, -4.8655, -4.8655, -5.1739, -5.1739, -5.1739, -5.2489, -5.2489, -5.33, -5.33, -5.33, -5.33, -5.33, -5.33, -5.33, -5.33, -5.33, -5.33, -5.33, -5.33, -5.33, -5.33, -4.7702, -4.6302, -4.2492, -4.641, -3.9471, -4.4629, -4.3571, -3.9984, -4.3297, -2.7049, -4.1419, -3.5346, -4.5611, -3.3675, -4.7574, -3.4117, -4.4099, -4.5254, -4.7892, -4.3554, -4.6025, -4.6884, -4.6926, -4.7524, -3.3627, -3.4951, -3.8539, -4.134, -4.134, -4.3393, -4.3649, -4.4366, -4.4462, -4.5244, -4.5244, -4.6896, -4.7387, -4.7905, -4.845, -4.845, -4.9027, -4.9027, -4.9639, -4.9639, -4.9639, -5.0291, -5.0291, -5.0291, -5.0989, -5.0989, -5.0989, -5.1739, -5.1739, -5.2549, -4.134, -4.084, -3.3856, -4.6427, -3.5185, -3.5201, -3.7207, -4.3933, -4.0973, -4.6609, -4.297, -4.517, -4.4912, -4.6106, -4.5507, -4.6954, -2.6681, -3.2851, -3.6858, -4.3565, -4.4598, -4.5351, -4.5749, -4.6932, -4.7893, -4.8955, -4.8955, -5.0144, -5.1494, -5.1494, -5.2244, -5.2244, -5.2244, -5.2244, -5.2244, -5.2244, -5.2244, -5.2244, -5.2244, -5.3054, -5.3054, -5.3054, -5.3054, -5.3054, -5.3054, -5.3054, -3.5527, -4.632, -4.3871, -3.9091, -3.9657, -4.3635, -4.4798, -3.8079, -4.2612, -4.7951, -4.5572, -4.4157, -4.7681, -4.9164, -4.8783, -5.0795, -4.9797, -5.0183, -5.0381, -4.3463, -4.3463, -4.4278, -4.5086, -4.8319, -4.8319, -5.0047, -4.4497, -4.2944, -3.4397, -5.2298, -5.295, -5.295, -5.3648, -5.3648, -5.3648, -5.3648, -5.3648, -5.3648, -3.2691, -5.4398, -5.4398, -5.4398, -5.4398, -5.4398, -5.4398, -5.5209, -5.5209, -5.5209, -5.5209, -5.5209, -5.2313, -4.6443, -4.435, -2.8404, -2.784, -4.7448, -3.9583, -4.0594, -3.4203, -4.7121, -4.3693, -3.8904, -4.8319, -4.2553, -4.2144, -4.2033, -4.1574, -4.5002, -4.5478, -4.7525, -3.872, -3.8921, -3.8992, -4.2897, -4.4548, -4.5557, -4.6679, -4.6679, -4.7291, -4.7943, -4.9391, -4.9391, -4.9391, -4.9391, -4.9391, -5.0202, -5.0202, -5.0202, -5.0202, -5.0202, -5.0202, -5.0202, -5.5318, -3.3874, -4.0216, -4.3839, -4.1664, -3.6624, -6.3607, -5.0202, -3.2707, -2.9792, -4.5468, -4.1441, -3.7597, -3.9539, -4.7943, -4.7015, -4.6776, -4.9391, -4.8698, -4.7534, -4.7563, -4.6886, -4.834, -4.8823, -4.8763]}, \"token.table\": {\"Topic\": [10, 16, 15, 16, 3, 15, 1, 2, 7, 9, 3, 1, 11, 11, 6, 7, 9, 20, 7, 3, 5, 6, 9, 15, 10, 13, 18, 1, 13, 4, 12, 20, 12, 14, 10, 3, 18, 9, 17, 13, 13, 14, 9, 13, 3, 18, 17, 19, 18, 7, 9, 17, 19, 10, 9, 12, 14, 2, 9, 10, 17, 6, 11, 10, 1, 10, 20, 17, 13, 1, 2, 3, 4, 5, 9, 10, 11, 13, 15, 13, 4, 19, 1, 10, 12, 13, 14, 17, 19, 1, 1, 12, 6, 17, 17, 19, 10, 6, 3, 15, 5, 4, 3, 5, 13, 16, 18, 3, 15, 4, 15, 19, 7, 19, 4, 7, 17, 19, 4, 15, 1, 2, 9, 16, 19, 2, 9, 11, 12, 13, 13, 19, 1, 8, 10, 13, 14, 19, 17, 16, 17, 3, 5, 12, 10, 13, 16, 13, 16, 6, 20, 15, 12, 16, 19, 19, 2, 19, 19, 16, 18, 9, 12, 1, 12, 8, 17, 19, 19, 5, 2, 19, 10, 1, 7, 13, 16, 6, 4, 10, 12, 12, 1, 8, 9, 10, 13, 14, 19, 1, 14, 16, 10, 6, 20, 13, 14, 13, 7, 12, 20, 8, 10, 17, 5, 15, 4, 6, 1, 4, 1, 12, 11, 17, 10, 5, 16, 7, 11, 12, 17, 1, 12, 2, 3, 6, 1, 6, 2, 1, 12, 13, 15, 20, 1, 5, 10, 4, 16, 17, 5, 11, 14, 12, 11, 20, 14, 19, 14, 15, 9, 4, 7, 18, 14, 19, 20, 6, 8, 1, 3, 7, 9, 12, 15, 18, 7, 13, 19, 1, 3, 5, 12, 15, 1, 3, 5, 7, 9, 11, 19, 6, 8, 14, 17, 3, 8, 3, 5, 16, 1, 2, 15, 16, 1, 6, 13, 20, 3, 9, 10, 17, 2, 2, 5, 14, 19, 20, 16, 18, 9, 8, 10, 11, 2, 19, 1, 3, 5, 6, 8, 11, 14, 16, 18, 20, 4, 11, 4, 6, 9, 16, 13, 15, 3, 3, 4, 5, 7, 8, 10, 2, 5, 6, 16, 18, 3, 6, 8, 12, 1, 2, 4, 5, 11, 13, 14, 20, 2, 16, 11, 18, 3, 5, 9, 13, 8, 5, 10, 13, 7, 16, 3, 3, 4, 6, 3, 4, 13, 6, 20, 3, 8, 16, 7, 9, 16, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 17, 17, 3, 7, 14, 2, 1, 8, 20, 20, 12, 20, 9, 15, 1, 20, 11, 20, 16, 17, 18, 13, 10, 7, 8, 1, 7, 14, 15, 9, 14, 20, 12, 6, 1, 6, 13, 19, 1, 18, 19, 8, 11, 16, 11, 20, 17, 6, 7, 10, 20, 3, 6, 13, 3, 5, 8, 20, 15, 10, 2, 14, 16, 5, 10, 14, 17, 19, 16, 14, 8, 1, 2, 3, 4, 14, 16, 3, 14, 18, 7, 9, 1, 8, 10, 12, 17, 19, 1, 1, 6, 13, 10, 20, 19, 18, 5, 3, 13, 20, 2, 12, 5, 1, 5, 20, 1, 20, 18, 2, 9, 4, 13, 15, 6, 1, 2, 16, 3, 12, 4, 5, 20, 17, 12, 13, 17, 8, 16, 3, 6, 10, 14, 19, 4, 14, 6, 7, 18, 20, 1, 4, 8, 19, 20, 12, 20, 14, 4, 14, 9, 12, 1, 16, 1, 5, 8, 7, 13, 8, 5, 19, 7, 14, 1, 4, 13, 10, 16, 10, 10, 6, 7, 9, 13, 8, 17, 4, 1, 3, 4, 5, 6, 8, 10, 15, 19, 1, 5, 6, 9, 12, 1, 2, 3, 5, 6, 8, 8, 1, 2, 12, 18, 4, 3, 4, 8, 9, 12, 20, 2, 5, 3, 1, 2, 4, 5, 16, 1, 3, 12, 14, 17, 20, 7, 4, 7, 12, 14, 18, 4, 5, 14, 19, 4, 14, 3, 4, 5, 6, 10, 1, 3, 7, 10, 20, 15, 18, 1, 3, 6, 1, 12, 8, 3, 1, 2, 4, 14, 16, 17, 19, 17, 4, 7, 12, 16, 17, 4, 18, 19, 7, 2, 5, 7, 5, 12, 7, 18, 1, 7, 8, 9, 11, 4, 8, 12, 2, 2, 9, 10, 16, 9, 17, 1, 20, 12, 9, 3, 7, 18, 9, 6, 14, 18, 16, 6, 15, 16, 8, 17, 9, 14, 3, 8, 9, 11, 4, 12, 19, 13, 5, 3, 10, 1, 2, 4, 5, 7, 8, 13, 16, 11, 18, 13, 1, 3, 4, 6, 7, 8, 9, 12, 13, 6, 8, 16, 1, 2, 8, 11, 13, 16, 18, 2, 20, 1, 3, 4, 5, 10, 12, 13, 18, 14, 19, 1, 2, 19, 1, 1, 2, 3, 4, 7, 8, 10, 7, 11, 7, 15, 13, 15, 2, 4, 5, 15, 4, 7, 8, 2, 4, 15, 1, 5, 14, 18, 6, 18, 2, 6, 7, 11, 15, 18, 20, 1, 19, 6, 10, 15, 8, 1, 3, 19, 20, 15, 19, 3, 8, 6, 6, 2, 3, 15, 9, 19, 4, 19, 4, 6, 17, 3, 18, 11, 14, 4, 16, 4, 12, 19, 16, 4, 12, 16, 2, 20, 10, 17, 6, 2, 4, 14, 20, 15, 2, 15, 18, 10, 17, 5, 11, 16, 8, 9, 3, 12, 17, 1, 5, 10, 16, 4, 13, 3, 7, 8, 10, 20, 6, 9, 1, 2, 4, 9, 11, 14, 15, 7, 3, 4, 5, 6, 7, 13, 20, 2, 3, 16, 1, 3, 8, 1, 5, 19, 2, 4, 8, 4, 5, 6, 9, 14, 15, 15, 18, 20, 6, 7, 10, 14, 18, 12, 6, 5, 12, 16, 2, 10, 18, 19, 20, 14, 8, 9, 10, 9, 9, 11, 15, 4, 6, 12, 8, 11, 12, 15, 17, 12, 2, 1, 2, 3, 6, 7, 17, 2, 3, 5, 6, 7, 19, 2, 5, 7, 10, 15, 16, 2, 14, 1, 5, 7, 19, 5, 13, 16, 15, 1, 17, 19, 2, 3, 4, 5, 6, 18, 10, 2, 11, 11, 17, 18, 3, 9, 20, 5, 8, 9, 11, 15, 16, 17, 19, 20, 7, 17, 4, 14, 7, 5, 3, 5, 10, 11, 2, 6, 4, 8, 15, 18, 16, 1, 11, 7, 12, 17, 2, 3, 5, 6, 5, 1, 18, 2, 7, 11, 1, 8, 6, 13, 14, 14, 6, 5, 16, 15, 4, 15, 16, 1, 9, 13, 19, 7, 13, 3, 6, 11, 12, 3, 3, 4, 11, 1, 2, 6, 7, 8, 9, 13, 14, 15, 18, 1, 4, 15, 20, 2, 1, 16, 2, 6, 16, 3, 12, 6, 13, 10, 11, 17, 1, 15, 9, 7, 3, 5, 8, 9, 18, 17, 11, 20, 4, 9, 11, 12, 13, 14, 16, 19, 1, 3, 4, 5, 7, 11, 12, 17, 1, 4, 14, 18, 16, 8, 18, 9, 2, 4, 1, 2, 4, 8, 10, 12, 18, 4, 13, 1, 2, 5, 12, 17, 7, 8, 10, 11, 14, 9, 10, 8, 9, 11, 3, 1, 6, 10, 19, 5, 18, 2, 5, 10, 12, 15, 16, 1, 2, 8, 19, 6, 8, 16, 9, 1, 5, 6, 7, 8, 7, 4, 5, 6, 10, 11, 12, 12, 19, 7, 20, 9, 14, 13, 15, 6, 8, 1, 2, 5, 16, 4, 14, 17, 18, 17, 17, 5, 1, 5, 6, 2, 12, 15, 1, 2, 1, 8, 19, 6, 14, 18, 8, 5, 5, 13, 9, 12, 13, 13, 15, 9, 9, 2, 3, 11, 12, 17, 2, 3, 5, 6, 3, 18, 11, 1, 12, 5, 7, 8, 10, 11, 18, 20, 7, 9, 13, 14, 15, 4, 15, 5, 11, 2, 3, 18, 19, 1, 9, 9, 12, 1, 2, 4, 5, 6, 7, 8, 10, 12, 18, 6, 11, 11, 15, 11, 18, 7, 13, 20, 5, 7, 18, 8, 15, 16, 6, 14, 15, 16, 10, 8, 14, 9, 14, 18, 11, 18, 14, 3, 4, 11, 9, 11, 14, 16, 18, 7, 3, 4, 3, 18, 1, 2, 4, 8, 12, 13, 20, 3, 11, 1, 7, 8, 13, 16, 18, 11, 16, 18, 10, 14, 15, 15, 9, 11, 1, 10, 5, 13, 16, 8, 2, 6, 13, 15, 3, 3, 15, 19, 7, 17, 13, 8, 10, 11, 7, 18, 4, 1, 2, 7, 10, 19, 19, 12, 4, 11, 6, 20, 1, 2, 3, 5, 6, 7, 8, 18, 19, 17, 5, 2, 8, 2, 3, 9, 9, 14, 2, 4, 5, 13, 3, 5, 2, 6, 7, 8, 1, 2, 5, 6, 5, 13, 19, 18, 12, 5, 2, 3, 6, 11, 15, 4, 5, 9, 12, 18, 17, 14, 5, 6, 7, 9, 6, 12, 20, 8, 5, 7, 11, 19, 14, 15, 18, 17, 6, 7, 4, 1, 3, 2, 4, 7, 9, 8, 12, 1, 4, 7, 4, 6, 3, 5, 8, 5, 8, 11, 13, 18, 3, 11, 12, 7, 1, 13, 17, 8, 15, 1, 2, 3, 6, 9, 12, 14, 13, 4, 10, 19, 1, 9, 18, 1, 1, 15, 4, 7, 8, 2, 11, 16, 18, 7, 8, 11, 15, 19, 5, 3, 5, 7, 8, 12, 14, 20, 14, 5, 6, 7, 9, 10, 11, 5, 8, 16, 18, 8, 4, 14, 8, 11, 12, 6, 3, 1, 2, 2, 11, 18, 8, 3, 5, 18, 14, 19, 20, 3, 12, 5, 10, 14, 5, 20, 3, 4, 14, 16, 17, 18, 2, 6, 9, 10, 11, 18, 1, 4, 5, 11, 19, 15, 1, 2, 7, 13, 15, 16, 17, 4, 8, 11, 20, 4, 5, 9, 12, 13, 18, 15, 12, 10, 17, 9, 10, 2, 2, 3, 5, 11, 20, 10, 3, 11], \"Freq\": [0.2817564121895681, 0.6574316284423256, 0.12367979392761892, 0.7420787635657136, 0.9589887783967038, 0.945524170167382, 0.9222336886971668, 0.06114256499649725, 0.010190427499416208, 0.9302820878307829, 0.9670870252838325, 0.921796882175224, 0.7856221925353671, 0.8558956309489641, 0.95188624088447, 0.8897388218228564, 0.9183758799514705, 0.8204644500321931, 0.9138978541634569, 0.9351976284765178, 0.08510344906874419, 0.8510344906874419, 0.5650147242451579, 0.3766764828301053, 0.966045550276543, 0.9406778572270736, 0.8638249651701057, 0.888764139291677, 0.737159371531322, 0.7835425134063717, 0.14246227516479487, 0.8204644500623994, 0.8368908315947885, 0.8093613663702636, 0.9249695935672507, 0.9670870242459791, 0.9230846920849416, 0.761469012876657, 0.9369686800850824, 0.9693384436882454, 0.9432446819238558, 0.9204837905289619, 0.8593504992971299, 0.8943044855642617, 0.8589719474928362, 0.9230846920602178, 0.19341690094990824, 0.773667603799633, 0.8174045709493482, 0.8897388219939775, 0.9183758799514705, 0.8251464237671156, 0.8876399870480872, 0.8774542838609304, 0.7614690123507285, 0.7820326654761176, 0.9204837905289619, 0.9666008666014679, 0.18496974755637277, 0.7861214271145843, 0.8634770776724298, 0.9518862381211441, 0.8558956307831368, 0.9249695932572104, 0.8748811545037583, 0.9607212052196467, 0.910134119214124, 0.9804547580150819, 0.9090889128675774, 0.04081920302333353, 0.23266945723300111, 0.008163840604666706, 0.06531072483733365, 0.20817793541900098, 0.008163840604666706, 0.14286721058166735, 0.04898304362800023, 0.07347456544200034, 0.17144065269800082, 0.9538299989761225, 0.9115588226173056, 0.7447986662404816, 0.20826737748812127, 0.0773564544955879, 0.029752482498303038, 0.20826737748812127, 0.14876241249151517, 0.10115844049423033, 0.22016837048744248, 0.967776423091018, 0.9167619790600615, 0.07639683158833846, 0.7631060357728419, 0.20349494287275782, 0.7749039296470972, 0.7447986643668338, 0.8337898238669401, 0.8681913230104772, 0.9586235912582974, 0.8454784777894614, 0.8528995408591791, 0.9095704010620937, 0.940313279642806, 0.26779032658960955, 0.15302304376549117, 0.5355806531792191, 0.9869377574274, 0.4430850127391454, 0.5415483489034, 0.9095704007888946, 0.661490215891337, 0.24805883095925138, 0.8280325027248061, 0.8789383824040524, 0.1740882791913606, 0.21761034898920076, 0.5222648375740818, 0.06528310469676023, 0.3519606761941069, 0.6335292171493925, 0.9552712415647128, 0.13147936420275289, 0.6179530117529386, 0.07888761852165173, 0.17092317346357874, 0.2886158370155541, 0.33880989562695485, 0.13803366118135196, 0.15058217583420214, 0.07529108791710107, 0.8659291708505983, 0.8343042647717352, 0.3994355108870789, 0.19971775544353945, 0.2207406770691752, 0.04204584325127147, 0.0630687648769072, 0.07358022568972507, 0.8902340501583248, 0.7906274900650434, 0.8727161278494446, 0.10371272159403919, 0.8297017727523135, 0.8168979347966487, 0.9249695936930719, 0.9740696322068056, 0.9235631856976331, 0.9184804130989072, 0.8416733912108761, 0.8841391637689241, 0.7664719243345618, 0.8322424674800472, 0.8368908316079522, 0.8997656657457783, 0.8876399870480872, 0.8904398974783789, 0.8872868309568853, 0.8789383822562968, 0.7870148187433166, 0.8997656657457783, 0.9230846920277114, 0.9183758799514705, 0.86423913832196, 0.8887641391522904, 0.9483732592984708, 0.7810385925854989, 0.15764263807265805, 0.8276238498814548, 0.787014819112755, 0.8548896028323907, 0.9482096218798496, 0.8343042652965151, 0.792473388934397, 0.8754824206591638, 0.09215604427991198, 0.7081956170791164, 0.2575256789378605, 0.8841391632492309, 0.9095704016000207, 0.7595188788321839, 0.8368908315813017, 0.7820326654463187, 0.34565081985410484, 0.02383798757614516, 0.3158533353839234, 0.04171647825825403, 0.02383798757614516, 0.11918993788072581, 0.1251494347747621, 0.5552958238781316, 0.15424883996614766, 0.24679814394583624, 0.7924733890967423, 0.9518862381331608, 0.8204644500321931, 0.9184804129024124, 0.763288594724884, 0.9432446819945379, 0.8280325027991968, 0.958774735641441, 0.820464450029861, 0.21321404245913253, 0.6183207231314843, 0.17057123396730603, 0.2448549900272505, 0.7345649700817515, 0.8566639521661235, 0.9344647346873521, 0.8903744272021671, 0.9710406819024564, 0.8873909885979281, 0.7820326659208057, 0.878231756501464, 0.8995217771584778, 0.7924733889375275, 0.954168519278773, 0.9663281938524061, 0.9138978541461148, 0.49482824908019735, 0.45948337414589757, 0.7749039282442447, 0.7709179191108689, 0.16229850928649872, 0.2030457617522558, 0.7014308133259746, 0.07383482245536574, 0.2749916446551413, 0.6874791116378532, 0.9181748674691302, 0.1611740032192478, 0.826016766498645, 0.9245316468390863, 0.6661379047281105, 0.9033593793453238, 0.9469874768771157, 0.8452486230524182, 0.895673201108756, 0.9554657607154821, 0.8997656657425323, 0.863477077620349, 0.40619020341468803, 0.3610579585908338, 0.1805289792954169, 0.8368908316094423, 0.8964154909816712, 0.8204644500424338, 0.5417006489187411, 0.38692903494195796, 0.9204837905524208, 0.8852740871379563, 0.9469045192356519, 0.22756799194891747, 0.7585599731630582, 0.8638249656343718, 0.9027233547643395, 0.4047345823250586, 0.5396461097667448, 0.8372654752496305, 0.14561138699993575, 0.20834915174702837, 0.04166983034940567, 0.2916888124458397, 0.22223909519683024, 0.01388994344980189, 0.09722960414861323, 0.12500949104821701, 0.8483642126440688, 0.555832285997134, 0.41687421449785045, 0.12775359701385477, 0.830398380590056, 0.2620032982986136, 0.23289182070987874, 0.4657836414197575, 0.28108186037775906, 0.18738790691850604, 0.04684697672962651, 0.09369395345925302, 0.18738790691850604, 0.09369395345925302, 0.09369395345925302, 0.05284127247957984, 0.47557145231621856, 0.42273017983663874, 0.8190212910381595, 0.23071922987470533, 0.692157689624116, 0.6651858493418482, 0.11086430822364138, 0.1847738470394023, 0.40318884319872306, 0.27416841337513165, 0.3225510745589784, 0.862461696441012, 0.9638764846616854, 0.8966221021727049, 0.444678571489702, 0.444678571489702, 0.9735390864161307, 0.8593504990677517, 0.8566347506883115, 0.12237639295547308, 0.9266557159970702, 0.2624745268377423, 0.19685589512830673, 0.0874915089459141, 0.2406016496012638, 0.21872877236478527, 0.7513382448364483, 0.10733403497663546, 0.912643119581416, 0.4259408456081779, 0.21297042280408895, 0.3833467610473601, 0.9266557172427498, 0.7870148190368401, 0.17174072774473848, 0.11665407922284124, 0.10045212377522439, 0.05832703961142062, 0.24302933171425256, 0.13285603467045806, 0.048605866342850516, 0.0810097772380842, 0.01296156435809347, 0.03888469307428041, 0.881160387826622, 0.06294002770190157, 0.8249766028047365, 0.16499532056094732, 0.8593504994881732, 0.909994114906664, 0.3641003710686608, 0.5461505566029912, 0.9670870255180207, 0.5749354811482841, 0.04599483849186273, 0.06899225773779409, 0.09198967698372545, 0.12648580585262248, 0.08049096736075977, 0.24406552636072198, 0.22187775123702, 0.421567727350338, 0.11093887561851, 0.8174045708067766, 0.08798170505372652, 0.24194968889774793, 0.35192682021490607, 0.3079359676880428, 0.01836020618386489, 0.5140857731482169, 0.12852144328705423, 0.09180103091932446, 0.07344082473545956, 0.165241855654784, 0.9204837892390821, 0.7664719243682042, 0.9005330048376209, 0.8997656657466062, 0.6341947592041283, 0.28186433742405703, 0.16058929283044476, 0.4817678784913343, 0.12044196962283357, 0.16058929283044476, 0.8631154834394135, 0.8548896032123385, 0.6263428612602019, 0.27837460500453415, 0.8897388218603086, 0.8997656657457783, 0.9566779650007395, 0.043825743434257894, 0.9115754634325642, 0.043825743434257894, 0.5145159041029592, 0.4603563352500161, 0.8921492532981153, 0.928569003360201, 0.846657471391466, 0.10772114610045189, 0.7181409740030126, 0.17953524350075314, 0.9490417548103328, 0.8593504994059886, 0.9545195359419568, 0.033777671137230826, 0.20266602682338497, 0.15762913197374387, 0.11259223712410275, 0.163258743829949, 0.016888835568615413, 0.0450368948496411, 0.033777671137230826, 0.06755534227446165, 0.06755534227446165, 0.02814805928102569, 0.02814805928102569, 0.0450368948496411, 0.9803726195124082, 0.32411909733861893, 0.08102977433465473, 0.48617864600792843, 0.9596184404149674, 0.9234999160723363, 0.8936033666199199, 0.8242557584176221, 0.9101341192182753, 0.8368908316093239, 0.820464450023004, 0.9451626174907201, 0.9455241699797116, 0.9677737818125348, 0.7664719243677521, 0.855895631023881, 0.9539758502231693, 0.8997656656926634, 0.9422543889129092, 0.9798548920465295, 0.773850861941803, 0.943410124172992, 0.9127645516722707, 0.928138953750907, 0.2160328508895067, 0.4560693518778474, 0.16802555069183853, 0.14402190059300446, 0.7219587710746906, 0.09024484638433633, 0.09024484638433633, 0.9174049667967433, 0.9650586669794274, 0.2100813267665279, 0.2941138574731391, 0.2310894594431807, 0.2520975921198335, 0.27072876182624195, 0.6768219045656049, 0.7870148192843422, 0.9162246835701243, 0.4222709483480473, 0.5278386854350591, 0.5063624326377396, 0.40508994611019167, 0.9112594294064208, 0.10814995821235307, 0.336466536660654, 0.18024993035392178, 0.37251652273143837, 0.6914150883077408, 0.24260178537113714, 0.060650446342784284, 0.9026605255200835, 0.953456675209061, 0.9434747305156279, 0.8647495609295429, 0.8454784777983361, 0.7924733889375275, 0.7994000975618528, 0.08642163216884896, 0.1080270402110612, 0.10358039521606373, 0.3107411856481912, 0.20716079043212746, 0.3625313832562231, 0.8343042645250738, 0.8997656657425323, 0.9149913753577159, 0.8823088088716002, 0.09609404176915119, 0.7687523341532095, 0.048047020884575596, 0.048047020884575596, 0.9204837892390821, 0.7906274892475568, 0.7344884733902646, 0.17865935839222652, 0.079404159285434, 0.9138978542219229, 0.8074542184039444, 0.17946697462953254, 0.08157589755887842, 0.07341830780299058, 0.5302433341327097, 0.057103128291214895, 0.08157589755887842, 0.9962687218271726, 0.2048381396338557, 0.6964496747551093, 0.08193525585354228, 0.8675016060548116, 0.5338858715864367, 0.9463307573007232, 0.8638249658456811, 0.8548902908986521, 0.3307015565291026, 0.2139833601070664, 0.44741975295113884, 0.9266557178069752, 0.8368908315947885, 0.9211471981504962, 0.8779680175430721, 0.921147198217383, 0.8787177414629951, 0.2431570941137061, 0.7294712823411182, 0.9230846920277114, 0.9918330859397797, 0.8545065167127759, 0.6276296437290622, 0.1394732541620138, 0.20920988124302073, 0.8999580676813503, 0.7938816136242118, 0.08820906818046798, 0.13231360227070196, 0.20936843896256505, 0.7327895363689776, 0.9095704009565496, 0.2657727499505172, 0.7087273332013792, 0.8251464220400265, 0.5688818034253762, 0.24380648718230408, 0.08126882906076802, 0.8172738169969175, 0.14213457686902914, 0.5139397742258907, 0.2855220967921615, 0.07138052419804038, 0.1142088387168646, 0.8450619137002956, 0.7738179952289197, 0.20635146539437857, 0.3772858316139598, 0.25938400923459737, 0.2122232802828524, 0.11790182237936245, 0.08722371975309857, 0.26167115925929574, 0.5669541783951407, 0.06541778981482393, 0.021805929938274644, 0.25106877481211143, 0.6904391307333063, 0.984333546170397, 0.9741516505379434, 0.8613534164137358, 0.8570635568496461, 0.8368908316079522, 0.8184745769769347, 0.15589991942417805, 0.9393590063224802, 0.8548902908986521, 0.7810385924175542, 0.971857322617645, 0.8659291707853489, 0.975596337676403, 0.8548902908986521, 0.6417608985195544, 0.9033851813766874, 0.9473130324424903, 0.3505833118036256, 0.28046664944290045, 0.3505833118036256, 0.8675016058529552, 0.9574797281037931, 0.924969593939104, 0.7924733889454936, 0.26335469439296827, 0.5469674422007803, 0.18232248073359344, 0.73715937151396, 0.8631154832149831, 0.7749039294289234, 0.856663952092602, 0.20511765888782205, 0.09572157414765028, 0.09572157414765028, 0.09572157414765028, 0.04102353177756441, 0.01367451059252147, 0.2871647224429509, 0.04102353177756441, 0.09572157414765028, 0.03601942779939118, 0.32417485019452064, 0.1440777111975647, 0.32417485019452064, 0.1440777111975647, 0.06035214328492843, 0.2615259542346899, 0.3621128597095706, 0.24140857313971373, 0.04023476218995229, 0.04023476218995229, 0.9225777411044876, 0.4532980317157999, 0.5396405139473808, 0.8368908316094423, 0.95030335331074, 0.9095704009597955, 0.12291501043067266, 0.47117420665091186, 0.10242917535889388, 0.14340084550245144, 0.12291501043067266, 0.020485835071778775, 0.3853586945658332, 0.5780380418487499, 0.9670870234663096, 0.05014784198877422, 0.225665288949484, 0.05014784198877422, 0.6017741038652906, 0.05014784198877422, 0.4461641529940597, 0.04957379477711774, 0.29744276866270647, 0.04957379477711774, 0.04957379477711774, 0.04957379477711774, 0.9773000784466146, 0.38835826727258543, 0.10591589107434149, 0.14122118809912199, 0.14122118809912199, 0.17652648512390248, 0.38823797701537066, 0.6039257420239099, 0.861353417051357, 0.8876399870453477, 0.3849859923412781, 0.48123249042659766, 0.423265268209238, 0.14108842273641267, 0.22574147637826028, 0.0423265268209238, 0.1693061072836952, 0.19765107226673148, 0.09882553613336574, 0.0395302144533463, 0.5138927878935019, 0.1185906433600389, 0.8454784777119051, 0.8638249651928671, 0.9379517794124435, 0.9253956989311154, 0.8681913443602091, 0.8883521917291702, 0.08883521917291703, 0.8631154833242775, 0.925704126601741, 0.1789305017069317, 0.05112300048769477, 0.29395725280424495, 0.28117650268232125, 0.12780750121923692, 0.06390375060961846, 0.012780750121923692, 0.9130358986129689, 0.1616203256203284, 0.4848609768609852, 0.191005839369479, 0.08815654124745186, 0.05877102749830124, 0.7068854312602936, 0.1413770862520587, 0.10603281468904403, 0.9173147124039953, 0.13399875868724495, 0.7593262992277213, 0.08933250579149662, 0.8548902908986521, 0.9622026969212377, 0.8280325027232324, 0.9681233884493379, 0.35946254819365747, 0.5991042469894291, 0.6819291265744962, 0.08524114082181203, 0.17048228164362406, 0.6056725306160478, 0.21376677551154627, 0.17813897959295522, 0.9411970200270848, 0.9904197710864575, 0.5288878266596581, 0.22036992777485753, 0.176295942219886, 0.6725524776626555, 0.2586740298702521, 0.5404662086439282, 0.4203626067230553, 0.8977679110371858, 0.8593504993961453, 0.6352841411037212, 0.28876551868350964, 0.05775310373670193, 0.9527509294271045, 0.5297925283965205, 0.13244813209913012, 0.2980082972230428, 0.7906274896118147, 0.941471015839856, 0.04279413708362982, 0.8997656657425323, 0.3246390664447778, 0.6492781328895556, 0.40956764436531223, 0.546090192487083, 0.902660523760375, 0.08980697572814846, 0.3592279029125938, 0.5388418543688908, 0.8932114375471869, 0.09415130819401414, 0.8473617737461272, 0.9245316466432475, 0.8548902908986521, 0.9670870234214041, 0.8945594633997986, 0.38374131902907843, 0.007106320722760712, 0.0639568865048464, 0.1208074522869321, 0.03553160361380356, 0.08527584867312854, 0.1208074522869321, 0.1847643387917785, 0.5608461829719078, 0.2804230914859539, 0.7738508617100832, 0.08190303445276395, 0.20103472092951152, 0.2978292161918689, 0.052120112833577065, 0.06701157364317051, 0.14146887769113775, 0.08190303445276395, 0.037228652023983615, 0.037228652023983615, 0.6747699906995669, 0.15744633116323228, 0.13495399813991338, 0.17136642383346418, 0.5640811451184863, 0.06426240893754907, 0.04998187361809372, 0.06426240893754907, 0.04998187361809372, 0.028561070638910696, 0.9607587826224103, 0.6159953891914882, 0.11994015273129616, 0.22274599792955, 0.10280584519825385, 0.15420876779738077, 0.017134307533042306, 0.017134307533042306, 0.2741489205286769, 0.08567153766521154, 0.8209253707379172, 0.12961979537967114, 0.2968186028086118, 0.6678418563193765, 0.7870148166096803, 0.9312420625040343, 0.24621063416759803, 0.08689787088268165, 0.2317276556871511, 0.07241489240223471, 0.11586382784357555, 0.2317276556871511, 0.014482978480446943, 0.9033851807827601, 0.8558956310219293, 0.9222450785517267, 0.9197272611018853, 0.8659291710571293, 0.7782892098006942, 0.41182266816176843, 0.09805301622899248, 0.45104387465336543, 0.039221206491596994, 0.18558336823016952, 0.7887293149782205, 0.8158259238928809, 0.6782346867734912, 0.2712938747093965, 0.0542587749418793, 0.2484752669586735, 0.5714931140049491, 0.012423763347933674, 0.16150892352313778, 0.8841391638257495, 0.8619528745609032, 0.5305142522752901, 0.43104282997367327, 0.016578570383602817, 0.8428066845491513, 0.37675580906521344, 0.25117053937680894, 0.31396317422101117, 0.8554704418185928, 0.11406272557581236, 0.8224016299656077, 0.06853346916380064, 0.4676399479234963, 0.9647749284768977, 0.3278941433276664, 0.4684202047538092, 0.07026303071307137, 0.1171050511884523, 0.4122382929820602, 0.5496510573094137, 0.906712251527483, 0.9503885716878976, 0.9611941571217557, 0.9293499340671919, 0.1214682104580254, 0.8097880697201694, 0.0607341052290127, 0.918375879944787, 0.8343042653768556, 0.3141872530438666, 0.6283745060877332, 0.7304480166052518, 0.26911242717035594, 0.899521777268579, 0.8956957840713075, 0.06889967569779289, 0.7977561653711807, 0.9430917277316573, 0.9785817337736193, 0.8997656657466062, 0.8566639521661235, 0.7820326649504495, 0.7068809626110706, 0.8997656657466062, 0.9095704018475171, 0.8112298068006715, 0.1352049678001119, 0.9444566018869324, 0.7664719231880724, 0.9249695936339459, 0.936968679974629, 0.8342655074707653, 0.8970081442273975, 0.9394008338790498, 0.8999909186057743, 0.06428506561469817, 0.8454784777894614, 0.9607587826732609, 0.8957306369356711, 0.9230846920849416, 0.29776913371145264, 0.6550920941651959, 0.8548896028323907, 0.7977561655977397, 0.9099941151912269, 0.8407917421222663, 0.944890961279976, 0.9060227380261665, 0.08236570345692423, 0.9130358985135237, 0.11617624227745398, 0.2710778986473926, 0.03872541409248466, 0.5421557972947852, 0.9554657603758291, 0.8676489496471126, 0.6571301885446492, 0.20652663068546118, 0.018775148244132834, 0.09387574122066417, 0.018775148244132834, 0.8175557095144631, 0.17211699147672907, 0.4246496693080625, 0.2547898015848375, 0.07549327454365555, 0.018873318635913888, 0.06605661522569861, 0.1038032524975264, 0.06605661522569861, 0.9490501187818948, 0.34484759201901083, 0.1358490514014285, 0.07314948921615382, 0.33439766498813167, 0.04179970812351646, 0.04179970812351646, 0.02089985406175823, 0.738237655532726, 0.2555438038382513, 0.8695293578941562, 0.3205636745300274, 0.4407750524787876, 0.2203875262393938, 0.07870656407039564, 0.8460955637567531, 0.05902992305279673, 0.3980726528788531, 0.47271127529363804, 0.12439770402464158, 0.023361036481478616, 0.47890124787031163, 0.1284857006481324, 0.16352725537035032, 0.04672207296295723, 0.1401662188888717, 0.18098372512080313, 0.21718047014496375, 0.57914792038657, 0.10710681148823077, 0.10710681148823077, 0.2907184883251978, 0.3366214075344396, 0.15300973069747253, 0.8838118004733239, 0.95188624088447, 0.8550872229084846, 0.2956208739298768, 0.6651469663422227, 0.4056244712787587, 0.17383905911946804, 0.14486588259955668, 0.08691952955973402, 0.17383905911946804, 0.8592515768852118, 0.44502169740083863, 0.14834056580027954, 0.3856854710807268, 0.8961333891794737, 0.22490081601531314, 0.4947817952336889, 0.2698809792183758, 0.8294266273792233, 0.09215851415324704, 0.9257106215940215, 0.178188057172296, 0.118792038114864, 0.089094028586148, 0.564262181045604, 0.059396019057432, 0.9690124958214753, 0.9266557173778823, 0.042113857945729506, 0.42113857945729505, 0.021056928972864753, 0.32287291091725956, 0.035094881621441254, 0.14739850281005326, 0.33718257187421297, 0.2247883812494753, 0.3773233542401907, 0.05619709531236883, 0.868339056456395, 0.7870148131592029, 0.10841220870627584, 0.06504732522376551, 0.4986961600488689, 0.02168244174125517, 0.17345953393004135, 0.10841220870627584, 0.8872868309568853, 0.9204837905289619, 0.11912168399198206, 0.6617871332887892, 0.0794144559946547, 0.13235742665775785, 0.2662842933287032, 0.2662842933287032, 0.39942643999305477, 0.9160729452181503, 0.7792679346610303, 0.06111905369890434, 0.13751787082253475, 0.3052598705083543, 0.25438322542362857, 0.2340325673897383, 0.06105197410167086, 0.142454606237232, 0.010175329016945144, 0.7924733889199168, 0.9005330055136044, 0.8428066848507463, 0.7856221928467242, 0.9347027366404294, 0.8876160281022524, 0.19744878171132088, 0.7897951268452835, 0.8001273215548563, 0.1082409545615828, 0.12177107388178066, 0.08569075569458638, 0.07216063637438853, 0.04510039773399283, 0.22550198866996415, 0.09471083524138495, 0.17589155116257205, 0.06314055682758997, 0.9033851808163584, 0.9508194962522563, 0.9095704011119158, 0.8613534170464859, 0.9290334512209375, 0.8548902908986521, 0.39427625786617937, 0.22530071878067393, 0.2628508385774529, 0.11265035939033696, 0.15514840933649507, 0.7757420466824754, 0.08093011432158172, 0.6474409145726537, 0.16186022864316343, 0.08093011432158172, 0.8997656657425323, 0.32266419348081726, 0.6453283869616345, 0.8011772051896363, 0.08901968946551515, 0.08901968946551515, 0.655056446286116, 0.15413092853790963, 0.11559819640343223, 0.07706546426895482, 0.9076711283156711, 0.9520602094819561, 0.9230846920860424, 0.04176647385614884, 0.8353294771229768, 0.08353294771229768, 0.23226595733146385, 0.6967978719943916, 0.8221757868663183, 0.07830245589203032, 0.0978780698650379, 0.809361365827755, 0.8841391627940979, 0.4714791659849056, 0.4714791659849056, 0.8298374597523693, 0.8819462347139232, 0.8852740874750225, 0.8997656656926634, 0.5235812899585243, 0.13574329739665442, 0.15513519702474793, 0.1745270966528414, 0.5937929161586761, 0.3492899506815742, 0.651059960283988, 0.13706525479662907, 0.034266313699157266, 0.17133156849578632, 0.9791089399573678, 0.1768522322874756, 0.29475372047912596, 0.47160595276660155, 0.27452997604121093, 0.12306516167364628, 0.08046568263276872, 0.06153258083682314, 0.1135986107756735, 0.0993987844287143, 0.023666377244931976, 0.14199826346959188, 0.00946655089797279, 0.07573240718378232, 0.26936985505683614, 0.19240703932631154, 0.3463326707873608, 0.19240703932631154, 0.8872868305872664, 0.9799705340626217, 0.8997656657466062, 0.8596632410722926, 0.08596632410722926, 0.02865544136907642, 0.9026605239243368, 0.8642391382234823, 0.8681913234579958, 0.9207052162770487, 0.5168004567820451, 0.33859340271927096, 0.14256564325021934, 0.8748812343613661, 0.845478477780778, 0.8129426686098233, 0.9173147123371068, 0.1710936155816398, 0.25664042337245974, 0.19960921817857977, 0.19960921817857977, 0.14257801298469985, 0.9347027365660764, 0.8428066848600919, 0.9721525016073356, 0.3134239417929821, 0.3134239417929821, 0.0482190679681511, 0.0482190679681511, 0.0964381359363022, 0.02410953398407555, 0.16876673788852883, 0.8450619135464587, 0.4069510215426749, 0.23097220141611274, 0.032996028773730396, 0.09898808632119119, 0.043994705031640526, 0.021997352515820263, 0.054993381289550655, 0.10998676257910131, 0.9591602890903084, 0.9741516507332999, 0.9204837905496648, 0.8212422047422316, 0.8416733908501239, 0.8631154835753652, 0.863824965134654, 0.8593504987488662, 0.9005330083907235, 0.9554657608427626, 0.025498913907359477, 0.19124185430519608, 0.28048805298095425, 0.1274945695367974, 0.07649674172207843, 0.24223968211991503, 0.050997827814718955, 0.4880142420986547, 0.4880142420986547, 0.2979159716358885, 0.39722129551451807, 0.13902745343008133, 0.0198610647757259, 0.13902745343008133, 0.5716947063318677, 0.1242814578982321, 0.1242814578982321, 0.14913774947787853, 0.8919116552090605, 0.7614690125822701, 0.9683832359190023, 0.7703615807868229, 0.18126154842042894, 0.968165197121103, 0.9403132800292551, 0.12287241331020818, 0.3276597688272218, 0.36861723993062456, 0.1638298844136109, 0.5635060535900043, 0.37567070239333616, 0.9746607863374798, 0.19989308664161687, 0.3331551444026948, 0.03331551444026948, 0.03331551444026948, 0.39978617328323374, 0.9868907673999311, 0.9321536561927033, 0.9688252664347268, 0.8876399869999781, 0.9381900217478181, 0.8158259239651559, 0.8997656657425323, 0.918375879944787, 0.9664730778241198, 0.3861695672720271, 0.11585087018160814, 0.038616956727202716, 0.42478652399922984, 0.8940617673352054, 0.08681183815620477, 0.5208710289372287, 0.08681183815620477, 0.04340591907810239, 0.17362367631240955, 0.04340591907810239, 0.883811800473063, 0.8343042644064058, 0.7482809958436203, 0.2494269986145401, 0.8890443511282925, 0.7632885945846051, 0.18349741551510115, 0.8073886282664451, 0.927325086421568, 0.8631154833652809, 0.8748811546379628, 0.9476590088337609, 0.8548896029038426, 0.9545195358364065, 0.3340826882681569, 0.1518557673946168, 0.2733403813103102, 0.24296922783138686, 0.8650608157776448, 0.8190212906787059, 0.8548896029038426, 0.04093978607241825, 0.163759144289673, 0.7778559353759468, 0.8657892796221975, 0.057719285308146503, 0.057719285308146503, 0.7356277410010718, 0.21017935457173478, 0.32794798929713725, 0.6558959785942745, 0.8876399869999781, 0.20289788784393198, 0.608693663531796, 0.10144894392196599, 0.7810385926070734, 0.9645537918738127, 0.9548663112739539, 0.9245316466858791, 0.7359993820970429, 0.24533312736568094, 0.8459411730300744, 0.8921492534344274, 0.9455241703131365, 0.8593504994062805, 0.941847454016936, 0.1596635926860081, 0.11974769451450608, 0.23949538902901216, 0.23949538902901216, 0.19957949085751014, 0.4752274076946314, 0.3320866222444412, 0.14314078545019018, 0.045805051344060856, 0.9257041249733391, 0.8638249651389615, 0.963597928820356, 0.9419462662369825, 0.917404966686773, 0.19395672288077426, 0.2041649714534466, 0.43895468862491016, 0.061249491436033976, 0.0714577400087063, 0.01020824857267233, 0.01020824857267233, 0.1253946289968311, 0.2194406007444544, 0.6269731449841555, 0.24592535025704845, 0.7377760507711454, 0.9810670965699131, 0.885274086818542, 0.9534566741028772, 0.9347325463621048, 0.6090072030029948, 0.1853500183052593, 0.07943572213082542, 0.10591429617443389, 0.4325214672140758, 0.5111617339802714, 0.900549219893383, 0.9861803647253662, 0.17972207663435444, 0.272754681009785, 0.08457509488675503, 0.05708818904855965, 0.11629075546928817, 0.029601283210364263, 0.18817958612302996, 0.0042287547443377515, 0.054973811676390774, 0.008457509488675503, 0.45800385722914705, 0.5234329796904538, 0.640812200435101, 0.21360406681170033, 0.4716964586626188, 0.863824965628864, 0.8897388218228564, 0.9207052164237765, 0.7664719243162714, 0.3263258464929454, 0.6526516929858908, 0.9054066799542658, 0.45219848668405344, 0.06459978381200764, 0.3875987028720458, 0.30965797628324626, 0.082575460342199, 0.495452762053194, 0.10321932542774874, 0.816756832656332, 0.8158259237823547, 0.9551519090441887, 0.7614690127829847, 0.7647763016684685, 0.20394034711159162, 0.8558956310219293, 0.8638249656432136, 0.9204837905458879, 0.8796594807832548, 0.9095704010253908, 0.7856221928085986, 0.7866543162642474, 0.11237918803774963, 0.8592515763192905, 0.891967273006603, 0.8638249656605654, 0.828032502950305, 0.8031758689268975, 0.1840611366290807, 0.7014997910809629, 0.25509083312035014, 0.17109840498518575, 0.3110880090639741, 0.13998960407878833, 0.16332120475858639, 0.03888600113299676, 0.12443520362558963, 0.04666320135959611, 0.9353663502976066, 0.47169645869822474, 0.1742177314155541, 0.0653316492808328, 0.5226531942466623, 0.10888608213472131, 0.1306632985616656, 0.9086578038660371, 0.564482615018869, 0.18816087167295634, 0.18816087167295634, 0.29636604849790027, 0.3951547313305337, 0.24697170708158356, 0.8454784777689606, 0.8896504046281997, 0.855895632265766, 0.22525217577603465, 0.6757565273281039, 0.8941956497835343, 0.2505685425040706, 0.6890634918861942, 0.9162246829371523, 0.9686835882152355, 0.9462948385486211, 0.5223904134609151, 0.39179281009568634, 0.9764537519506229, 0.35434973532352887, 0.08858743383088222, 0.5315246029852934, 0.34197682254228706, 0.5984594394490024, 0.8173047872892275, 0.8825920941386327, 0.7381941535606279, 0.22145824606818837, 0.69796940451391, 0.2538070561868764, 0.9095704036658463, 0.664682135853376, 0.18549268907536073, 0.15457724089613395, 0.864658725697699, 0.834304265224443, 0.783048033389528, 0.917404966756733, 0.5888453095369179, 0.3680283184605737, 0.8716871552121361, 0.10896089440151702, 0.24750312726785728, 0.02605296076503761, 0.15631776459022564, 0.13026480382518804, 0.05210592153007522, 0.23447664688533848, 0.07815888229511282, 0.05210592153007522, 0.02605296076503761, 0.8910724963714841, 0.9076711287358802, 0.9764785317838676, 0.7810385928605937, 0.31502275241078787, 0.2700195020663896, 0.3600260027551861, 0.29090671270281915, 0.6545401035813432, 0.8872868309568853, 0.597421451410595, 0.3676439700988277, 0.9502620060646761, 0.9670870241047881, 0.9062572252761885, 0.48535707878319784, 0.42825624598517453, 0.02855041639901164, 0.02855041639901164, 0.11798723469830535, 0.29043011618044395, 0.30858199844172174, 0.2722782339191662, 0.3630593314835485, 0.48407910864473136, 0.12101977716118284, 0.8939828249258538, 0.894850969574698, 0.9282645928159587, 0.23530174013413496, 0.02240968953658428, 0.4369889459633935, 0.3025308087438878, 0.9214426062723419, 0.9410247927040373, 0.11604074682870905, 0.8122852278009633, 0.5857206916143365, 0.3904804610762243, 0.8634770777320518, 0.9204837905289619, 0.33949694182855594, 0.0727493446775477, 0.2667475971510082, 0.2909973787101908, 0.8019423810174572, 0.17433530022118635, 0.820464450029861, 0.7810385927022432, 0.35881757934961533, 0.03588175793496153, 0.25117230554473075, 0.28705406347969226, 0.9204837905377956, 0.3862853650909224, 0.5407995111272914, 0.8513337693964592, 0.06931722740048285, 0.9011239562062772, 0.8819462345926751, 0.9573558809363845, 0.919485720508475, 0.38345126929882484, 0.42179639622870735, 0.057517690394823726, 0.11503538078964745, 0.27264464075573497, 0.6816116018893374, 0.24442942134721593, 0.1777668518888843, 0.5555214121527634, 0.9428220654592651, 0.9925063296812908, 0.23865370093968133, 0.7485047893108188, 0.8209740467245714, 0.32552823064261055, 0.10016253250541864, 0.3505688637689652, 0.10016253250541864, 0.12520316563177328, 0.4291800411379044, 0.5364750514223805, 0.932131458992121, 0.9033851813910946, 0.9627240929979888, 0.920705215934689, 0.8823557809494812, 0.7810385924402314, 0.8454784777541513, 0.006563833681540515, 0.40695768825551193, 0.3675746861662688, 0.019691501044621546, 0.0853298378600267, 0.05251066945232412, 0.05251066945232412, 0.8459411730665483, 0.8960913691321936, 0.11095024998617097, 0.7766517499031969, 0.9469874768756867, 0.9005492200906317, 0.9230846920849416, 0.9379517789941716, 0.8903744269069181, 0.845478477780778, 0.25011176220333564, 0.12505588110166782, 0.5627514649575052, 0.980618583202546, 0.12511421349027244, 0.6255710674513622, 0.25022842698054487, 0.7032206715266194, 0.21096620145798584, 0.4716964585889207, 0.7859894186126708, 0.16842630398842945, 0.9541685194997018, 0.27613736479790946, 0.036818315306387926, 0.18409157653193964, 0.22090989183832757, 0.036818315306387926, 0.1472732612255517, 0.09204578826596982, 0.763288594596629, 0.8941956502938296, 0.29619160531683336, 0.44428740797525, 0.222143703987625, 0.03702395066460417, 0.9277893898693259, 0.09186605955609227, 0.3674642382243691, 0.2755981786682768, 0.2143541389642153, 0.9574467312610456, 0.9569278276452854, 0.8613534170656499, 0.24072207266411252, 0.48144414532822505, 0.24072207266411252, 0.934464868309757, 0.9631125614398666, 0.7163963918497276, 0.28144143965525015, 0.16374324522016898, 0.5731013582705914, 0.24561486783025346, 0.8407917416758703, 0.9460297838691334, 0.9354112884327345, 0.8117148998553477, 0.5717319692349783, 0.06352577435944204, 0.31762887179721017, 0.30683840144089053, 0.6136768028817811, 0.2470141782338435, 0.2470141782338435, 0.494028356467687, 0.3747663741845744, 0.6246106236409574, 0.9403132790350682, 0.2310685286583423, 0.24207179192778716, 0.24207179192778716, 0.13203915923333845, 0.15404568577222819, 0.15731298830753207, 0.30032479585983396, 0.20021653057322264, 0.21451771132845285, 0.11440944604184151, 0.8117148987116471, 0.22953145632487915, 0.5279223495472221, 0.11476572816243957, 0.022953145632487914, 0.06885943689746374, 0.8454784777119051, 0.13298514619068083, 0.26597029238136166, 0.053194058476272336, 0.10638811695254467, 0.18617920466695317, 0.21277623390508935, 0.053194058476272336, 0.0825599663857162, 0.7430396974714458, 0.12383994957857429, 0.0412799831928581, 0.19686639133831776, 0.05468510870508827, 0.3281106522305296, 0.13124426089221183, 0.25155150004340604, 0.043748086964070614, 0.885274086902111, 0.9174049667553207, 0.9354640192094106, 0.9130358984168192, 0.5301539128040607, 0.4307500541532993, 0.869952035773834, 0.9828954610825891, 0.7648551930916695, 0.11767002970641069, 0.058835014853205345, 0.058835014853205345, 0.9279013205695208, 0.4019803805369123, 0.5806383274422067], \"Term\": [\"4\", \"4\", \"8\", \"8\", \"Abraham\", \"According\", \"Allah\", \"Allah\", \"Allah\", \"Almighty\", \"Another\", \"Apostle\", \"Arioch\", \"Arising\", \"Asleep\", \"Attachment\", \"Authority\", \"Awareness\", \"Baba\", \"Babylon\", \"Behold\", \"Behold\", \"Beloved\", \"Beloved\", \"Best\", \"Blessed\", \"Blessings\", \"Boat\", \"Body\", \"Book\", \"Book\", \"Cheating\", \"Coming\", \"Command\", \"Companion\", \"Compassionate\", \"Consciousness\", \"Court\", \"Creation\", \"Creative\", \"Creator\", \"Cruelty\", \"Darling\", \"Darshan\", \"David\", \"Deep\", \"Destiny\", \"Destiny\", \"Divine\", \"Eating\", \"Empire\", \"Engrossed\", \"Enjoy\", \"Everyone\", \"Everything\", \"Faith\", \"Falling\", \"Father\", \"Fear\", \"Fear\", \"Feet\", \"Filth\", \"Flavor\", \"Forever\", \"Forgiving\", \"Friend\", \"Give\", \"Giver\", \"Glance\", \"God\", \"God\", \"God\", \"God\", \"God\", \"God\", \"God\", \"God\", \"God\", \"God\", \"Grace\", \"Great\", \"Greatness\", \"Guru\", \"Guru\", \"Guru\", \"Guru\", \"Guru\", \"Guru\", \"Guru\", \"Hands\", \"Holy\", \"Holy\", \"Home\", \"Home\", \"Honor\", \"Husband\", \"Infinite\", \"Jacob\", \"Jerusalem\", \"Joining\", \"Joseph\", \"Keep\", \"Kind\", \"Let\", \"Let\", \"Let\", \"Light\", \"Like\", \"Like\", \"Listen\", \"Love\", \"Love\", \"Many\", \"Master\", \"Maya\", \"Maya\", \"Maya\", \"Maya\", \"Meeting\", \"Meeting\", \"Merciful\", \"Name\", \"Name\", \"Name\", \"Name\", \"Nanak\", \"Nanak\", \"Nanak\", \"Nanak\", \"Nanak\", \"None\", \"Nothing\", \"One\", \"One\", \"One\", \"One\", \"One\", \"One\", \"Peace\", \"People\", \"Perfect\", \"Pharaoh\", \"Pharaoh\", \"Please\", \"Pleasure\", \"Power\", \"Practicing\", \"Praises\", \"Pride\", \"Primal\", \"Protector\", \"Pure\", \"Renounce\", \"Restrain\", \"Robe\", \"Saints\", \"Salt\", \"Sanctuary\", \"Says\", \"Search\", \"Searching\", \"Seat\", \"Seek\", \"Serve\", \"Sexual\", \"Show\", \"Siblings\", \"Siblings\", \"Sin\", \"Someone\", \"Son\", \"Source\", \"Sublime\", \"Surely\", \"Surely\", \"Teachings\", \"Teachings\", \"Tell\", \"Telling\", \"Timothy\", \"Touchstone\", \"Treasury\", \"True\", \"True\", \"True\", \"True\", \"True\", \"True\", \"True\", \"Truth\", \"Truth\", \"Truth\", \"Truthfulness\", \"Twenty\", \"Understand\", \"Universe\", \"Value\", \"Vision\", \"Water\", \"Wealth\", \"Wind\", \"Without\", \"Without\", \"Without\", \"Woe\", \"Woe\", \"abolish\", \"abundance\", \"accept\", \"accord\", \"account\", \"acquire\", \"across\", \"action\", \"adore\", \"adorn\", \"advice\", \"affect\", \"age\", \"age\", \"air\", \"alone\", \"alone\", \"also\", \"also\", \"also\", \"among\", \"among\", \"angel\", \"anger\", \"anger\", \"animal\", \"anoint\", \"anxiety\", \"anywhere\", \"appear\", \"appearance\", \"apply\", \"appreciate\", \"approve\", \"around\", \"around\", \"around\", \"arrogance\", \"arrow\", \"article\", \"asleep\", \"asleep\", \"asset\", \"assign\", \"astray\", \"attachment\", \"attachment\", \"avarice\", \"awake\", \"awaken\", \"awaken\", \"awareness\", \"awareness\", \"away\", \"away\", \"away\", \"away\", \"away\", \"away\", \"away\", \"bath\", \"be\", \"be\", \"beast\", \"beast\", \"beauty\", \"beauty\", \"beauty\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"bed\", \"bed\", \"bed\", \"beg\", \"behind\", \"behind\", \"behold\", \"behold\", \"behold\", \"believe\", \"believe\", \"believe\", \"belong\", \"bestow\", \"bird\", \"birth\", \"birth\", \"black\", \"blacken\", \"blame\", \"blame\", \"bland\", \"bless\", \"bless\", \"bless\", \"bless\", \"bless\", \"blind\", \"blind\", \"bliss\", \"blood\", \"blood\", \"blood\", \"blow\", \"boat\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"body\", \"book\", \"book\", \"border\", \"border\", \"bother\", \"bow\", \"breath\", \"breath\", \"brilliant\", \"bring\", \"bring\", \"bring\", \"bring\", \"bring\", \"bring\", \"brother\", \"brother\", \"brother\", \"brother\", \"burden\", \"burn\", \"burn\", \"burn\", \"burn\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"capture\", \"carcass\", \"care\", \"carriage\", \"carry\", \"carry\", \"cast\", \"cast\", \"cast\", \"cast\", \"cave\", \"center\", \"chant\", \"chant\", \"charm\", \"check\", \"cherish\", \"child\", \"child\", \"child\", \"city\", \"city\", \"class\", \"clay\", \"close\", \"clothe\", \"clothe\", \"clothe\", \"cold\", \"collect\", \"color\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"comfort\", \"command\", \"command\", \"command\", \"commit\", \"communication\", \"companion\", \"company\", \"compassion\", \"compel\", \"composure\", \"conceit\", \"conceited\", \"condition\", \"conflict\", \"confuse\", \"conquer\", \"conquest\", \"conscious\", \"consciousness\", \"contemplate\", \"contentment\", \"cool\", \"corn\", \"corruption\", \"corruption\", \"corruption\", \"corruption\", \"could\", \"could\", \"could\", \"counterfeit\", \"country\", \"create\", \"create\", \"create\", \"create\", \"creation\", \"creation\", \"cross\", \"cruel\", \"cry\", \"cry\", \"cure\", \"cure\", \"cut\", \"darkness\", \"darkness\", \"darkness\", \"darkness\", \"day\", \"day\", \"day\", \"dear\", \"death\", \"deceit\", \"deception\", \"decoration\", \"decrease\", \"deed\", \"deed\", \"deed\", \"deep\", \"deep\", \"deep\", \"deep\", \"defeat\", \"defect\", \"delay\", \"delight\", \"deliver\", \"deliver\", \"deliver\", \"deliver\", \"demolish\", \"demon\", \"depart\", \"depart\", \"depart\", \"desert\", \"deserve\", \"desire\", \"desire\", \"desire\", \"desire\", \"desire\", \"desire\", \"destiny\", \"destroy\", \"destroy\", \"destroy\", \"detach\", \"devote\", \"devotion\", \"devotional\", \"diamond\", \"die\", \"die\", \"die\", \"difficult\", \"diffuse\", \"direction\", \"disbelieve\", \"discipline\", \"disease\", \"dispel\", \"dispel\", \"distract\", \"do\", \"dog\", \"door\", \"door\", \"door\", \"doth\", \"doubt\", \"doubt\", \"doubt\", \"draw\", \"draw\", \"dreadful\", \"dream\", \"dream\", \"dress\", \"drink\", \"drink\", \"drink\", \"dust\", \"dust\", \"dwell\", \"dwell\", \"dwell\", \"dwell\", \"dye\", \"ear\", \"ear\", \"earth\", \"earth\", \"earth\", \"earth\", \"eat\", \"eat\", \"eat\", \"eat\", \"eat\", \"ego\", \"ego\", \"egotism\", \"eight\", \"eighty\", \"elephant\", \"eliminate\", \"else\", \"else\", \"emancipate\", \"emerald\", \"emerge\", \"emotional\", \"emperor\", \"empty\", \"encase\", \"endure\", \"energy\", \"engross\", \"enjoy\", \"enjoy\", \"enjoy\", \"enjoyment\", \"enshrine\", \"entangle\", \"entanglement\", \"enter\", \"enter\", \"enter\", \"entertain\", \"entice\", \"entire\", \"eradicate\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"everyone\", \"evil\", \"evil\", \"excessive\", \"expanse\", \"extinguish\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"eye\", \"face\", \"face\", \"fade\", \"faith\", \"faith\", \"faith\", \"faith\", \"faith\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"false\", \"falsehood\", \"falsehood\", \"falsehood\", \"falsehood\", \"falsehood\", \"family\", \"family\", \"famous\", \"fascinate\", \"fast\", \"fast\", \"father\", \"father\", \"father\", \"father\", \"father\", \"fear\", \"fear\", \"fear\", \"fear\", \"fear\", \"fearless\", \"fearlessly\", \"feel\", \"field\", \"fight\", \"fill\", \"fill\", \"filth\", \"finally\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fine\", \"fire\", \"fire\", \"fire\", \"fire\", \"fire\", \"five\", \"five\", \"five\", \"flame\", \"flesh\", \"flesh\", \"flesh\", \"floor\", \"flower\", \"fly\", \"focus\", \"food\", \"food\", \"fool\", \"fool\", \"fool\", \"foot\", \"foot\", \"foot\", \"forbid\", \"forehead\", \"forever\", \"forever\", \"forever\", \"forget\", \"forget\", \"forgiveness\", \"forgiveness\", \"forsake\", \"fort\", \"forth\", \"forth\", \"forth\", \"forty\", \"four\", \"four\", \"four\", \"fourth\", \"friend\", \"friend\", \"frog\", \"fulfil\", \"fulfil\", \"full\", \"full\", \"furnace\", \"garment\", \"garment\", \"garment\", \"gate\", \"gather\", \"gather\", \"genuine\", \"gesture\", \"ghost\", \"gift\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"glorify\", \"glorify\", \"glorious\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"gold\", \"gold\", \"gold\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gossip\", \"grave\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"greed\", \"greed\", \"guard\", \"guard\", \"guest\", \"guide\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"handle\", \"handsome\", \"happiness\", \"hard\", \"harvest\", \"hat\", \"hath\", \"hath\", \"hath\", \"hath\", \"head\", \"head\", \"heap\", \"hear\", \"hear\", \"hear\", \"heart\", \"heart\", \"heart\", \"heart\", \"hearth\", \"heat\", \"heaven\", \"heaven\", \"heaven\", \"heavenly\", \"heavy\", \"heavy\", \"heavy\", \"hereafter\", \"hereafter\", \"high\", \"high\", \"hind\", \"hold\", \"home\", \"home\", \"home\", \"home\", \"honor\", \"honor\", \"honour\", \"hop\", \"horn\", \"hour\", \"house\", \"house\", \"house\", \"huge\", \"human\", \"humble\", \"humble\", \"hundred\", \"hundred\", \"hungry\", \"husband\", \"husband\", \"idiotic\", \"ignorance\", \"ignorant\", \"ignore\", \"illness\", \"illumine\", \"imbue\", \"impure\", \"inclination\", \"increase\", \"increase\", \"indeed\", \"indulge\", \"influence\", \"infuse\", \"inhabitant\", \"inherit\", \"inheritance\", \"inner\", \"inner\", \"inscription\", \"insipid\", \"instant\", \"instinct\", \"intellect\", \"intellect\", \"intensive\", \"intoxicate\", \"iron\", \"issue\", \"join\", \"joy\", \"joy\", \"karma\", \"keep\", \"keep\", \"keep\", \"keep\", \"key\", \"kind\", \"king\", \"king\", \"king\", \"king\", \"king\", \"kingdom\", \"kingdom\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"l\", \"land\", \"land\", \"land\", \"land\", \"land\", \"land\", \"land\", \"law\", \"law\", \"lead\", \"leave\", \"leave\", \"leave\", \"let\", \"let\", \"let\", \"lie\", \"lie\", \"lie\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"light\", \"light\", \"light\", \"like\", \"like\", \"like\", \"like\", \"like\", \"lily\", \"limb\", \"lip\", \"listen\", \"listen\", \"live\", \"live\", \"live\", \"live\", \"live\", \"load\", \"long\", \"long\", \"long\", \"look\", \"lose\", \"lose\", \"lose\", \"lot\", \"lot\", \"lotus\", \"love\", \"love\", \"love\", \"love\", \"love\", \"low\", \"lowly\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"man\", \"man\", \"man\", \"man\", \"manifest\", \"mansion\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"mason\", \"material\", \"may\", \"may\", \"may\", \"may\", \"meditate\", \"meditate\", \"meditate\", \"meditation\", \"meet\", \"meet\", \"meet\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"mental\", \"merchandise\", \"merchant\", \"merciful\", \"mere\", \"merge\", \"might\", \"might\", \"million\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mingle\", \"mistake\", \"mix\", \"moment\", \"moon\", \"mosaic\", \"mother\", \"mother\", \"mother\", \"mother\", \"mountain\", \"mountain\", \"mouth\", \"mouth\", \"mouth\", \"mouth\", \"mud\", \"multitude\", \"multitude\", \"must\", \"must\", \"must\", \"name\", \"name\", \"name\", \"name\", \"naturally\", \"near\", \"nectar\", \"neither\", \"neither\", \"neither\", \"never\", \"never\", \"night\", \"night\", \"night\", \"ninety\", \"ninth\", \"nothing\", \"nothing\", \"number\", \"obey\", \"object\", \"objective\", \"obtain\", \"obtain\", \"obtain\", \"obtain\", \"ocean\", \"ocean\", \"offer\", \"offer\", \"offer\", \"offer\", \"oil\", \"old\", \"old\", \"old\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"open\", \"open\", \"open\", \"open\", \"opportunity\", \"ordain\", \"ornate\", \"others\", \"others\", \"others\", \"outside\", \"overflow\", \"overlay\", \"owe\", \"pain\", \"pain\", \"pain\", \"painful\", \"painfully\", \"palace\", \"parable\", \"pas\", \"pas\", \"pas\", \"pas\", \"pas\", \"past\", \"path\", \"patience\", \"peace\", \"peace\", \"peace\", \"peace\", \"peace\", \"peace\", \"peace\", \"peaceful\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"perfect\", \"perform\", \"permit\", \"person\", \"personal\", \"pervade\", \"physician\", \"pierce\", \"pilgrimage\", \"pitch\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plant\", \"plant\", \"please\", \"please\", \"please\", \"please\", \"please\", \"pleasure\", \"pleasure\", \"pleasure\", \"pleasure\", \"plunder\", \"point\", \"poise\", \"poison\", \"poison\", \"pollute\", \"possession\", \"power\", \"power\", \"power\", \"power\", \"practice\", \"practice\", \"praise\", \"prayer\", \"prayer\", \"prayer\", \"prayer\", \"prayer\", \"pre\", \"preserve\", \"pride\", \"prisoner\", \"produce\", \"protect\", \"puddle\", \"puff\", \"punishment\", \"pure\", \"pure\", \"pure\", \"pure\", \"purify\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"quench\", \"radiate\", \"rain\", \"rain\", \"raise\", \"read\", \"receive\", \"receive\", \"record\", \"reincarnation\", \"reject\", \"rejoice\", \"relation\", \"relative\", \"remain\", \"remain\", \"remain\", \"remain\", \"remember\", \"remembrance\", \"repeat\", \"return\", \"return\", \"return\", \"reveal\", \"reveal\", \"reveal\", \"reward\", \"reward\", \"right\", \"right\", \"rival\", \"river\", \"river\", \"river\", \"rot\", \"ruby\", \"run\", \"sacred\", \"sacrifice\", \"sacrifice\", \"sake\", \"sanctify\", \"sand\", \"satisfaction\", \"satisfy\", \"save\", \"save\", \"save\", \"save\", \"save\", \"say\", \"say\", \"say\", \"say\", \"scent\", \"scorpion\", \"search\", \"secure\", \"seduce\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"seek\", \"seek\", \"seek\", \"self\", \"self\", \"selfishness\", \"sense\", \"sensual\", \"separation\", \"servant\", \"servant\", \"servant\", \"servant\", \"serve\", \"serve\", \"seventy\", \"sexual\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shall\", \"shalt\", \"shalt\", \"shame\", \"shame\", \"sharp\", \"shin\", \"shore\", \"shrine\", \"sickness\", \"sign\", \"sign\", \"silence\", \"silver\", \"silver\", \"silver\", \"sin\", \"sin\", \"sin\", \"sin\", \"since\", \"sinful\", \"sing\", \"single\", \"sit\", \"sit\", \"sixty\", \"skepticism\", \"slanderous\", \"slew\", \"slip\", \"slow\", \"smoke\", \"smoke\", \"snake\", \"social\", \"someone\", \"something\", \"son\", \"son\", \"sorrow\", \"sorrow\", \"soul\", \"soul\", \"soul\", \"soul\", \"soul\", \"soul\", \"soul\", \"source\", \"sowest\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"speech\", \"spirit\", \"spirit\", \"spirit\", \"spiritual\", \"spiritual\", \"spiritual\", \"splendor\", \"stable\", \"stain\", \"star\", \"star\", \"state\", \"status\", \"status\", \"steady\", \"steal\", \"stick\", \"still\", \"still\", \"store\", \"strength\", \"strength\", \"strength\", \"strong\", \"strong\", \"subject\", \"suck\", \"suffer\", \"suffer\", \"sun\", \"sun\", \"supply\", \"surely\", \"surely\", \"surely\", \"survive\", \"sustain\", \"sustenance\", \"swan\", \"sweet\", \"sweet\", \"sword\", \"sword\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"talk\", \"task\", \"taste\", \"tax\", \"tell\", \"tell\", \"tell\", \"temple\", \"temple\", \"temporary\", \"ten\", \"ten\", \"terrify\", \"test\", \"thank\", \"thereof\", \"thereof\", \"thereof\", \"thereof\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"third\", \"thirst\", \"thirsty\", \"thou\", \"thou\", \"thou\", \"thou\", \"thousand\", \"three\", \"throne\", \"throne\", \"throughout\", \"throughout\", \"tie\", \"tight\", \"time\", \"time\", \"time\", \"time\", \"together\", \"together\", \"tolerance\", \"tongs\", \"tongue\", \"tongue\", \"tongue\", \"tongue\", \"touchstone\", \"transitory\", \"transitory\", \"treasure\", \"tree\", \"tree\", \"tribe\", \"trick\", \"trouble\", \"truth\", \"truth\", \"truth\", \"truth\", \"try\", \"try\", \"turn\", \"turn\", \"turn\", \"twenty\", \"two\", \"u\", \"u\", \"unclean\", \"understand\", \"understand\", \"understand\", \"understand\", \"understand\", \"union\", \"union\", \"unite\", \"universe\", \"unjust\", \"unlucky\", \"unsatisfied\", \"unstable\", \"untrue\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"use\", \"utter\", \"vain\", \"vain\", \"vanish\", \"victory\", \"violent\", \"virtue\", \"virtuous\", \"wail\", \"walk\", \"walk\", \"walk\", \"wall\", \"wander\", \"wander\", \"wander\", \"wash\", \"wash\", \"wast\", \"waste\", \"waste\", \"watch\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"water\", \"wave\", \"waver\", \"way\", \"way\", \"way\", \"way\", \"weakness\", \"wealth\", \"wealth\", \"wealth\", \"wealth\", \"wear\", \"weep\", \"weigh\", \"well\", \"well\", \"well\", \"wherein\", \"whole\", \"whose\", \"whose\", \"wicked\", \"wicked\", \"wicked\", \"wickedness\", \"wife\", \"wild\", \"will\", \"wind\", \"wind\", \"wind\", \"wine\", \"wine\", \"wisdom\", \"wisdom\", \"wisdom\", \"wise\", \"wise\", \"wither\", \"within\", \"within\", \"within\", \"within\", \"within\", \"without\", \"without\", \"without\", \"without\", \"without\", \"wive\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"wondrous\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"worldly\", \"worry\", \"worship\", \"worthless\", \"would\", \"would\", \"wrath\", \"write\", \"year\", \"year\", \"year\", \"year\", \"young\", \"youth\", \"youth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [17, 13, 16, 1, 14, 12, 15, 3, 6, 2, 8, 9, 10, 5, 11, 19, 7, 20, 18, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el100801140825905364323713315\", ldavis_el100801140825905364323713315_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el100801140825905364323713315\", ldavis_el100801140825905364323713315_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el100801140825905364323713315\", ldavis_el100801140825905364323713315_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "16     12.199331        1       1 -0.020027  0.226302\n",
       "12     10.523478        1       2 -0.193636  0.124296\n",
       "15      8.777564        1       3 -0.169224 -0.066337\n",
       "0       7.926825        1       4 -0.095746  0.047813\n",
       "13      7.456008        1       5 -0.102503 -0.044005\n",
       "11      6.999531        1       6 -0.161284 -0.034197\n",
       "14      5.137311        1       7 -0.047694 -0.035862\n",
       "2       5.046215        1       8 -0.052346  0.040363\n",
       "5       3.611599        1       9  0.086697  0.066495\n",
       "1       3.598499        1      10  0.058331 -0.079830\n",
       "7       3.431417        1      11 -0.011400 -0.109004\n",
       "8       3.275524        1      12 -0.035744  0.082526\n",
       "9       3.112012        1      13  0.093497  0.132969\n",
       "4       3.068346        1      14  0.091421 -0.019556\n",
       "10      3.066279        1      15  0.049021 -0.072815\n",
       "18      2.795034        1      16  0.093316 -0.056142\n",
       "6       2.656018        1      17  0.134358 -0.026686\n",
       "19      2.642171        1      18 -0.006842 -0.121787\n",
       "17      2.382012        1      19  0.236062  0.092010\n",
       "3       2.294825        1      20  0.053743 -0.146553, topic_info=     Category        Freq           Term       Total  loglift  logprob\n",
       "term                                                                  \n",
       "2866  Default  196.000000          Allah  196.000000  30.0000  30.0000\n",
       "792   Default  221.000000           mind  221.000000  29.0000  29.0000\n",
       "13    Default  472.000000          shall  472.000000  28.0000  28.0000\n",
       "77    Default  308.000000           body  308.000000  27.0000  27.0000\n",
       "3537  Default  168.000000           Guru  168.000000  26.0000  26.0000\n",
       "92    Default  244.000000            God  244.000000  25.0000  25.0000\n",
       "3267  Default  167.000000           True  167.000000  24.0000  24.0000\n",
       "1235  Default  122.000000         desire  122.000000  23.0000  23.0000\n",
       "28    Default  114.000000          child  114.000000  22.0000  22.0000\n",
       "4082  Default  112.000000        destiny  112.000000  21.0000  21.0000\n",
       "30    Default  142.000000           make  142.000000  20.0000  20.0000\n",
       "7     Default  211.000000            one  211.000000  19.0000  19.0000\n",
       "85    Default  174.000000            say  174.000000  18.0000  18.0000\n",
       "511   Default  138.000000           evil  138.000000  17.0000  17.0000\n",
       "2457  Default   83.000000       darkness   83.000000  16.0000  16.0000\n",
       "79    Default  140.000000           give  140.000000  15.0000  15.0000\n",
       "344   Default   92.000000              u   92.000000  14.0000  14.0000\n",
       "3580  Default   76.000000           Name   76.000000  13.0000  13.0000\n",
       "4010  Default   50.000000  consciousness   50.000000  12.0000  12.0000\n",
       "928   Default   90.000000         within   90.000000  11.0000  11.0000\n",
       "276   Default  152.000000           upon  152.000000  10.0000  10.0000\n",
       "25    Default   89.000000           thou   89.000000   9.0000   9.0000\n",
       "710   Default   91.000000          world   91.000000   8.0000   8.0000\n",
       "405   Default   49.000000          anger   49.000000   7.0000   7.0000\n",
       "457   Default   67.000000           love   67.000000   6.0000   6.0000\n",
       "138   Default  140.000000           good  140.000000   5.0000   5.0000\n",
       "245   Default   80.000000          heart   80.000000   4.0000   4.0000\n",
       "407   Default  124.000000            man  124.000000   3.0000   3.0000\n",
       "995   Default   97.000000            see   97.000000   2.0000   2.0000\n",
       "393   Default  128.000000           soul  128.000000   1.0000   1.0000\n",
       "...       ...         ...            ...         ...      ...      ...\n",
       "4210  Topic20    4.066380      composure    4.875287   3.5931  -5.0202\n",
       "4251  Topic20    4.066380     Understand    4.875287   3.5931  -5.0202\n",
       "4252  Topic20    4.066380      Awareness    4.875287   3.5931  -5.0202\n",
       "4125  Topic20    4.066380        article    4.875287   3.5931  -5.0202\n",
       "4174  Topic20    4.066380       Cheating    4.875287   3.5931  -5.0202\n",
       "1950  Topic20    2.437870          grave    3.246778   3.4880  -5.5318\n",
       "4050  Topic20   20.811161         dispel   28.787974   3.4500  -3.3874\n",
       "4045  Topic20   11.037851            ego   15.931890   3.4075  -4.0216\n",
       "1667  Topic20    7.682783          dream   11.287839   3.3898  -4.3839\n",
       "8     Topic20    9.549499           wise   16.009974   3.2578  -4.1664\n",
       "1033  Topic20   15.807902          light   27.626793   3.2162  -3.6624\n",
       "3694  Topic20    1.064152         devote    1.873059   3.2091  -6.3607\n",
       "4095  Topic20    4.066380         awaken    7.412265   3.1741  -5.0202\n",
       "230   Topic20   23.387071            die   51.405866   2.9869  -3.2707\n",
       "2457  Topic20   31.304351       darkness   83.217785   2.7968  -2.9792\n",
       "945   Topic20    6.527915    forgiveness   16.652290   2.8381  -4.5468\n",
       "1004  Topic20    9.765085          bless   45.718722   2.2308  -4.1441\n",
       "792   Topic20   14.342109           mind  221.727535   1.0363  -3.7597\n",
       "77    Topic20   11.811165           body  308.604725   0.5115  -3.9539\n",
       "2533  Topic20    5.096669          heavy   15.925435   2.6352  -4.7943\n",
       "238   Topic20    5.592357           live   34.514683   1.9545  -4.7015\n",
       "1468  Topic20    5.727601           fear   50.594211   1.5960  -4.6776\n",
       "1634  Topic20    4.409810          birth    8.995261   3.0616  -4.9391\n",
       "90    Topic20    4.726268           wind   15.741642   2.5713  -4.8698\n",
       "712   Topic20    5.309395          earth   42.408166   1.6967  -4.7534\n",
       "1356  Topic20    5.294070           home   42.696706   1.6870  -4.7563\n",
       "393   Topic20    5.665048           soul  128.580977   0.6523  -4.6886\n",
       "1173  Topic20    4.898381           open   25.986575   2.1058  -4.8340\n",
       "1240  Topic20    4.667266           rain   20.045945   2.3171  -4.8823\n",
       "196   Topic20    4.695676          water   54.320791   1.3262  -4.8763\n",
       "\n",
       "[1106 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "586      10  0.281756           4\n",
       "586      16  0.657432           4\n",
       "305      15  0.123680           8\n",
       "305      16  0.742079           8\n",
       "1412      3  0.958989     Abraham\n",
       "2232     15  0.945524   According\n",
       "2866      1  0.922234       Allah\n",
       "2866      2  0.061143       Allah\n",
       "2866      7  0.010190       Allah\n",
       "96        9  0.930282    Almighty\n",
       "1647      3  0.967087     Another\n",
       "2950      1  0.921797     Apostle\n",
       "248      11  0.785622      Arioch\n",
       "4197     11  0.855896     Arising\n",
       "4119      6  0.951886      Asleep\n",
       "4121      7  0.889739  Attachment\n",
       "4255      9  0.918376   Authority\n",
       "4252     20  0.820464   Awareness\n",
       "3560      7  0.913898        Baba\n",
       "252       3  0.935198     Babylon\n",
       "312       5  0.085103      Behold\n",
       "312       6  0.851034      Behold\n",
       "2350      9  0.565015     Beloved\n",
       "2350     15  0.376676     Beloved\n",
       "4229     10  0.966046        Best\n",
       "825      13  0.940678     Blessed\n",
       "275      18  0.863825   Blessings\n",
       "3625      1  0.888764        Boat\n",
       "4178     13  0.737159        Body\n",
       "2744      4  0.783543        Book\n",
       "...     ...       ...         ...\n",
       "48        7  0.053194        word\n",
       "48       13  0.106388        word\n",
       "48       15  0.186179        word\n",
       "48       16  0.212776        word\n",
       "48       17  0.053194        word\n",
       "9         4  0.082560        work\n",
       "9         8  0.743040        work\n",
       "9        11  0.123840        work\n",
       "9        20  0.041280        work\n",
       "710       4  0.196866       world\n",
       "710       5  0.054685       world\n",
       "710       9  0.328111       world\n",
       "710      12  0.131244       world\n",
       "710      13  0.251552       world\n",
       "710      18  0.043748       world\n",
       "3906     15  0.885274     worldly\n",
       "1072     12  0.917405       worry\n",
       "990      10  0.935464     worship\n",
       "3495     17  0.913036   worthless\n",
       "109       9  0.530154       would\n",
       "109      10  0.430750       would\n",
       "507       2  0.869952       wrath\n",
       "280       2  0.982895       write\n",
       "270       3  0.764855        year\n",
       "270       5  0.117670        year\n",
       "270      11  0.058835        year\n",
       "270      20  0.058835        year\n",
       "678      10  0.927901       young\n",
       "2169      3  0.401980       youth\n",
       "2169     11  0.580638       youth\n",
       "\n",
       "[1602 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[17, 13, 16, 1, 14, 12, 15, 3, 6, 2, 8, 9, 10, 5, 11, 19, 7, 20, 18, 4])"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(sldamodel, scorpus, sdictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5078 entries, 0 to 5077\n",
      "Data columns (total 6 columns):\n",
      "author          5078 non-null object\n",
      "quote           5078 non-null object\n",
      "no_stopwords    5078 non-null object\n",
      "lemmatized      5078 non-null object\n",
      "stemmed         5078 non-null object\n",
      "auth_label      5078 non-null int64\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 238.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_amodel.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.019*\"one\" + 0.016*\"age\" + 0.010*\"old\" + 0.009*\"year\" + 0.008*\"men\"')\n",
      "(1, '0.010*\"secret\" + 0.009*\"people\" + 0.008*\"forgive\" + 0.008*\"nothing\" + 0.007*\"work\"')\n",
      "(2, '0.025*\"one\" + 0.015*\"man\" + 0.011*\"never\" + 0.008*\"another\" + 0.008*\"learn\"')\n",
      "(3, '0.010*\"make\" + 0.009*\"men\" + 0.009*\"president\" + 0.009*\"man\" + 0.008*\"art\"')\n",
      "(4, '0.019*\"great\" + 0.010*\"human\" + 0.008*\"past\" + 0.007*\"always\" + 0.007*\"America\"')\n",
      "(5, '0.019*\"man\" + 0.015*\"thing\" + 0.010*\"make\" + 0.010*\"world\" + 0.009*\"lie\"')\n",
      "(6, '0.025*\"one\" + 0.014*\"talk\" + 0.012*\"tell\" + 0.010*\"old\" + 0.010*\"life\"')\n",
      "(7, '0.028*\"man\" + 0.023*\"know\" + 0.013*\"love\" + 0.011*\"thing\" + 0.011*\"never\"')\n",
      "(8, '0.036*\"good\" + 0.015*\"one\" + 0.013*\"live\" + 0.013*\"life\" + 0.013*\"know\"')\n",
      "(9, '0.017*\"woman\" + 0.012*\"love\" + 0.011*\"man\" + 0.010*\"play\" + 0.009*\"everything\"')\n"
     ]
    }
   ],
   "source": [
    "data_desc = \"lemmatized\"\n",
    "df_acorpus = pd.DataFrame(df_amodel[data_desc].str.split()).reset_index(drop=True)\n",
    "df_acorpus = df_acorpus[[data_desc]]\n",
    "df_acorpus.head()\n",
    "\n",
    "# a list of each quote as a list of words \n",
    "q_aword_lsts = list(df_acorpus.lemmatized.values)\n",
    "q_aword_lsts\n",
    "aldamodel, acorpus, adictionary = model_topic(q_aword_lsts, num_topics_=10, passes_ = 50, min_proba=.05)\n",
    "_ = [print(i) for i in aldamodel.print_topics(num_topics=10, num_words=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kjrunner/anaconda3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el100801140825901768169422962\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el100801140825901768169422962_data = {\"mdsDat\": {\"Freq\": [14.84811426013576, 14.076502399972357, 12.276567875271494, 10.377219179449558, 10.110778617168373, 9.13275356713922, 8.338833599593078, 8.02115625696981, 6.6032187106307845, 6.214855533669578], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"x\": [-0.10999590192943942, -0.10611808133577502, -0.05229551018672644, -0.08083236937698507, -0.07664214592909917, -0.031053419731905004, 0.04908144839855166, 0.05371908214073638, 0.1763086757336065, 0.17782822221703573], \"y\": [-0.021130078598642764, -0.0051274655968520716, -0.028263227056363256, -0.10562867912296996, -0.026709766407212013, 0.13805222024447159, 0.22243074225390125, -0.07464822499030596, -0.03208628414863368, -0.06688923657739292]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"Freq\": [342.0, 310.0, 569.0, 203.0, 575.0, 147.0, 80.0, 73.0, 205.0, 83.0, 128.0, 158.0, 88.0, 98.0, 182.0, 71.0, 181.0, 246.0, 55.0, 217.0, 65.0, 63.0, 71.0, 192.0, 150.0, 74.0, 36.0, 104.0, 77.0, 53.0, 23.162377620508085, 22.419932028674776, 18.35161021406377, 34.478813736967034, 16.112171406881803, 14.377344096083267, 13.515443002863591, 12.696396789051494, 12.592162678792308, 12.030551180234903, 11.482273358777475, 10.870797047274252, 10.856870029423106, 10.739730341287375, 10.725793131328388, 10.635458321904082, 10.336452781027495, 9.058161352078189, 8.927316612498087, 8.914004556607788, 8.809608543275802, 8.718611151001635, 8.628363077943632, 60.316015250791835, 8.510544371083002, 8.406268791798084, 7.975540448721595, 7.780875124238124, 7.663253507933517, 7.663147176948136, 31.752138194309154, 63.82188378883875, 33.1360894029437, 31.873145113534125, 13.427057307649573, 16.910656720623418, 18.508483084368606, 12.897600515891748, 12.339996361316794, 14.882143050033788, 171.60517993498843, 23.08989139980834, 20.411517981499433, 55.410910551467516, 97.28490735778871, 211.72348518168727, 20.435095312838172, 77.92907757527718, 71.69344870159885, 17.18262910639863, 47.236764717729926, 83.66184228194952, 49.538889640806964, 61.12678359369508, 33.50099317384607, 18.34404364118174, 76.01355897804854, 40.028677270673334, 39.5483989425374, 84.41159996505668, 28.345713371091076, 75.74483536585372, 38.94163046805774, 50.567245806966476, 24.47955681677051, 38.94762255300858, 63.68287349742075, 37.172325576001576, 35.90754802038157, 33.641075015506786, 35.14858862067516, 34.758416869628235, 38.83623788622088, 33.75739508548254, 38.4372760657083, 20.688354966523626, 13.18991314907982, 11.891994326941479, 11.031516573167176, 10.819486093990085, 10.57992371595161, 10.396228607123609, 9.811967137782773, 32.05102308306417, 9.056857449956441, 8.633618574384695, 8.554562742126874, 8.407994266314278, 8.237339655636553, 8.195875984464584, 7.984029029597203, 7.786171196018435, 33.35774366302464, 7.53346216349539, 7.22905297709074, 7.137035411741535, 7.123694526882889, 7.03116323952206, 6.911622955254865, 6.68608453801677, 6.60759825418939, 6.593666726365864, 6.580086428021541, 6.156539340444979, 16.39472511301424, 256.69269344834254, 23.107050830381375, 25.943954203080192, 15.532252068616177, 37.45475504113226, 22.536310119822446, 62.64279089039524, 40.181880064516, 15.175112280039635, 29.76928089633266, 34.66846172794956, 39.49224547239533, 96.33090554436518, 82.61831258357178, 24.187662993193918, 15.045561855460473, 67.48286762307364, 12.896541859191425, 13.056802895813465, 93.9663274192304, 23.404321410425815, 93.460650907937, 53.8269835004644, 70.43919720528112, 35.442742684270684, 25.95921485459198, 108.54814663317204, 30.188913537889857, 47.34599556974126, 33.0030028023519, 67.54878015000357, 64.68181795285177, 48.25754383986772, 47.60908829837932, 40.24052409206672, 35.52601852428741, 32.72542324445121, 44.876654831342954, 35.78927024503005, 38.79059591540395, 27.893992568508565, 23.899003957182146, 22.183188893538336, 16.671085488501703, 16.526808674192978, 15.76814791841223, 15.43451598858722, 13.877267009425966, 13.372583508594106, 12.082040057101839, 11.947892934981137, 11.827722463356272, 11.096988168246678, 10.842030976406832, 10.750316691138327, 19.495040621114914, 10.204858604170068, 9.991163210106372, 8.70141015035766, 8.276070766308955, 8.26178429668493, 8.1280551084753, 8.03504866370695, 8.007907798663576, 7.808484241383151, 7.596136760620382, 15.09891430794113, 7.064277254566027, 7.050625938803672, 7.05055971600226, 12.530079842514462, 45.00601367374181, 12.203263627861576, 11.600012449250777, 46.95981134746227, 12.364476017043305, 27.145795085931617, 53.658105024854706, 16.561388847109047, 12.346422115659742, 27.393115047443043, 21.598375882985387, 92.86182341695795, 23.20144714761444, 119.5558329386346, 62.70685856984668, 18.44866531270882, 52.6303356002467, 52.519664646648316, 64.67704505486826, 27.97741904297136, 43.42103470075908, 16.858476916250662, 35.57306812829057, 40.677780030162175, 44.17982086258496, 20.646362163834755, 28.877971629914068, 42.07193543500654, 35.84136907139992, 28.256663841254642, 25.595045165653545, 26.846412887221838, 24.255421372799432, 22.657947428658666, 26.99039421599773, 29.80429908371204, 24.287651476715865, 23.382755897642582, 32.82024263572328, 32.56248535940744, 32.08949147065484, 31.281005084383093, 19.44423065544069, 16.927891209045928, 16.531521883192596, 14.559219744692163, 14.18950455745363, 14.095709891727662, 13.660643072487135, 13.427184272692429, 13.211173871716044, 12.312675742609168, 11.347617524057327, 11.224494113706792, 10.912713123607162, 10.870359341579748, 10.449247519907578, 10.217437471394081, 10.108610431504038, 9.673559014920443, 18.533721483946888, 9.332903558474406, 9.304482398220614, 27.253318997676377, 28.684246155150518, 7.89044085628907, 7.658754075923852, 7.644865944944448, 27.044619816095263, 16.706710869333666, 20.631937918283786, 47.35219965861893, 14.361086272654555, 41.42928693549936, 24.65855303429451, 20.60945035386123, 13.508845287778918, 22.192398448751455, 23.622126994669863, 50.21468926340055, 34.514001227326006, 25.91651445487687, 53.78403224466576, 33.95211363456918, 31.65523471909666, 27.235585980643318, 21.944341800767234, 34.58927915617587, 30.121604603976568, 45.9080973231692, 31.322343881937226, 34.36880448150951, 27.507908890852875, 28.76463788127537, 33.421270815235225, 26.184263736826587, 24.14882600985797, 22.30086022430017, 23.208281109136628, 22.629260672256144, 34.18330530521484, 23.014224708127305, 19.951326610724138, 15.415645778310811, 14.808988989570423, 13.075586126832038, 12.752052128823506, 10.569390525039383, 10.556108549128073, 9.936252789893377, 9.599464781386516, 9.48284627057952, 9.303025305665052, 9.275910195691244, 9.173132400188702, 8.656634663062409, 8.55322155594394, 8.5393372537855, 8.20330726653081, 8.113115680665372, 8.03676289096113, 7.983220808257781, 7.893027792473828, 7.816558926615145, 7.699902670536484, 7.479325126216897, 7.376525506460346, 7.363284323034047, 6.859965191739541, 6.756559950052799, 23.320506647276584, 14.878569593646041, 39.806093283724564, 11.854275735423803, 21.22268802814169, 43.42033821796156, 15.591695442129602, 34.34191114098028, 26.191770021734897, 16.353103347379985, 41.56255349776128, 14.625406268377974, 130.69083648456376, 19.836853630572396, 28.674483354482607, 36.766239821610704, 57.19049986078856, 40.38742876701777, 17.885262035498048, 76.70533565308561, 28.321784360073668, 24.037406876186104, 25.676828007235812, 38.37561883179297, 30.585119568446974, 28.678382865686277, 25.50917545943587, 29.393164752180446, 20.553604549865128, 18.626386415980217, 20.077698356168952, 18.77294464593715, 19.325182642443146, 19.1083551170232, 31.633079786913157, 29.458716685372966, 12.288052435066058, 10.608505442332074, 10.016743267362278, 9.586980981297486, 9.359222112489034, 8.841990493107282, 8.412250358591717, 8.350700443866163, 66.7214975810783, 8.135799070812014, 7.605130306752724, 7.517591305436605, 7.517545225830869, 7.517454322789424, 6.9869361740274565, 6.898918042318429, 6.8860323884906816, 6.684639939080148, 6.57056093602901, 6.267817451478409, 6.180346022677946, 6.079311025796617, 5.978414405740291, 5.763556450479904, 5.737738548362133, 5.4477202511289775, 5.360126190164093, 5.360080373247638, 21.68210707771663, 10.166721163273637, 13.868314389813344, 55.90868112703378, 20.685208263577145, 27.771267615681946, 9.8633744336761, 10.819626529681788, 15.044788510457833, 26.154581760822346, 9.555880476841672, 14.459137143997339, 19.58746679762508, 14.79251141002234, 45.50673366808811, 117.54360775581723, 15.923094054421526, 10.572686776326766, 15.113377383609714, 31.899483020205587, 20.701767723812225, 18.171740313566776, 41.79789994095859, 25.448010154336686, 15.229612083176262, 38.734692725759835, 44.55968882045674, 30.2784028410862, 37.487259426831784, 43.312581772082815, 24.64044157791413, 36.58608225344223, 28.710061629133477, 18.472550853922883, 19.424919023249405, 25.995609526774043, 21.48942637410602, 19.876592609617507, 17.517390552313653, 18.282418208022335, 18.337698234055363, 28.44657787567376, 19.619665313104253, 19.376252716545107, 19.21179162344877, 18.085870348716153, 17.0797506907351, 14.911448161458512, 12.512777798476156, 11.644467419486135, 11.58209175961555, 10.841992675653442, 10.50940596523016, 10.190226989990533, 9.591268226743521, 9.068370926762585, 8.735991732243026, 8.620857781227409, 8.328119367349052, 8.226115205097221, 7.4988908107141885, 7.396850728033608, 7.2556299266348026, 7.179523854378332, 6.6696589407453395, 6.439460961119245, 6.2488706818103426, 6.2221000496504955, 6.044780388195383, 6.044736863780329, 6.031680878759067, 66.9582664168205, 25.42181204784523, 17.02936496543788, 25.01491141430274, 29.812811018814457, 10.290668436990941, 22.419913954495264, 30.147823861064026, 15.032794246774136, 38.77348770800866, 17.039464958558327, 18.876962144990564, 14.324498087638675, 25.14381233870827, 41.72147352080415, 15.695111927412404, 12.106663364227668, 79.25714922425414, 24.857536892452295, 33.59264296610332, 23.34140122797069, 17.040356440033538, 29.421284534421954, 22.53636153756599, 22.255025238790047, 28.373742924048447, 21.67836158586039, 26.07135023495707, 27.13314577194905, 19.32982868894226, 21.148040918001314, 17.227390982639715, 17.50457118504297, 16.012934375479258, 14.80650570967746, 13.341174770694693, 13.019988668516062, 12.827397602559198, 12.77419011561924, 11.746642839108999, 10.589910011214524, 10.371002631686785, 10.089199906571457, 9.870390783533933, 9.664595496541152, 9.240583662823159, 9.137627166653854, 8.494758767512112, 8.172309209256312, 8.043704634309746, 7.762078346935047, 7.64542336469811, 7.323662886001466, 7.221311123178837, 6.8104012229505795, 6.694473261648815, 6.412774656304553, 6.398985935751808, 6.269714300756215, 6.090871834625154, 5.9748646704661805, 5.858309762909221, 15.036518137303982, 30.86142903388459, 31.389490820033377, 8.905633893412231, 14.604294216980998, 9.226403068842433, 39.92242027906178, 12.333506160092126, 9.065671966003434, 37.42421196056343, 71.12080461434064, 17.726273714583424, 14.459128745750434, 37.688454929045896, 14.152967317166855, 10.420847851643774, 35.88368333309887, 13.65764410625121, 49.52375485460824, 24.869726682806387, 22.04495356815175, 18.68684376094351, 27.315563204042537, 44.009330476460235, 12.797008007093373, 24.792198250441103, 16.895766724755152, 23.72981635798197, 20.90339510108429, 18.091583511893234, 15.920159760432604, 15.969367970068365, 17.236809443712797, 15.220366136761688, 15.004574872469835, 15.746946434107867, 14.763790318516342, 28.487881078576397, 21.91509083684403, 18.983870164984836, 34.82976814969112, 15.998482847981569, 15.184026947413436, 11.871990134070664, 10.643215703403452, 10.569185730241365, 10.416349333177264, 9.628127459541506, 9.514378076247091, 9.114086993048554, 9.49274068801606, 8.486365727857313, 7.972374276704902, 7.67130840849582, 7.357976393782537, 6.86963997771646, 6.856885225361315, 6.856856815713702, 6.843331907977988, 6.643294253985914, 6.555802732040159, 6.555779200306091, 6.255366423083175, 6.255345789272024, 6.041796046933012, 5.928622823207098, 5.928598762128222, 16.542145443408806, 12.809137748986055, 23.821219341573855, 13.802584136526091, 7.872036123069644, 16.373817425002347, 17.07911989203929, 11.4946168219596, 15.83136627825684, 8.035213392260133, 16.612180868025227, 9.635615619564154, 21.110126369135692, 17.399502674996413, 24.82626999929977, 16.606333271423768, 26.833207106058516, 30.003742535254123, 18.98218665656557, 21.15194879646491, 18.489419319160607, 13.339295373371131, 21.802051005737006, 14.481894791364589, 17.082334613716757, 13.048395131320952, 13.76698163971299, 13.03687040838576, 21.17926265321743, 18.724745027808254, 12.63246548596097, 12.034753448458641, 11.797066855787486, 11.497913803147759, 9.77898762502226, 9.67931666716349, 9.142533363890735, 8.606387750807345, 8.346072271197682, 8.220251572141173, 8.034177468577647, 7.722169375232497, 7.6359364427624765, 7.609804238275197, 7.43648361880473, 7.42372814704538, 7.42371557518045, 7.298465220121159, 7.224278538552545, 7.186087890709307, 7.099096696156707, 6.81256447916831, 6.601041105924864, 13.312261179406795, 6.501385434539755, 6.003419993753329, 25.326172565677822, 5.877620795857706, 14.980899231015215, 19.03932188944865, 8.283146744726892, 17.61316436980903, 16.99190310170852, 18.05834414330523, 12.474119021464936, 22.53386916363731, 58.9440610615069, 12.202035362571428, 17.897293854179228, 30.638855756321696, 17.663174474644183, 11.274369188048427, 21.8677903434541, 20.43079471061979, 14.160721916809086, 12.046547943889014, 18.463895372426624, 15.122718224193894, 14.212988938270811, 23.811223909291687, 17.63498534658227, 19.45799002527292, 18.468607317755787, 16.845599541132774, 14.144560774185177, 16.800966488064862, 12.58946201800236, 12.733976377235372], \"Term\": [\"good\", \"know\", \"one\", \"love\", \"man\", \"woman\", \"age\", \"talk\", \"great\", \"tell\", \"old\", \"get\", \"bad\", \"everything\", \"live\", \"write\", \"always\", \"never\", \"play\", \"world\", \"read\", \"heart\", \"president\", \"would\", \"must\", \"year\", \"secret\", \"human\", \"lie\", \"new\", \"alone\", \"ten\", \"thy\", \"marry\", \"disappoint\", \"conviction\", \"mostly\", \"vulgar\", \"interfere\", \"Faith\", \"pig\", \"saint\", \"envy\", \"hurt\", \"smile\", \"nine\", \"pessimist\", \"Work\", \"press\", \"absolute\", \"struggle\", \"otherwise\", \"optimist\", \"read\", \"rid\", \"bore\", \"novel\", \"careful\", \"ignorant\", \"notion\", \"Men\", \"write\", \"difference\", \"rest\", \"account\", \"story\", \"second\", \"sight\", \"thee\", \"sinner\", \"know\", \"someone\", \"none\", \"first\", \"love\", \"man\", \"half\", \"always\", \"like\", \"Women\", \"want\", \"never\", \"book\", \"say\", \"many\", \"enjoy\", \"people\", \"well\", \"person\", \"thing\", \"else\", \"make\", \"come\", \"time\", \"fool\", \"every\", \"one\", \"get\", \"woman\", \"believe\", \"take\", \"go\", \"good\", \"would\", \"easy\", \"Truth\", \"prevent\", \"pray\", \"probably\", \"swear\", \"Imagination\", \"divide\", \"comfort\", \"sure\", \"agreement\", \"unexpected\", \"forbid\", \"Time\", \"immoral\", \"group\", \"fill\", \"alike\", \"least\", \"silence\", \"storm\", \"faithful\", \"shame\", \"combination\", \"ready\", \"kindness\", \"Fortunately\", \"biography\", \"painful\", \"mode\", \"imagine\", \"good\", \"support\", \"clothe\", \"oneself\", \"do\", \"freedom\", \"bad\", \"beauty\", \"talent\", \"joy\", \"value\", \"idea\", \"live\", \"get\", \"full\", \"drink\", \"must\", \"humor\", \"miracle\", \"life\", \"teach\", \"know\", \"way\", \"world\", \"best\", \"show\", \"one\", \"others\", \"nothing\", \"friend\", \"thing\", \"make\", \"time\", \"think\", \"give\", \"work\", \"call\", \"people\", \"u\", \"man\", \"charm\", \"fire\", \"trouble\", \"commitment\", \"shallow\", \"dull\", \"easily\", \"wit\", \"perfection\", \"funeral\", \"punishment\", \"vision\", \"ruin\", \"Iraqi\", \"moon\", \"behind\", \"Words\", \"belong\", \"front\", \"overestimate\", \"secure\", \"alter\", \"due\", \"ahead\", \"train\", \"hungry\", \"determine\", \"gossip\", \"argument\", \"detect\", \"whatever\", \"rich\", \"exercise\", \"door\", \"die\", \"neighbor\", \"poor\", \"lie\", \"philosopher\", \"sad\", \"away\", \"dangerous\", \"thing\", \"pleasure\", \"man\", \"world\", \"whether\", \"u\", \"think\", \"make\", \"nature\", \"great\", \"natural\", \"see\", \"would\", \"people\", \"force\", \"mind\", \"good\", \"never\", \"n\", \"come\", \"without\", \"look\", \"power\", \"love\", \"one\", \"say\", \"live\", \"Congress\", \"free\", \"artist\", \"forward\", \"choice\", \"proper\", \"dance\", \"thoroughly\", \"solve\", \"sick\", \"coward\", \"classify\", \"physical\", \"mad\", \"charity\", \"England\", \"Conscience\", \"perhaps\", \"wild\", \"truly\", \"along\", \"Experience\", \"view\", \"privilege\", \"Science\", \"information\", \"move\", \"consciousness\", \"treat\", \"position\", \"fine\", \"security\", \"step\", \"president\", \"attempt\", \"art\", \"Life\", \"problem\", \"win\", \"earth\", \"important\", \"men\", \"use\", \"kind\", \"make\", \"way\", \"believe\", \"law\", \"place\", \"u\", \"must\", \"man\", \"think\", \"thing\", \"take\", \"time\", \"one\", \"live\", \"find\", \"bear\", \"go\", \"work\", \"cat\", \"happen\", \"produce\", \"regret\", \"fiction\", \"wonder\", \"humanity\", \"tail\", \"towards\", \"stave\", \"obvious\", \"sincere\", \"pure\", \"destroy\", \"notice\", \"tedious\", \"forty\", \"black\", \"tale\", \"selfish\", \"lid\", \"quiet\", \"bed\", \"newspaper\", \"pleasant\", \"trace\", \"sheep\", \"behold\", \"river\", \"eighteen\", \"sit\", \"minute\", \"new\", \"cold\", \"lead\", \"another\", \"wealth\", \"sense\", \"moral\", \"forget\", \"learn\", \"prove\", \"one\", \"Nothing\", \"begin\", \"word\", \"never\", \"go\", \"sometimes\", \"man\", \"may\", \"day\", \"mind\", \"make\", \"would\", \"men\", \"old\", \"life\", \"anything\", \"seem\", \"long\", \"lose\", \"like\", \"time\", \"compliment\", \"walk\", \"oblige\", \"possibility\", \"Fiction\", \"luxury\", \"buy\", \"despise\", \"Though\", \"excess\", \"talk\", \"mental\", \"develop\", \"Books\", \"test\", \"standard\", \"asylum\", \"inventor\", \"respectable\", \"Fortune\", \"tame\", \"contempt\", \"grieve\", \"Except\", \"insane\", \"impressive\", \"Virtue\", \"request\", \"temperament\", \"liberty\", \"large\", \"hardly\", \"period\", \"tell\", \"conversation\", \"music\", \"wait\", \"intelligence\", \"faith\", \"real\", \"demand\", \"stop\", \"money\", \"fashion\", \"old\", \"one\", \"exist\", \"spend\", \"speech\", \"truth\", \"speak\", \"name\", \"would\", \"One\", \"Let\", \"u\", \"life\", \"n\", \"world\", \"thing\", \"person\", \"people\", \"say\", \"wise\", \"could\", \"make\", \"always\", \"every\", \"anything\", \"get\", \"never\", \"youth\", \"temptation\", \"party\", \"smoke\", \"star\", \"necessity\", \"middle\", \"husband\", \"subject\", \"savage\", \"refuge\", \"mighty\", \"lady\", \"hair\", \"Ah\", \"universal\", \"winter\", \"million\", \"adore\", \"neglect\", \"rely\", \"madness\", \"delight\", \"heroic\", \"worthy\", \"London\", \"welcome\", \"rarely\", \"yes\", \"error\", \"age\", \"simple\", \"tragedy\", \"individual\", \"rule\", \"birth\", \"marriage\", \"opinion\", \"strength\", \"year\", \"answer\", \"break\", \"lay\", \"duty\", \"old\", \"thousand\", \"fish\", \"one\", \"ever\", \"men\", \"mean\", \"three\", \"love\", \"something\", \"everything\", \"never\", \"human\", \"think\", \"life\", \"soul\", \"give\", \"day\", \"equal\", \"devil\", \"precious\", \"ugly\", \"blame\", \"angry\", \"lover\", \"failure\", \"adversity\", \"reputation\", \"delightful\", \"wine\", \"prayer\", \"scarce\", \"audience\", \"sir\", \"especially\", \"honesty\", \"window\", \"escape\", \"greatly\", \"awake\", \"Better\", \"tear\", \"moralize\", \"drive\", \"outline\", \"basis\", \"sincerity\", \"Knowledge\", \"sign\", \"happy\", \"certain\", \"blind\", \"poetry\", \"temper\", \"play\", \"game\", \"harmony\", \"heart\", \"woman\", \"blood\", \"water\", \"everything\", \"intellect\", \"personal\", \"God\", \"passion\", \"love\", \"lose\", \"young\", \"grow\", \"book\", \"man\", \"sorrow\", \"would\", \"upon\", \"know\", \"great\", \"may\", \"genius\", \"use\", \"time\", \"friend\", \"could\", \"make\", \"law\", \"forgive\", \"count\", \"advice\", \"secret\", \"four\", \"miss\", \"weapon\", \"five\", \"imitate\", \"reward\", \"Always\", \"punish\", \"annoy\", \"criminal\", \"disaster\", \"original\", \"equally\", \"relief\", \"rhyme\", \"intention\", \"offend\", \"importance\", \"Woman\", \"cynic\", \"editor\", \"cheer\", \"publisher\", \"disposition\", \"iron\", \"reverence\", \"number\", \"afraid\", \"enemy\", \"manner\", \"bless\", \"cease\", \"principle\", \"mother\", \"heaven\", \"unhappy\", \"authority\", \"golden\", \"end\", \"Man\", \"work\", \"really\", \"nothing\", \"people\", \"bad\", \"great\", \"give\", \"virtue\", \"man\", \"need\", \"u\", \"except\", \"much\", \"n\", \"deal\", \"expect\", \"capacity\", \"educate\", \"flat\", \"early\", \"astonish\", \"stick\", \"family\", \"aby\", \"complaint\", \"excuse\", \"immortality\", \"suspect\", \"monkey\", \"slave\", \"mainly\", \"Whenever\", \"deceive\", \"monster\", \"fatal\", \"gaze\", \"current\", \"tie\", \"risk\", \"hide\", \"mask\", \"partly\", \"past\", \"capable\", \"literature\", \"fight\", \"attain\", \"save\", \"future\", \"present\", \"neither\", \"America\", \"great\", \"sympathy\", \"race\", \"human\", \"modern\", \"today\", \"become\", \"fact\", \"language\", \"taste\", \"action\", \"school\", \"consist\", \"always\", \"word\", \"life\", \"think\", \"see\", \"high\", \"man\", \"require\", \"merely\"], \"Total\": [342.0, 310.0, 569.0, 203.0, 575.0, 147.0, 80.0, 73.0, 205.0, 83.0, 128.0, 158.0, 88.0, 98.0, 182.0, 71.0, 181.0, 246.0, 55.0, 217.0, 65.0, 63.0, 71.0, 192.0, 150.0, 74.0, 36.0, 104.0, 77.0, 53.0, 23.95175686495442, 23.20930351573391, 19.141040510132864, 36.06209834228337, 16.901547765062066, 15.166765469478907, 14.304852911150045, 13.485944002451854, 13.381615739350151, 12.819944583418803, 12.271617405704287, 11.660176205066394, 11.646238050109334, 11.529162471710912, 11.515224105770619, 11.424834486489496, 11.125784051396389, 9.847741112942856, 9.716733884482068, 9.703392909448551, 9.59906277944864, 9.508074406048701, 9.41768418269035, 65.83883438724789, 9.300012777397878, 9.195683499983907, 8.765022838063999, 8.57030497175922, 8.452632198032992, 8.452630405591727, 35.05119371103412, 71.84800411168686, 37.10752123155514, 36.00204466807583, 14.942288899983959, 19.08455761054774, 21.435757660712202, 14.592870804913895, 14.12847603431041, 17.570244142762895, 310.1871392380336, 29.39732109231419, 26.718441052149753, 97.41843861310338, 203.74561114436187, 575.4691812781082, 27.420428642395034, 181.05653361649163, 165.53513322882685, 22.29538890540254, 102.4726467815252, 246.6392603787629, 116.61638519587137, 168.12204169947555, 66.4174187117516, 24.750048591743457, 262.0259536120602, 91.0257117694113, 93.11370026838667, 356.5488512181941, 51.94477058554376, 357.04050663446185, 106.78672563517782, 199.83881590647908, 41.12185487508796, 133.128968429651, 569.8881009043439, 158.65165874347434, 147.39551558154264, 120.26278763464256, 152.36733726243332, 149.87819464295316, 342.7549856520923, 192.26042699359067, 39.22525199764277, 21.476386231508872, 13.977876400735122, 12.679943160698654, 11.819576447263339, 11.607566918150775, 11.36785038625641, 11.184166698836439, 10.599930840284346, 34.743774920133355, 9.844956861669985, 9.421556882722266, 9.342659372839758, 9.19599271129295, 9.025262314605833, 8.983982716236545, 8.771985208016662, 8.574139667232243, 36.846964355835226, 8.321465649222649, 8.017013971214922, 7.92516950796902, 7.911619057260141, 7.8191676445167095, 7.699611406400322, 7.474050950749121, 7.395761853010503, 7.38160495235644, 7.368048305750407, 6.944639338813437, 19.025692888738295, 342.7549856520923, 27.875118958628974, 31.779275629332425, 18.531365101603985, 49.24485995265563, 28.304828489355344, 88.26142479947067, 54.379710276678665, 18.375932006087652, 40.14073330607939, 50.913673670401366, 60.78527073896908, 182.48997281930465, 158.65165874347434, 35.956859817026725, 19.4421536837464, 150.46252252809876, 16.117328096338287, 16.402504624040837, 284.76702847658487, 38.60049846052066, 310.1871392380336, 139.56931334299603, 217.755272990136, 75.3749161719985, 47.87399120317285, 569.8881009043439, 66.28192164718372, 156.25386359175832, 80.77711849766519, 356.5488512181941, 357.04050663446185, 199.83881590647908, 221.1935817003113, 143.9012798799228, 107.45454890339307, 85.575702262478, 262.0259536120602, 206.94121572053902, 575.4691812781082, 28.68156952723708, 24.68654075233106, 22.970730872608204, 17.458663939830764, 17.31436595037679, 16.55584303478882, 16.22211691786283, 14.664834767307307, 14.16017479083969, 12.869754266329306, 12.735415488287225, 12.615293458881363, 11.884621047682243, 11.629549281599305, 11.537882180643772, 20.953544926594375, 10.99236812884532, 10.778758060595745, 9.488949901758394, 9.063557296172268, 9.049329111666337, 8.915588868325774, 8.822700857249718, 8.795469763355474, 8.596085809316143, 8.383691938839032, 16.685951908671733, 7.851796995333595, 7.838176512013307, 7.838172898629972, 14.070296698325487, 51.89275111908382, 13.778742248045713, 13.141859448612841, 61.832003576974095, 14.295722264481121, 35.157438987214825, 77.01041992107804, 20.208211189344805, 14.684782086817812, 38.91350088826988, 30.510842567959948, 356.5488512181941, 40.11270133474851, 575.4691812781082, 217.755272990136, 29.069684418556456, 206.94121572053902, 221.1935817003113, 357.04050663446185, 73.43492396226823, 205.1241772323827, 26.5456348734077, 136.34493280739966, 192.26042699359067, 262.0259536120602, 41.774646627991686, 104.0752249525965, 342.7549856520923, 246.6392603787629, 134.18468974350748, 106.78672563517782, 133.0202773200345, 91.62555331158805, 68.98948750956707, 203.74561114436187, 569.8881009043439, 168.12204169947555, 182.48997281930465, 33.60572197698499, 33.348011426962536, 32.874980776571974, 32.066484176598074, 20.229728830070446, 17.713441413457847, 17.31709103620424, 15.344718835332088, 14.974976233735173, 14.881237547351231, 14.446229060246312, 14.212633064411456, 13.99668370342929, 13.098201347635559, 12.13320997953712, 12.010361670231925, 11.69821247024827, 11.655813269225128, 11.234734526346767, 11.002991561362501, 10.894089351505178, 10.459082849773598, 20.044427051350475, 10.118437278791937, 10.089965071964466, 29.646364396499933, 31.250612630139557, 8.67604440110261, 8.444303620729976, 8.430380174317097, 30.974062528182515, 19.16868370659077, 25.883260403299566, 71.84369626053713, 17.37092490562393, 66.92359310273109, 36.130155252101375, 29.802488985999748, 16.53239848579459, 38.8738166825601, 43.321567717205326, 161.73683517182374, 89.21589786755418, 53.97150102094287, 357.04050663446185, 139.56931334299603, 120.26278763464256, 85.64161643807276, 54.88708929696857, 206.94121572053902, 150.46252252809876, 575.4691812781082, 221.1935817003113, 356.5488512181941, 152.36733726243332, 199.83881590647908, 569.8881009043439, 182.48997281930465, 127.00611385369616, 62.980553436343946, 149.87819464295316, 107.45454890339307, 34.97343056140577, 23.804465318025073, 20.74147986903241, 16.205922409428073, 15.599211433576158, 13.865705339409951, 13.542217429519868, 11.35950571516281, 11.346279907757587, 10.726342750350318, 10.389628463059912, 10.272981971927349, 10.093180469147468, 10.066138410274236, 9.963308831956114, 9.44679427882498, 9.343371264210537, 9.329555077768637, 8.993431151601508, 8.903235072051077, 8.826854883402746, 8.773362707178206, 8.683167037600136, 8.606786275695804, 8.490141352768456, 8.269483517634487, 8.166651426880021, 8.153424883347386, 7.650133444705384, 7.546713625121268, 26.42818303180224, 17.09137277592891, 53.860251837378506, 13.921597553014072, 29.619459867484508, 72.69247432542076, 20.809963954946095, 58.5202489737232, 41.60894360332289, 24.04901257621476, 93.40904917277248, 20.661487815188853, 569.8881009043439, 33.61999850399715, 59.37641726679208, 88.31751591172133, 246.6392603787629, 149.87819464295316, 34.43174210796215, 575.4691812781082, 105.93841708305253, 79.2107047251513, 104.0752249525965, 357.04050663446185, 192.26042699359067, 161.73683517182374, 128.69309091328475, 284.76702847658487, 70.4416108228339, 48.12759559590697, 89.27676294319352, 67.038744855229, 165.53513322882685, 199.83881590647908, 32.42537781696972, 30.25099130082033, 13.080249897618653, 11.400712136625922, 10.808944110736476, 10.379232377205785, 10.151465275988215, 9.634267847812959, 9.204554022778716, 9.142894325844345, 73.06720369906708, 8.92804039841331, 8.39735386948101, 8.309873717042796, 8.309872479347328, 8.309876956966427, 7.779186650433284, 7.691124546696672, 7.678212257375276, 7.47684590948511, 7.362965559133033, 7.060044635594338, 6.972560918493585, 6.871590972661727, 6.7706161046753115, 6.555760745932183, 6.529935557372764, 6.239933483702356, 6.152451563301535, 6.152456729657329, 27.673760954143507, 12.347453776175374, 17.51576222086163, 83.84367502679177, 28.091595317910176, 40.837431191005074, 12.17924853774939, 13.632959280878643, 20.42150749793482, 41.48392218182688, 11.77308615945159, 21.318074031221915, 33.65411059375789, 22.85785246936378, 128.69309091328475, 569.8881009043439, 27.741762436100068, 14.478267030043096, 26.47182443913286, 103.32126261139838, 47.83064993518731, 38.28999295661013, 192.26042699359067, 78.63634964051798, 29.020830102783385, 206.94121572053902, 284.76702847658487, 134.18468974350748, 217.755272990136, 356.5488512181941, 93.11370026838667, 262.0259536120602, 168.12204169947555, 49.82340512941971, 84.0613985773596, 357.04050663446185, 181.05653361649163, 133.128968429651, 70.4416108228339, 158.65165874347434, 246.6392603787629, 29.237870538254036, 20.410902719444703, 20.1675512745384, 20.00311596355268, 18.877162139997758, 17.871039744171725, 15.70272982488916, 13.304124382901115, 12.435744625635229, 12.373401278382488, 11.633223469868522, 11.300840153041523, 10.981500627911048, 10.382584219764164, 9.859647677510434, 9.527259454597946, 9.412109785479853, 9.119472020387986, 9.017378280750581, 8.290258528913165, 8.188163587656524, 8.046904753379948, 7.970924786124027, 7.46104279048017, 7.23074666353592, 7.040199592698196, 7.013506462493993, 6.836013035055419, 6.836014452599276, 6.822958322820536, 80.09197181999312, 30.23790850600708, 21.432695013306084, 33.365432712737906, 43.866009796143125, 12.686654988126842, 34.05021744264281, 53.1418546310406, 21.131799307929125, 74.90346093416707, 25.016114973491707, 29.919109474953014, 20.69095468527167, 52.09541258936421, 128.69309091328475, 25.367134864554867, 16.445558135040475, 569.8881009043439, 67.58316407838679, 161.73683517182374, 93.2373900780083, 42.0372492060049, 203.74561114436187, 96.05109444990512, 98.5813871591723, 246.6392603787629, 104.33445610878337, 221.1935817003113, 284.76702847658487, 71.30844764201758, 143.9012798799228, 79.2107047251513, 18.29521485559787, 16.803546717086483, 15.597142339531306, 14.131785634582924, 13.810597735031276, 13.618004816361054, 13.564797464768635, 12.53724177605053, 11.380502384290153, 11.161602120476058, 10.879881006933806, 10.660979718250385, 10.455232458981584, 10.031173182922762, 9.928298412480254, 9.285337972769277, 8.962976474550727, 8.834380670582686, 8.55265951846706, 8.436044465769251, 8.114270080933164, 8.011983650156244, 7.601078392436481, 7.485050587048334, 7.203328457343398, 7.189586294955581, 7.060405555790874, 6.881554238700854, 6.76552583655721, 6.648909560881205, 17.645956143679836, 38.427939967210094, 39.55605802173411, 10.310591749980656, 17.703959733438406, 10.754016428706157, 55.123193028237424, 15.156371117397635, 10.628180774463809, 63.35919507345661, 147.39551558154264, 25.883747136432483, 21.38587715826936, 98.5813871591723, 22.014844823855544, 13.331333499301568, 107.82007039091592, 21.03023424757097, 203.74561114436187, 67.038744855229, 62.006190598279765, 45.839546992768916, 116.61638519587137, 575.4691812781082, 20.74521360773418, 192.26042699359067, 62.47750609381423, 310.1871392380336, 205.1241772323827, 105.93841708305253, 55.20672576457211, 89.21589786755418, 199.83881590647908, 80.77711849766519, 84.0613985773596, 357.04050663446185, 85.64161643807276, 29.280668011435033, 22.7078316660344, 19.776657187597916, 36.48534419056651, 16.79128453293399, 15.976812215341925, 12.664729353523912, 11.436036121093164, 11.361923416207203, 11.209099237225928, 10.420864516253422, 10.307110968243457, 9.90686696652198, 10.322491398173531, 9.279111855804365, 8.765110823597748, 8.46406740319991, 8.15076460059013, 7.662428436236546, 7.649594188504807, 7.649594815303087, 7.636191953015781, 7.436066421970567, 7.348551422121976, 7.348551418467545, 7.048077966046855, 7.048078538142497, 6.834550629310755, 6.721368695346379, 6.7213697363888025, 20.39931693706708, 16.009672308363402, 32.97275040824879, 17.88807828828335, 9.289790596595077, 22.734135875305775, 25.602361975591787, 15.316852474965438, 25.128706782237245, 9.616418810553046, 32.2823146834186, 13.411268167531224, 56.607935904406, 39.81704278350833, 107.45454890339307, 47.50897834703773, 156.25386359175832, 262.0259536120602, 88.26142479947067, 205.1241772323827, 143.9012798799228, 41.20599007739753, 575.4691812781082, 77.37003487569183, 206.94121572053902, 49.02778491110875, 110.22854583974366, 134.18468974350748, 21.972565762905607, 19.51803634534465, 13.42577267282655, 12.82807784665558, 12.590404872071312, 12.29127411319095, 10.572402528291313, 10.472689400992971, 9.935884644943654, 9.399645896746422, 9.139336439945062, 9.013556849371387, 8.827454739774373, 8.515574793519775, 8.429180459386503, 8.403112504405803, 8.229761561549427, 8.217010520511339, 8.217010649312321, 8.091802105620669, 8.017590505373759, 7.979335091299505, 7.892377781120882, 7.6060029054435, 7.394397445907648, 14.931801533948486, 7.294683214901571, 6.796700528301177, 28.721102897585205, 6.6709191135200445, 18.440693556725837, 24.66192582935389, 9.78037630822845, 24.85110230210268, 25.702968993820704, 28.79936037867499, 17.551734156217258, 45.35604150644494, 205.1241772323827, 17.887745461737417, 34.72585454020019, 104.33445610878337, 39.30821563740197, 17.805848650352832, 67.67150091019664, 59.94148226312055, 29.78306561484112, 21.57397703166763, 62.23996503281633, 38.94797598616891, 35.5522727973414, 181.05653361649163, 88.31751591172133, 284.76702847658487, 221.1935817003113, 136.34493280739966, 66.08206069226641, 575.4691812781082, 31.16326106236886, 44.99427272070614], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.8738, 1.8727, 1.8652, 1.8624, 1.8595, 1.8538, 1.8505, 1.847, 1.8465, 1.8437, 1.8408, 1.8372, 1.8371, 1.8364, 1.8363, 1.8357, 1.8337, 1.8237, 1.8226, 1.8224, 1.8215, 1.8206, 1.8198, 1.8197, 1.8186, 1.8175, 1.8129, 1.8107, 1.8093, 1.8092, 1.8084, 1.7888, 1.7941, 1.7855, 1.8004, 1.7864, 1.7605, 1.7838, 1.772, 1.7413, 1.3153, 1.6658, 1.638, 1.3431, 1.1681, 0.9074, 1.6133, 1.0643, 1.0705, 1.6468, 1.1329, 0.8262, 1.0512, 0.8956, 1.2229, 1.6078, 0.6698, 1.0858, 1.051, 0.4665, 1.3016, 0.3568, 0.8985, 0.5331, 1.3886, 0.6782, -0.2842, 0.4562, 0.4951, 0.6334, 0.4406, 0.4459, -0.2704, 0.1676, 1.9404, 1.9233, 1.9026, 1.8965, 1.8917, 1.8904, 1.8888, 1.8876, 1.8834, 1.88, 1.8772, 1.8733, 1.8725, 1.8711, 1.8693, 1.8689, 1.8665, 1.8643, 1.8612, 1.8612, 1.8572, 1.8559, 1.8558, 1.8544, 1.8527, 1.8493, 1.848, 1.8478, 1.8476, 1.8402, 1.8118, 1.6715, 1.7731, 1.7578, 1.7841, 1.687, 1.7328, 1.6178, 1.6581, 1.7693, 1.6617, 1.5764, 1.5294, 1.3218, 1.3082, 1.5642, 1.7043, 1.1588, 1.7377, 1.7325, 0.8519, 1.4603, 0.761, 1.0079, 0.832, 1.2061, 1.3486, 0.3024, 1.1742, 0.7667, 1.0656, 0.297, 0.2523, 0.5397, 0.4246, 0.6864, 0.8539, 0.9994, 0.1961, 0.2059, -0.7363, 2.0696, 2.0651, 2.0626, 2.0513, 2.0509, 2.0487, 2.0477, 2.0423, 2.0403, 2.0343, 2.0336, 2.033, 2.0289, 2.0274, 2.0268, 2.0253, 2.0231, 2.0216, 2.0108, 2.0066, 2.0064, 2.005, 2.004, 2.0037, 2.0014, 1.9988, 1.9975, 1.9918, 1.9916, 1.9916, 1.9815, 1.9551, 1.9761, 1.9727, 1.8223, 1.9523, 1.8389, 1.7362, 1.8985, 1.924, 1.7464, 1.752, 0.7521, 1.55, 0.5261, 0.8526, 1.6428, 0.7283, 0.6596, 0.389, 1.1325, 0.5448, 1.6435, 0.7539, 0.5443, 0.3173, 1.3927, 0.8154, -0.0002, 0.1687, 0.5396, 0.669, 0.4971, 0.7684, 0.984, 0.0761, -0.8533, 0.1628, 0.0428, 2.2419, 2.2417, 2.2414, 2.2408, 2.226, 2.2202, 2.2191, 2.213, 2.2117, 2.2113, 2.2096, 2.2087, 2.2078, 2.2037, 2.1986, 2.1979, 2.196, 2.1958, 2.1931, 2.1915, 2.1907, 2.1875, 2.1872, 2.1847, 2.1845, 2.1814, 2.1799, 2.1706, 2.1679, 2.1677, 2.1299, 2.1281, 2.0388, 1.8487, 2.0753, 1.786, 1.8836, 1.8967, 2.0636, 1.705, 1.6591, 1.0959, 1.3159, 1.532, 0.3727, 0.8519, 0.9308, 1.1199, 1.3488, 0.4767, 0.6571, -0.263, 0.3109, -0.0738, 0.5537, 0.3272, -0.5707, 0.324, 0.6056, 1.2274, 0.4002, 0.7077, 2.2687, 2.2578, 2.2527, 2.2416, 2.2396, 2.2329, 2.2314, 2.2195, 2.2194, 2.2151, 2.2125, 2.2115, 2.21, 2.2098, 2.2089, 2.2042, 2.2032, 2.2031, 2.1996, 2.1986, 2.1978, 2.1972, 2.1962, 2.1953, 2.1939, 2.1911, 2.1898, 2.1896, 2.1825, 2.181, 2.1665, 2.1529, 1.9892, 2.1308, 1.9582, 1.7763, 2.0029, 1.7586, 1.8287, 1.9059, 1.4818, 1.9461, 0.819, 1.764, 1.5637, 1.4152, 0.83, 0.9803, 1.6366, 0.2764, 0.9723, 1.0991, 0.892, 0.0611, 0.4532, 0.5617, 0.6732, 0.0207, 1.0598, 1.3423, 0.7994, 1.0187, 0.1438, -0.0558, 2.3686, 2.3668, 2.3308, 2.3213, 2.3172, 2.3139, 2.312, 2.3075, 2.3033, 2.3027, 2.3025, 2.3004, 2.2942, 2.2931, 2.2931, 2.2931, 2.2859, 2.2846, 2.2844, 2.2813, 2.2794, 2.2743, 2.2727, 2.2708, 2.2689, 2.2645, 2.264, 2.2575, 2.2554, 2.2554, 2.1493, 2.199, 2.1598, 1.9881, 2.0873, 2.0077, 2.1824, 2.1622, 2.0877, 1.932, 2.1846, 2.0051, 1.8521, 1.9581, 1.3537, 0.8147, 1.8381, 2.0789, 1.8328, 1.218, 1.5559, 1.648, 0.8673, 1.2651, 1.7485, 0.7176, 0.5385, 0.9045, 0.6339, 0.2853, 1.0639, 0.4245, 0.6259, 1.4011, 0.9283, -0.2266, 0.2621, 0.4915, 1.0017, 0.2325, -0.2057, 2.4568, 2.4447, 2.4442, 2.4439, 2.4414, 2.439, 2.4325, 2.4229, 2.4185, 2.4182, 2.4138, 2.4116, 2.4095, 2.405, 2.4006, 2.3975, 2.3964, 2.3935, 2.3924, 2.3839, 2.3826, 2.3807, 2.3797, 2.3721, 2.3683, 2.365, 2.3645, 2.3612, 2.3612, 2.361, 2.3051, 2.3108, 2.2543, 2.1962, 2.098, 2.2749, 2.0664, 1.9174, 2.1437, 1.8258, 2.1003, 2.0237, 2.1165, 1.7558, 1.3578, 2.0041, 2.1779, 0.5115, 1.484, 0.9126, 1.0993, 1.5813, 0.5491, 1.0345, 0.9959, 0.3218, 0.913, 0.346, 0.1333, 1.1789, 0.5667, 0.9586, 2.4789, 2.4749, 2.4711, 2.4655, 2.4641, 2.4633, 2.463, 2.458, 2.4511, 2.4496, 2.4476, 2.446, 2.4445, 2.441, 2.4401, 2.4341, 2.4307, 2.4293, 2.4261, 2.4247, 2.4206, 2.4192, 2.4132, 2.4115, 2.4068, 2.4066, 2.4043, 2.401, 2.3988, 2.3965, 2.3631, 2.3038, 2.2918, 2.3766, 2.3306, 2.3699, 2.2005, 2.317, 2.3641, 1.9966, 1.7943, 2.1445, 2.1317, 1.5616, 2.0813, 2.2768, 1.4229, 2.0914, 1.1087, 1.5315, 1.4889, 1.6258, 1.0717, -0.0477, 2.04, 0.4748, 1.2153, -0.0474, 0.2394, 0.7557, 1.2796, 0.8027, 0.0726, 0.854, 0.7999, -0.5981, 0.7651, 2.6902, 2.6821, 2.6767, 2.6712, 2.6692, 2.6667, 2.653, 2.6458, 2.6453, 2.6443, 2.6385, 2.6376, 2.6342, 2.6338, 2.6283, 2.6228, 2.6193, 2.6153, 2.6084, 2.6082, 2.6082, 2.608, 2.6049, 2.6035, 2.6035, 2.5983, 2.5983, 2.5943, 2.5921, 2.5921, 2.508, 2.4946, 2.3925, 2.4583, 2.552, 2.3894, 2.3128, 2.4305, 2.2556, 2.538, 2.0532, 2.387, 1.7312, 1.8898, 1.2524, 1.6665, 0.9558, 0.5505, 1.1808, 0.4457, 0.6657, 1.5897, -0.5556, 1.0419, 0.2232, 1.3939, 0.6373, 0.3862, 2.7415, 2.7367, 2.7173, 2.7144, 2.7131, 2.7115, 2.7002, 2.6994, 2.695, 2.6901, 2.6874, 2.6861, 2.6841, 2.6804, 2.6794, 2.6791, 2.6769, 2.6767, 2.6767, 2.675, 2.674, 2.6735, 2.6723, 2.6681, 2.6647, 2.6634, 2.6631, 2.6541, 2.6524, 2.6516, 2.5704, 2.5195, 2.6121, 2.434, 2.3644, 2.3115, 2.4367, 2.0787, 1.5312, 2.3957, 2.1154, 1.5529, 1.9783, 2.3212, 1.6486, 1.7019, 2.0348, 2.1955, 1.563, 1.8322, 1.8614, 0.7496, 1.1672, 0.0948, 0.2953, 0.6871, 1.2367, -0.7555, 1.8718, 1.516], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.7922, -5.8248, -6.025, -5.3944, -6.1551, -6.2691, -6.3309, -6.3934, -6.4016, -6.4473, -6.4939, -6.5486, -6.5499, -6.5608, -6.5621, -6.5705, -6.599, -6.731, -6.7456, -6.7471, -6.7589, -6.7693, -6.7797, -4.8351, -6.7934, -6.8057, -6.8583, -6.883, -6.8983, -6.8983, -5.4768, -4.7786, -5.4341, -5.4729, -6.3374, -6.1068, -6.0165, -6.3777, -6.4219, -6.2345, -3.7895, -5.7953, -5.9186, -4.9199, -4.3571, -3.5794, -5.9175, -4.5789, -4.6623, -6.0908, -5.0795, -4.5079, -5.032, -4.8218, -5.4231, -6.0254, -4.6038, -5.2451, -5.2572, -4.499, -5.5902, -4.6073, -5.2726, -5.0114, -5.7369, -5.2725, -4.7808, -5.3191, -5.3538, -5.419, -5.3751, -5.3863, -5.2754, -5.4155, -5.2323, -5.8518, -6.3019, -6.4055, -6.4806, -6.5, -6.5224, -6.5399, -6.5977, -5.414, -6.6778, -6.7257, -6.7349, -6.7522, -6.7727, -6.7777, -6.8039, -6.829, -5.3741, -6.862, -6.9032, -6.916, -6.9179, -6.931, -6.9481, -6.9813, -6.9931, -6.9952, -6.9973, -7.0638, -6.0844, -3.3335, -5.7412, -5.6254, -6.1384, -5.2582, -5.7662, -4.7439, -5.1879, -6.1617, -5.4879, -5.3355, -5.2052, -4.3136, -4.4671, -5.6955, -6.1703, -4.6695, -6.3244, -6.312, -4.3384, -5.7284, -4.3438, -4.8956, -4.6266, -5.3134, -5.6248, -4.1942, -5.4739, -5.0239, -5.3847, -4.6685, -4.7119, -5.0048, -5.0183, -5.1865, -5.3111, -5.3932, -5.0774, -5.3037, -5.2232, -5.4161, -5.5707, -5.6452, -5.9309, -5.9395, -5.9865, -6.0079, -6.1143, -6.1513, -6.2528, -6.264, -6.2741, -6.3379, -6.3611, -6.3696, -5.7744, -6.4217, -6.4428, -6.581, -6.6312, -6.6329, -6.6492, -6.6607, -6.6641, -6.6893, -6.7169, -6.0299, -6.7895, -6.7914, -6.7914, -6.2164, -4.9377, -6.2428, -6.2935, -4.8952, -6.2297, -5.4433, -4.7619, -5.9375, -6.2312, -5.4342, -5.6719, -4.2134, -5.6003, -3.9607, -4.6061, -5.8295, -4.7812, -4.7833, -4.5751, -5.4131, -4.9736, -5.9197, -5.1729, -5.0388, -4.9563, -5.717, -5.3815, -5.0052, -5.1654, -5.4032, -5.5021, -5.4544, -5.5559, -5.624, -5.4491, -5.3499, -5.5546, -5.5925, -5.0854, -5.0933, -5.1079, -5.1334, -5.6089, -5.7475, -5.7712, -5.8982, -5.9239, -5.9306, -5.9619, -5.9792, -5.9954, -6.0658, -6.1474, -6.1584, -6.1865, -6.1904, -6.2299, -6.2524, -6.2631, -6.3071, -5.6569, -6.3429, -6.346, -5.2713, -5.2201, -6.5108, -6.5406, -6.5424, -5.279, -5.7606, -5.5496, -4.7188, -5.9119, -4.8525, -5.3713, -5.5507, -5.9731, -5.4767, -5.4143, -4.6601, -5.0351, -5.3216, -4.5915, -5.0515, -5.1215, -5.2719, -5.4879, -5.0329, -5.1712, -4.7498, -5.1321, -5.0393, -5.262, -5.2173, -5.0673, -5.3113, -5.3922, -5.4718, -5.4319, -5.4572, -5.0187, -5.4143, -5.5571, -5.8151, -5.8552, -5.9797, -6.0047, -6.1925, -6.1937, -6.2543, -6.2887, -6.301, -6.3201, -6.323, -6.3342, -6.3921, -6.4041, -6.4058, -6.4459, -6.457, -6.4664, -6.4731, -6.4845, -6.4942, -6.5092, -6.5383, -6.5521, -6.5539, -6.6247, -6.6399, -5.4011, -5.8505, -4.8664, -6.0778, -5.4954, -4.7795, -5.8037, -5.0141, -5.285, -5.756, -4.8232, -5.8677, -3.6776, -5.5629, -5.1944, -4.9459, -4.5041, -4.8519, -5.6665, -4.2105, -5.2068, -5.3708, -5.3049, -4.903, -5.1299, -5.1943, -5.3114, -5.1697, -5.5274, -5.6259, -5.5508, -5.618, -5.589, -5.6003, -4.9945, -5.0657, -5.9401, -6.0871, -6.1444, -6.1883, -6.2123, -6.2692, -6.319, -6.3264, -4.2482, -6.3524, -6.4199, -6.4315, -6.4315, -6.4315, -6.5047, -6.5173, -6.5192, -6.5489, -6.5661, -6.6133, -6.6273, -6.6438, -6.6606, -6.6972, -6.7016, -6.7535, -6.7697, -6.7697, -5.3722, -6.1296, -5.8191, -4.425, -5.4193, -5.1247, -6.1599, -6.0673, -5.7377, -5.1847, -6.1915, -5.7774, -5.4738, -5.7546, -4.6308, -3.6819, -5.6809, -6.0904, -5.7331, -4.9861, -5.4185, -5.5488, -4.7159, -5.2121, -5.7255, -4.792, -4.6519, -5.0383, -4.8247, -4.6803, -5.2443, -4.849, -5.0915, -5.5324, -5.4821, -5.1908, -5.3811, -5.4592, -5.5855, -5.5428, -5.5397, -5.0097, -5.3812, -5.3937, -5.4022, -5.4626, -5.5199, -5.6556, -5.831, -5.9029, -5.9083, -5.9743, -6.0055, -6.0363, -6.0969, -6.153, -6.1903, -6.2036, -6.2381, -6.2504, -6.343, -6.3567, -6.376, -6.3865, -6.4602, -6.4953, -6.5254, -6.5297, -6.5586, -6.5586, -6.5607, -4.1537, -5.1222, -5.5228, -5.1383, -4.9628, -6.0265, -5.2478, -4.9516, -5.6475, -4.7, -5.5222, -5.4198, -5.6958, -5.1332, -4.6267, -5.6044, -5.864, -3.9851, -5.1446, -4.8435, -5.2075, -5.5222, -4.976, -5.2426, -5.2552, -5.0123, -5.2814, -5.0969, -5.057, -5.3961, -5.3062, -5.5113, -5.4565, -5.5455, -5.6239, -5.7281, -5.7524, -5.7673, -5.7715, -5.8554, -5.959, -5.9799, -6.0075, -6.0294, -6.0505, -6.0953, -6.1065, -6.1795, -6.2182, -6.234, -6.2697, -6.2848, -6.3278, -6.3419, -6.4005, -6.4176, -6.4606, -6.4628, -6.4832, -6.5121, -6.5314, -6.5511, -5.6084, -4.8894, -4.8724, -6.1322, -5.6376, -6.0969, -4.632, -5.8066, -6.1144, -4.6966, -4.0545, -5.4439, -5.6476, -4.6896, -5.669, -5.9751, -4.7386, -5.7046, -4.4165, -5.1053, -5.2258, -5.3911, -5.0115, -4.5345, -5.7697, -5.1084, -5.4919, -5.1522, -5.279, -5.4235, -5.5513, -5.5482, -5.4719, -5.5963, -5.6106, -5.5623, -5.6267, -4.7749, -5.0372, -5.1808, -4.5739, -5.3519, -5.4042, -5.6502, -5.7595, -5.7665, -5.781, -5.8597, -5.8716, -5.9146, -5.8739, -5.9859, -6.0484, -6.0869, -6.1286, -6.1973, -6.1991, -6.1991, -6.2011, -6.2308, -6.244, -6.244, -6.291, -6.291, -6.3257, -6.3446, -6.3446, -5.3185, -5.5742, -4.9538, -5.4995, -6.0611, -5.3287, -5.2865, -5.6825, -5.3624, -6.0406, -5.3143, -5.8589, -5.0746, -5.268, -4.9125, -5.3146, -4.8348, -4.7231, -5.1809, -5.0727, -5.2072, -5.5337, -5.0424, -5.4515, -5.2864, -5.5557, -5.5021, -5.5566, -5.0108, -5.1339, -5.5275, -5.576, -5.5959, -5.6216, -5.7835, -5.7938, -5.8508, -5.9113, -5.942, -5.9572, -5.9801, -6.0197, -6.0309, -6.0343, -6.0574, -6.0591, -6.0591, -6.0761, -6.0863, -6.0916, -6.1038, -6.145, -6.1766, -5.4751, -6.1918, -6.2715, -4.8319, -6.2926, -5.357, -5.1173, -5.9496, -5.1951, -5.231, -5.1702, -5.5401, -4.9488, -3.9872, -5.5622, -5.1791, -4.6415, -5.1923, -5.6412, -4.9788, -5.0467, -5.4133, -5.575, -5.148, -5.3476, -5.4096, -4.8936, -5.1939, -5.0955, -5.1477, -5.2397, -5.4145, -5.2423, -5.5309, -5.5195]}, \"token.table\": {\"Topic\": [7, 9, 3, 5, 10, 8, 6, 4, 4, 4, 6, 4, 1, 6, 2, 6, 1, 2, 3, 5, 7, 8, 9, 10, 2, 3, 8, 3, 4, 6, 4, 5, 7, 1, 4, 7, 9, 1, 5, 3, 5, 6, 7, 1, 2, 3, 5, 6, 7, 9, 4, 6, 2, 2, 6, 10, 9, 1, 3, 3, 1, 1, 10, 1, 2, 1, 2, 3, 6, 8, 9, 10, 7, 8, 9, 8, 9, 6, 7, 2, 3, 2, 1, 4, 3, 1, 2, 4, 5, 6, 10, 8, 9, 3, 4, 5, 6, 8, 9, 1, 7, 1, 3, 5, 6, 3, 1, 4, 5, 9, 4, 10, 6, 1, 10, 4, 10, 8, 1, 5, 6, 9, 10, 8, 1, 3, 4, 2, 8, 9, 8, 1, 3, 4, 5, 8, 1, 2, 7, 1, 3, 4, 5, 8, 10, 5, 2, 5, 7, 3, 10, 5, 1, 2, 3, 4, 6, 7, 8, 10, 3, 2, 3, 6, 9, 10, 2, 5, 7, 5, 8, 7, 9, 8, 9, 3, 5, 8, 1, 2, 4, 8, 9, 10, 1, 3, 7, 8, 6, 1, 2, 3, 4, 5, 6, 10, 10, 1, 5, 1, 9, 1, 8, 9, 4, 3, 9, 4, 4, 2, 3, 5, 10, 2, 1, 2, 3, 7, 9, 10, 2, 3, 10, 6, 4, 2, 6, 10, 6, 6, 7, 1, 1, 2, 4, 5, 6, 8, 9, 4, 9, 10, 9, 4, 1, 3, 7, 1, 3, 4, 5, 7, 10, 10, 10, 7, 8, 6, 10, 6, 5, 3, 3, 10, 6, 8, 1, 3, 9, 1, 2, 1, 9, 9, 2, 2, 4, 5, 9, 3, 7, 2, 6, 8, 3, 3, 2, 5, 7, 10, 4, 5, 7, 8, 3, 2, 9, 10, 5, 1, 6, 8, 9, 1, 5, 7, 9, 2, 9, 1, 7, 8, 1, 8, 9, 7, 8, 8, 2, 3, 4, 5, 6, 7, 1, 2, 4, 5, 6, 7, 8, 9, 10, 2, 6, 7, 8, 1, 4, 6, 8, 9, 6, 10, 3, 9, 4, 5, 6, 7, 8, 10, 1, 3, 4, 5, 8, 10, 8, 3, 6, 7, 2, 10, 1, 6, 8, 10, 5, 6, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 10, 4, 8, 3, 1, 2, 4, 5, 7, 9, 2, 7, 9, 10, 1, 3, 6, 7, 2, 1, 3, 9, 2, 5, 9, 5, 4, 9, 4, 2, 4, 7, 1, 2, 5, 8, 3, 2, 4, 7, 8, 3, 3, 10, 5, 8, 10, 2, 3, 4, 8, 9, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 6, 9, 1, 2, 3, 9, 3, 1, 2, 3, 4, 5, 7, 8, 9, 10, 8, 6, 2, 1, 2, 5, 8, 7, 1, 2, 3, 5, 3, 8, 6, 8, 7, 8, 1, 8, 9, 3, 7, 9, 7, 8, 10, 1, 4, 5, 6, 7, 9, 10, 8, 1, 2, 5, 7, 8, 9, 10, 5, 2, 5, 3, 1, 7, 2, 5, 7, 1, 2, 9, 9, 2, 10, 9, 1, 2, 3, 4, 6, 10, 6, 4, 7, 8, 10, 4, 10, 6, 2, 8, 6, 10, 9, 1, 6, 9, 2, 5, 8, 1, 2, 4, 5, 10, 2, 1, 2, 6, 8, 9, 7, 2, 6, 9, 10, 1, 2, 6, 1, 3, 4, 7, 8, 9, 3, 7, 3, 5, 1, 2, 3, 4, 5, 7, 8, 2, 9, 6, 5, 1, 3, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 9, 1, 10, 1, 2, 3, 4, 5, 6, 9, 1, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 1, 3, 4, 5, 8, 9, 1, 3, 7, 8, 8, 6, 4, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 8, 9, 10, 6, 9, 1, 2, 3, 4, 6, 2, 3, 7, 1, 7, 10, 1, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 6, 3, 5, 7, 8, 10, 7, 7, 7, 1, 3, 4, 5, 6, 8, 5, 9, 2, 9, 9, 2, 2, 4, 5, 6, 8, 9, 10, 1, 3, 6, 10, 10, 3, 2, 5, 8, 1, 9, 10, 3, 4, 1, 2, 5, 6, 7, 8, 9, 10, 2, 4, 6, 8, 1, 2, 4, 5, 10, 1, 2, 3, 5, 6, 7, 8, 9, 10, 3, 6, 7, 3, 4, 5, 2, 3, 4, 5, 8, 9, 10, 7, 2, 3, 4, 5, 8, 9, 7, 3, 6, 1, 10, 1, 3, 4, 5, 6, 7, 10, 2, 5, 5, 1, 1, 8, 1, 2, 3, 5, 6, 7, 8, 9, 5, 1, 1, 1, 6, 9, 6, 5, 9, 2, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 7, 10, 2, 6, 1, 2, 7, 1, 9, 1, 2, 3, 6, 7, 10, 1, 8, 3, 2, 10, 7, 1, 7, 8, 6, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 4, 3, 6, 1, 2, 3, 4, 6, 9, 2, 8, 1, 3, 5, 4, 1, 1, 2, 3, 4, 5, 8, 6, 8, 5, 3, 4, 5, 9, 5, 8, 1, 3, 5, 4, 6, 1, 2, 3, 4, 5, 8, 9, 2, 8, 8, 1, 4, 5, 10, 1, 2, 3, 4, 9, 1, 2, 1, 3, 7, 9, 4, 2, 3, 4, 5, 6, 5, 4, 5, 7, 8, 9, 9, 3, 5, 5, 2, 9, 10, 7, 1, 8, 2, 2, 3, 6, 9, 1, 4, 5, 7, 9, 7, 5, 9, 7, 8, 6, 4, 5, 10, 6, 1, 3, 9, 9, 9, 3, 4, 6, 1, 10, 5, 3, 1, 7, 8, 2, 3, 1, 7, 7, 10, 1, 2, 3, 5, 6, 7, 8, 9, 10, 8, 1, 4, 6, 9, 10, 1, 4, 2, 9, 3, 3, 4, 1, 2, 3, 4, 6, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 5, 2, 3, 4, 5, 6, 10, 3, 2, 5, 1, 2, 3, 4, 4, 1, 8, 8, 9, 2, 6, 7, 5, 8, 1, 2, 8, 5, 8, 10, 1, 7, 4, 1, 2, 1, 2, 4, 5, 7, 1, 2, 3, 5, 6, 2, 8, 3, 4, 7, 8, 9, 10, 1, 4, 5, 6, 8, 1, 3, 6, 4, 6, 6, 7, 5, 3, 4, 10, 3, 6, 2, 1, 4, 5, 7, 8, 1, 7, 2, 3, 4, 1, 2, 10, 2, 5, 10, 5, 1, 2, 3, 4, 5, 6, 7, 8, 5, 1, 2, 6, 9, 6, 1, 3, 10, 2, 4, 5, 8, 5, 1, 6, 5, 8, 6, 7, 1, 6, 1, 6, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 4, 2, 5, 6, 7, 1, 5, 7, 1, 10, 1, 2, 3, 4, 5, 6, 7, 8, 10, 3, 8, 10, 5, 5, 1, 7, 3, 4, 3, 4, 1, 2, 3, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 9, 8, 2, 5, 9, 7, 1, 3, 4, 5, 6, 7, 8, 1, 3, 4, 5, 6, 8, 1, 2, 4, 10, 4, 9, 1, 3, 7, 8, 9, 3, 1, 2, 6, 6, 1, 2, 4, 6, 7, 3, 8, 2, 3, 4, 5, 6, 8, 10, 1, 5, 10, 9, 7, 1, 2, 4, 5, 8, 3, 4, 3, 4, 4, 4, 8, 8, 8, 7, 1, 2, 6, 7, 3, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 3, 4, 6, 8, 5, 1, 3, 5, 6, 8, 10, 1, 2, 4, 5, 8, 9, 1, 2, 3, 5, 6, 7, 8, 7, 1, 3, 4, 5, 6, 8, 1, 2, 1, 6, 7, 8, 7, 5, 6, 7, 8, 9, 7], \"Freq\": [0.9128115217066767, 0.9596132820269374, 0.1322866767186334, 0.37481225070279467, 0.507098927421428, 0.9209219585164929, 0.9627101773631922, 0.9819756297037803, 0.9403146017373155, 0.915875833053709, 0.8731602366716373, 0.9561067775858056, 0.936041487692598, 0.9251597471086046, 0.9464880209941583, 0.936223654297839, 0.04637355533039293, 0.18549422132157173, 0.17621951025549315, 0.11129653279294303, 0.02782413319823576, 0.3338895983788291, 0.09274711066078586, 0.02782413319823576, 0.9676411657650652, 0.9458664075145715, 0.9024036114584776, 0.17229004071528783, 0.31012207328751806, 0.5168701221458635, 0.6919427781464064, 0.3044548223844188, 0.8522485649729238, 0.3013784842145594, 0.1506892421072797, 0.07534462105363984, 0.42695285263729243, 0.9129503623702949, 0.08558909647221515, 0.14872100602281524, 0.594884024091261, 0.1784652072273783, 0.0594884024091261, 0.11445088742220406, 0.0890173568839365, 0.07630059161480271, 0.0890173568839365, 0.31791913172834463, 0.178034713767873, 0.11445088742220406, 0.8919753374575107, 0.8691349934176301, 0.8699441431892138, 0.9778181381926375, 0.918845208698204, 0.8518913274513362, 0.9413579173147019, 0.7624895027455932, 0.179409294763669, 0.9097220801547554, 0.913915170675164, 0.9275106227262392, 0.9574828774257597, 0.8700139641935284, 0.06692415109180987, 0.1606684707282122, 0.09640108243692731, 0.12853477658256973, 0.11246792950974853, 0.14460162365539095, 0.048200541218463656, 0.2892032473107819, 0.8871758232742236, 0.9665654141230702, 0.9607285912765398, 0.12492448074375678, 0.812009124834419, 0.1498277508633453, 0.8365382756536778, 0.9141736349338705, 0.9095591497944049, 0.9330382184668123, 0.9602635885826395, 0.9179289500336578, 0.897304723014027, 0.43080466880702134, 0.17121724016689308, 0.06075450457534916, 0.08284705169365794, 0.11598587237112112, 0.1325552827098527, 0.9546185491417535, 0.9084607707374559, 0.041269746666896596, 0.041269746666896596, 0.5915330355588513, 0.17883556888988525, 0.05502632888919547, 0.08253949333379319, 0.2798196285641292, 0.6795619550843137, 0.354903865882297, 0.08517692781175128, 0.2981192473411295, 0.2555307834352538, 0.8930648588062973, 0.23907861574974304, 0.6126389528587165, 0.04482724045307682, 0.08965448090615365, 0.9733845995981382, 0.9458588029769405, 0.8998370028324382, 0.1022455546172265, 0.817964436937812, 0.8059444201193585, 0.11513491715990835, 0.9064997470952981, 0.061953426190572224, 0.15488356547643056, 0.15488356547643056, 0.5266041226198639, 0.12390685238114445, 0.8736912487163514, 0.20558417560450148, 0.6938465926651926, 0.07709406585168806, 0.7137886131244261, 0.06797986791661201, 0.21526958173593802, 0.8718960560184033, 0.17465708698666774, 0.22229083798303165, 0.3493141739733355, 0.047633750996363924, 0.17465708698666774, 0.1103352697076278, 0.7355684647175187, 0.14711369294350374, 0.26599084929247946, 0.05910907762055099, 0.08866361643082647, 0.13299542464623973, 0.11821815524110198, 0.3250999269130304, 0.9213228267241822, 0.33683406511604325, 0.48840939441826275, 0.16841703255802162, 0.9067678078607633, 0.04772462146635596, 0.8585349224590088, 0.2827142183273827, 0.21619322577976324, 0.03326049627380973, 0.26608397019047786, 0.041575620342262164, 0.016630248136904866, 0.11641173695833405, 0.024945372205357298, 0.9277506688416474, 0.46434545837680635, 0.15920415715776218, 0.18573818335072254, 0.13267013096480182, 0.05306805238592072, 0.9483032545334711, 0.15764596750457513, 0.7882298375228757, 0.9646762278563602, 0.941306107774383, 0.10764505287842797, 0.8611604230274238, 0.8728887941874806, 0.09698764379860896, 0.19317141268785948, 0.11590284761271569, 0.6954170856762941, 0.4287562156554495, 0.13720198900974384, 0.07717611881798092, 0.23152835645394276, 0.03430049725243596, 0.08575124313108991, 0.8699733956713495, 0.06684690938660168, 0.635045639172716, 0.2673876375464067, 0.8865715200039312, 0.17528339941624976, 0.3856234787157495, 0.257082319143833, 0.023371119922166634, 0.09348447968866654, 0.05842779980541658, 0.8994262856282752, 0.9682869147867889, 0.9334556968931113, 0.9721665691417765, 0.26392030173961034, 0.7037874713056275, 0.0758417332270988, 0.7836979100133543, 0.12640288871183133, 0.9066026235886216, 0.976236672592487, 0.8512959176819799, 0.9392117986157819, 0.9146792111696812, 0.8181432548450499, 0.15733524131635573, 0.8619700400261865, 0.07183083666884887, 0.8952359532678441, 0.3652139324248797, 0.1591958166980245, 0.2434759549499198, 0.14046689708649218, 0.056186758834596874, 0.028093379417298437, 0.9434023816453266, 0.9737285773177434, 0.8753370720695439, 0.9868813304390519, 0.9220791907177546, 0.1687655817168651, 0.4219139542921627, 0.39378635733935186, 0.8498529838961706, 0.7475545536785931, 0.24918485122619774, 0.9230709097581243, 0.09516853318396554, 0.10706459983196123, 0.16654493307193968, 0.21412919966392246, 0.22602526631191813, 0.17844099971993538, 0.9688287425922242, 0.9691110352476507, 0.8718825381237388, 0.8869316946211683, 0.9525686897865746, 0.9816891280676814, 0.13110093538355708, 0.721055144609564, 0.16387616922944637, 0.13887011911039387, 0.08837189397934156, 0.22724201308973543, 0.3029893507863139, 0.21461745680697233, 0.025249112565526158, 0.9557372692201698, 0.8518913140980081, 0.8781917014429448, 0.9191276994322776, 0.8493949559667383, 0.16987899119334765, 0.9341654334473437, 0.8940866530122358, 0.8930652705075598, 0.8989598005616006, 0.05993065337077338, 0.952681061718128, 0.9521799337594957, 0.1617285454376566, 0.760124163556986, 0.06469141817506263, 0.8893075825269022, 0.08084614386608202, 0.9466588635790093, 0.8621514778912551, 0.8778923919691679, 0.894121150844467, 0.7513474509943184, 0.02030668786471131, 0.08122675145884524, 0.12184012718826785, 0.9131127940397074, 0.07609273283664228, 0.7715194645611699, 0.20573852388297864, 0.8345403690626498, 0.906751813241668, 0.9664261714960196, 0.4606931552529797, 0.057586644406622464, 0.4798887033885206, 0.8949438356593838, 0.5659336251865855, 0.05144851138059868, 0.23151830121269407, 0.1286212784514967, 0.9246635365747421, 0.9687636934055541, 0.9525686902602866, 0.9354480182803483, 0.9275560658216333, 0.5390340487477754, 0.11550729616023757, 0.15400972821365008, 0.15400972821365008, 0.2296497795283181, 0.2296497795283181, 0.15898830890422022, 0.3709727207765139, 0.24262458851472216, 0.7278737655441665, 0.7272712994189735, 0.1212118832364956, 0.1212118832364956, 0.9445110045553923, 0.983863821336455, 0.9451720572281281, 0.8793839440484323, 0.9483117392827196, 0.89256063794377, 0.11837267622926245, 0.11837267622926245, 0.29593169057315616, 0.059186338114631226, 0.029593169057315613, 0.3699146132164452, 0.29294901372730664, 0.13520723710491075, 0.07511513172495042, 0.09764967124243554, 0.15023026344990084, 0.12018421075992067, 0.060092105379960334, 0.030046052689980167, 0.03755756586247521, 0.30431708119060197, 0.09129512435718058, 0.22316585953977477, 0.38546830284142913, 0.4691217447759636, 0.08158639039581976, 0.12237958559372963, 0.06118979279686482, 0.2651557687864142, 0.8749964414864, 0.8875519546490603, 0.8709067768287778, 0.07257556473573148, 0.10814020943731142, 0.07209347295820762, 0.5767477836656609, 0.10814020943731142, 0.10814020943731142, 0.9734585828113692, 0.3336587492482673, 0.06673174984965345, 0.16682937462413364, 0.06673174984965345, 0.033365874924826726, 0.3336587492482673, 0.9571483277065929, 0.04896798143335539, 0.7345197215003307, 0.14690394430006615, 0.8832618649937101, 0.9058076177021718, 0.2624918508001466, 0.6562296270003665, 0.08749728360004887, 0.8730802596251676, 0.9615870689279588, 0.2027416688622404, 0.7704183416765136, 0.9119942419292785, 0.06298909365273192, 0.17322000754501277, 0.09448364047909787, 0.18896728095819573, 0.10235727718568936, 0.09448364047909787, 0.0787363670659149, 0.11023091389228085, 0.10235727718568936, 0.871697084469736, 0.09685523160774845, 0.9721896737489949, 0.5645748462304154, 0.09238497483770433, 0.11291496924608307, 0.15397495806284056, 0.03079499161256811, 0.04105998881675748, 0.24322677084927988, 0.7296803125478396, 0.9618717432792191, 0.953106760420312, 0.5836312606253431, 0.19454375354178105, 0.07295390757816789, 0.12158984596361315, 0.963323143960925, 0.3111935360163925, 0.5026972504880186, 0.19150371447162615, 0.29107224164884105, 0.6653079809116367, 0.9562623362644974, 0.9632497463173909, 0.9667414684215244, 0.952875282925378, 0.9895642524974919, 0.8125822069068412, 0.10598898350958799, 0.07065932233972533, 0.34663281534125684, 0.4085315323664813, 0.049518973620179554, 0.1856961510756733, 0.9484716531522854, 0.6674665174358533, 0.027811104893160552, 0.16686662935896332, 0.11124441957264221, 0.9324187355616561, 0.31124808974104484, 0.6614021906997203, 0.1319577083794318, 0.7917462502765908, 0.8772660779257972, 0.19925108485711074, 0.3260472297661812, 0.09056867493505034, 0.28981975979216107, 0.09056867493505034, 0.23321533662516392, 0.5231587281050974, 0.12606234412171022, 0.1134561097095392, 0.10423812778118875, 0.2779683407498367, 0.08339050222495101, 0.041695251112475504, 0.11118733629993467, 0.06254287666871325, 0.14593337889366426, 0.048644459631221416, 0.1250857533374265, 0.23352296231869243, 0.18014628521727702, 0.1000812695651539, 0.1534579466665693, 0.2668833855070771, 0.060048761739092335, 0.2236924922031625, 0.7456416406772084, 0.11378390288270321, 0.7498067446373007, 0.1225365107967573, 0.014587679856756823, 0.8915156624859472, 0.12675248891087526, 0.07800153163746171, 0.20962911627567832, 0.009750191454682713, 0.04875095727341357, 0.0341256700913895, 0.10237701027416848, 0.10237701027416848, 0.28763064791314, 0.8626777184122247, 0.8605159668215985, 0.8904736632609259, 0.08726089724732644, 0.17452179449465288, 0.30541314036564254, 0.41448926192480057, 0.9631513492531194, 0.7293832004171436, 0.1823458001042859, 0.03646916002085718, 0.9662052767294915, 0.18215912708235155, 0.8067047056504141, 0.8098835744819853, 0.08098835744819853, 0.09408947977274595, 0.8468053179547136, 0.2525284606512143, 0.5839720652559331, 0.14204725911630806, 0.1591804956245295, 0.1591804956245295, 0.636721982498118, 0.9382066550980739, 0.06697115533758138, 0.870625019388558, 0.07566350001226808, 0.12106160001962894, 0.21185780003435065, 0.030265400004907236, 0.24212320003925789, 0.10592890001717532, 0.21185780003435065, 0.9055530091247864, 0.06709192975234868, 0.14376842089789002, 0.14376842089789002, 0.2108603506502387, 0.028753684179578003, 0.11501473671831201, 0.2971214031889727, 0.959960956738302, 0.806585305101128, 0.18613507040795263, 0.9542335355785788, 0.9541022625876496, 0.9771405938378037, 0.6416028015648424, 0.1809648927490581, 0.16451353886278008, 0.946450740144789, 0.8409680579607555, 0.10512100724509443, 0.968145937712365, 0.8864008292649154, 0.9062634967646945, 0.9166872759445854, 0.06924957147403829, 0.1615823334394227, 0.023083190491346096, 0.5539965717923063, 0.1615823334394227, 0.023083190491346096, 0.9152255905194482, 0.14985569175882896, 0.7492784587941448, 0.02997113835176579, 0.02997113835176579, 0.9107356179966416, 0.06746189762938086, 0.8861822775414517, 0.3179672650889966, 0.6359345301779932, 0.8068681034959455, 0.14670329154471737, 0.9150812222848417, 0.9714820880539884, 0.9101399876571353, 0.8926753272966819, 0.7473705019598245, 0.12456175032663742, 0.12456175032663742, 0.2223395638995397, 0.09264148495814155, 0.4817357217823361, 0.11116978194976986, 0.09264148495814155, 0.936573759816073, 0.554503969515027, 0.29981900677265994, 0.05480562489392708, 0.07737264690907353, 0.012895441151512255, 0.9106223583490561, 0.26860901773703044, 0.20145676330277282, 0.06715225443425761, 0.4700657810398033, 0.10840593748609435, 0.07227062499072957, 0.7949768748980253, 0.1284422277101002, 0.14011879386556383, 0.31526728619751865, 0.11676566155463652, 0.17514849233195479, 0.1284422277101002, 0.28998178630544036, 0.6766241680460275, 0.27009270377621564, 0.708993347412566, 0.2141120178089741, 0.08564480712358964, 0.02141120178089741, 0.18199521513762798, 0.44963523739884564, 0.010705600890448705, 0.03211680267134612, 0.8955961658419221, 0.08141783325835657, 0.8126834888408038, 0.9063250847187381, 0.03895576732440189, 0.701203811839234, 0.16880832507240817, 0.0908967904236044, 0.112372560022802, 0.3300943950669809, 0.07374449251496382, 0.035116425007125626, 0.10183763252066431, 0.15802391253206532, 0.09481434751923919, 0.024581497504987938, 0.06672120751353869, 0.4349529830653598, 0.07853317749791218, 0.1147792594200255, 0.054369122883169974, 0.1147792594200255, 0.054369122883169974, 0.07853317749791218, 0.06041013653685552, 0.16268368598890448, 0.8134184299445224, 0.027398765656844223, 0.5260563006114091, 0.12603432202148343, 0.14247358141558997, 0.016439259394106533, 0.09315580323327036, 0.06027728444505729, 0.17921796750382563, 0.08960898375191281, 0.14561459859685832, 0.22402245937978205, 0.12321235265888011, 0.10081010672090192, 0.05600561484494551, 0.08960898375191281, 0.25102167647255175, 0.19645174680460573, 0.26193566240614097, 0.03274195780076762, 0.010913985933589207, 0.12005384526948128, 0.12005384526948128, 0.01491674705663885, 0.10441722939647195, 0.1790009646796662, 0.28341819407613816, 0.37291867641597126, 0.04475024116991655, 0.4760838746669819, 0.1325181919176135, 0.14233435428188118, 0.2454040591066917, 0.9583630005360889, 0.96346238686797, 0.9161563241785253, 0.8698996961607858, 0.8505714227135034, 0.21286100200896482, 0.18205217277082517, 0.18205217277082517, 0.15124334353268554, 0.10643050100448241, 0.07282086910833006, 0.025207223922114254, 0.04481284252820312, 0.025207223922114254, 0.3683950538048819, 0.06777078819995469, 0.20852550215370674, 0.07993477582558758, 0.13380386388196183, 0.07645935078969247, 0.03822967539484624, 0.029541112805108453, 0.16770946278589316, 0.7826441596675014, 0.5119139023989832, 0.045168873741086746, 0.12045032997623131, 0.1053940387292024, 0.22584436870543373, 0.26431549270310517, 0.05873677615624559, 0.6461045377187015, 0.9428181265906669, 0.027729944899725495, 0.9596030141103876, 0.12271280200277479, 0.04719723153952877, 0.16991003354230355, 0.2643044966213611, 0.09439446307905754, 0.07551557046324603, 0.16991003354230355, 0.04719723153952877, 0.11797842036115236, 0.19305559695461297, 0.1287037313030753, 0.06435186565153765, 0.24668215166422766, 0.1287037313030753, 0.11797842036115236, 0.04946306752881043, 0.06801171785211435, 0.11129190193982347, 0.3091441720550652, 0.17930361979193782, 0.01854865032330391, 0.21021803699744435, 0.055645950969911734, 0.8960532931080551, 0.11112525434151589, 0.0889002034732127, 0.20002545781472858, 0.2889256612879413, 0.2889256612879413, 0.9552479197740945, 0.9733789568768871, 0.8772437682921518, 0.15373495476264956, 0.27864460550730236, 0.16334338943531515, 0.24981930148930553, 0.06725904270865918, 0.08647591205399038, 0.8776357637653103, 0.1170181018353747, 0.7925618860028333, 0.1828988967698846, 0.938860631133667, 0.8639757527026827, 0.17807982088455482, 0.05087994882415852, 0.07631992323623778, 0.05087994882415852, 0.1271998720603963, 0.02543997441207926, 0.4579195394174267, 0.0891421566956054, 0.2971405223186847, 0.5942810446373694, 0.9490839635650962, 0.8650730589589816, 0.9533812035673119, 0.360499419139353, 0.6248656598415452, 0.8329482732226835, 0.9786888468519362, 0.7181632138834595, 0.19586269469548895, 0.06399874535807039, 0.9279818076920208, 0.2268015041797465, 0.26308974484850595, 0.09979266183908846, 0.08164854150470874, 0.0453603008359493, 0.09979266183908846, 0.12700884234065804, 0.06350442117032902, 0.17141136932094378, 0.07346201542326163, 0.6856454772837751, 0.07346201542326163, 0.19273902572372648, 0.4452936111548163, 0.19938519902454463, 0.10633877281309047, 0.04652321310572708, 0.12669105568224892, 0.08197656544145518, 0.2086676211237041, 0.08197656544145518, 0.22357245120396865, 0.08942898048158747, 0.037262075200661444, 0.09688139552171976, 0.044714490240793735, 0.23504835872387644, 0.4700967174477529, 0.26116484302652937, 0.6404066085091031, 0.11301293091337114, 0.22602586182674228, 0.19064498530962423, 0.38128997061924846, 0.04085249685206234, 0.08170499370412468, 0.13617498950687446, 0.06808749475343723, 0.09532249265481212, 0.951259705275078, 0.3101976112400634, 0.10339920374668779, 0.20679840749337558, 0.09047430327835182, 0.09047430327835182, 0.18094860655670364, 0.8443645002850936, 0.8394119428169762, 0.06995099523474801, 0.22789770881888052, 0.6836931264566415, 0.3405783810371534, 0.14596216330163717, 0.06892657711466199, 0.2311067585609255, 0.07298108165081858, 0.11352612701238446, 0.024327027216939526, 0.24136537718485235, 0.7426626990303149, 0.9294990887122094, 0.9628148235327272, 0.7485466671114335, 0.22456400013343006, 0.20479493603822704, 0.300792562306146, 0.05759857576075136, 0.09599762626791893, 0.07679810101433515, 0.07039825926314056, 0.019199525253583788, 0.1727957272822541, 0.9033143659196413, 0.9464509408464974, 0.9127186714515195, 0.09804249849002791, 0.049021249245013956, 0.8333612371652372, 0.9174136651765865, 0.9624983256672529, 0.9150811473042251, 0.023311274744511678, 0.023311274744511678, 0.20203104778576786, 0.3574395460825124, 0.32635784642316346, 0.07770424914837226, 0.11230274837891806, 0.19126561833284483, 0.05264191330261784, 0.057906104632879624, 0.2298696880880979, 0.20705819232363018, 0.13862370503022697, 0.012283113103944162, 0.8634010453236992, 0.1079251306654624, 0.2634458299809221, 0.1693580335591642, 0.5645267785305473, 0.9556489499342046, 0.9127095094407832, 0.03017414025269104, 0.4526121037903656, 0.33191554277960145, 0.04526121037903656, 0.0754353506317276, 0.04526121037903656, 0.9465639009171529, 0.8498095403427441, 0.8826556437590535, 0.9500480601541167, 0.8827812811549148, 0.9421074349262998, 0.2377529389896125, 0.095101175595845, 0.665708229170915, 0.10445281334416417, 0.8704401112013681, 0.290047603881717, 0.17173871282470085, 0.16792229698415195, 0.03816415840548908, 0.015265663362195632, 0.1412073861003096, 0.03434774256494017, 0.015265663362195632, 0.11449247521646724, 0.011449247521646725, 0.9180677634297131, 0.9437350913164787, 0.17127430494728563, 0.7992800897539996, 0.4295823266039888, 0.06443734899059832, 0.0536977908254986, 0.07517690715569804, 0.268488954127493, 0.1073955816509972, 0.15002250150780344, 0.7501125075390171, 0.8988130592688348, 0.8412421980706337, 0.14845450554187656, 0.9287914391331786, 0.896377358936142, 0.18219220818751455, 0.09109610409375728, 0.23684987064376894, 0.40082285801253204, 0.018219220818751457, 0.07287688327500583, 0.25397657920194056, 0.7256473691484017, 0.9422693530763618, 0.5733844701223287, 0.17450831699375222, 0.09971903828214412, 0.12464879785268015, 0.11296907754610931, 0.8472680815958198, 0.028443482483569264, 0.7679740270563702, 0.1706608949014156, 0.9489489008303282, 0.9648520082058213, 0.23191939203463732, 0.15944458202381315, 0.3333841260497912, 0.1304546580194835, 0.086969772012989, 0.014494962002164833, 0.0434848860064945, 0.9463764819698774, 0.9564588869001649, 0.9617146316592986, 0.17361496693872205, 0.13889197355097763, 0.06944598677548881, 0.6250138809793994, 0.04175731701109404, 0.2644630077369289, 0.013919105670364678, 0.6541979665071399, 0.013919105670364678, 0.9262371602430407, 0.9300411326656391, 0.0781177924875336, 0.0390588962437668, 0.195294481218834, 0.6640012361440356, 0.8894654136823913, 0.930659406373813, 0.06710848885606621, 0.7046391329886952, 0.06710848885606621, 0.16777122214016552, 0.9642513517013094, 0.9597231618179058, 0.7259883767408594, 0.14519767534817188, 0.09679845023211459, 0.851295848581915, 0.9702039718802218, 0.942254299519039, 0.8916911797535901, 0.9118510503908092, 0.23037590020250892, 0.25917288772782254, 0.5183457754556451, 0.8777045873423145, 0.911316255192106, 0.07594302126600884, 0.909136790225703, 0.0964228980680208, 0.241057245170052, 0.6267488374421352, 0.0241057245170052, 0.2315351830899952, 0.06314595902454415, 0.06314595902454415, 0.2525838360981766, 0.3578271011390835, 0.9455676690550432, 0.9255875488625993, 0.8588151349007415, 0.8548925439829201, 0.895928728874407, 0.8012905927698025, 0.28880161103768226, 0.28880161103768226, 0.4171578826099855, 0.9116705510812335, 0.8888384061246228, 0.0833286005741834, 0.8926751890342557, 0.8921323460844691, 0.9135484994412683, 0.8671731413263042, 0.07708205700678258, 0.03854102850339129, 0.9677406058917457, 0.9466626660532126, 0.9150167184135412, 0.9255659020062097, 0.2735603273643341, 0.6839008184108353, 0.02279669394702784, 0.13619541564701554, 0.8171724938820932, 0.9433819700958255, 0.9698222606717802, 0.28167764612226964, 0.7243139471715505, 0.3628316631381374, 0.07732478066878339, 0.142753441234677, 0.10111702087456288, 0.1724937414919014, 0.059480600514448756, 0.0237922402057795, 0.047584480411559, 0.017844180154334626, 0.8972031322639062, 0.3337785769565155, 0.05135055030100239, 0.128376375752506, 0.10270110060200478, 0.3851291272575179, 0.8863694160353148, 0.09330204379319103, 0.027408265488106747, 0.9592892920837361, 0.8840434358483494, 0.10433684600431588, 0.886863191036685, 0.14668678614006084, 0.1393524468330578, 0.2640362150521095, 0.14668678614006084, 0.04400603584201825, 0.09534641099103955, 0.04400603584201825, 0.12468376821905172, 0.18700290111242143, 0.041556200247204765, 0.062334300370807144, 0.08311240049440953, 0.39478390234844524, 0.1038905006180119, 0.14544670086521666, 0.8985497895156671, 0.05126430684440632, 0.20505722737762527, 0.034176204562937545, 0.5809954775699383, 0.05126430684440632, 0.05126430684440632, 0.9818436348591819, 0.8847746522346032, 0.8571444566569768, 0.10444084302017888, 0.5430923837049302, 0.12532901162421464, 0.22976985464439353, 0.9407819716238529, 0.8908459599068387, 0.06852661230052605, 0.8500531157317013, 0.1133404154308935, 0.9613691069850563, 0.13228428147420837, 0.8267767592138022, 0.8760844732906193, 0.8868490262174854, 0.8537160826065375, 0.113828811014205, 0.8615733776693176, 0.8702830600319004, 0.0756767878288609, 0.9520281914356795, 0.9552571360280844, 0.9498520147870742, 0.9348929695434991, 0.7823842154791872, 0.20410023012500536, 0.2706892633436899, 0.24986701231725222, 0.12493350615862611, 0.11452238064540728, 0.23945588680403337, 0.058085936916259344, 0.14521484229064835, 0.2033007792069077, 0.5227734322463341, 0.058085936916259344, 0.33742723176348866, 0.6266505732750504, 0.2243773427844502, 0.15425942316430952, 0.2664480945565346, 0.19633017493639393, 0.12621225531625324, 0.042070751772084414, 0.12544257726228414, 0.04181419242076138, 0.1881638658934262, 0.4390490204179945, 0.1881638658934262, 0.2266560815933147, 0.18888006799442894, 0.5666402039832867, 0.20720711904089464, 0.7597594364832804, 0.9627098020137774, 0.953533156440968, 0.9322842121256478, 0.19317504526449095, 0.811335190110862, 0.9548645641158657, 0.2814513164375239, 0.6567197383542225, 0.873143046168248, 0.8907725474655154, 0.05239838514503032, 0.047322046997899395, 0.709830704968491, 0.18928818799159758, 0.9375915343807085, 0.9649603108818287, 0.8251085864112576, 0.03587428636570685, 0.10762285909712056, 0.05756426883945297, 0.9210283014312475, 0.9394550801301024, 0.9476576855050716, 0.27952097209205007, 0.6708503330209202, 0.9683519931080331, 0.2297080242317089, 0.15751407375888613, 0.15095098735226586, 0.18376641938536714, 0.09188320969268357, 0.09844629609930382, 0.06563086406620255, 0.019689259219860766, 0.8895381379080661, 0.16325702549433402, 0.81628512747167, 0.916964063329215, 0.0821161847757506, 0.9507038901352988, 0.27811283896301664, 0.13905641948150832, 0.5562256779260333, 0.5958472278155593, 0.23315761088434928, 0.12953200604686071, 0.9351974203237002, 0.952704137971283, 0.3220278690237791, 0.6679096542715418, 0.09298851332704469, 0.8368966199434023, 0.8126841712699148, 0.9798684690680902, 0.9478957429759102, 0.9627103207519176, 0.849348505164924, 0.070779042097077, 0.23559184025696173, 0.19071720401754044, 0.2608338231416362, 0.09535860200877022, 0.022437318119710642, 0.12060058489344469, 0.030851312414602133, 0.01963265335474681, 0.022437318119710642, 0.054251122061301255, 0.21700448824520502, 0.23960912243741386, 0.1401487319916949, 0.054251122061301255, 0.027125561030650627, 0.11754409779948605, 0.06329297573818479, 0.004520926838441771, 0.08137668309195188, 0.9775350178109257, 0.23652651480099607, 0.11826325740049803, 0.03942108580016601, 0.6307373728026562, 0.4995569500061438, 0.09515370476307501, 0.4044032452430688, 0.9403877490605163, 0.9203257068164157, 0.25520567547731604, 0.24019357691982685, 0.030024197114978356, 0.1451169527223954, 0.09507662419743146, 0.06004839422995671, 0.05504436137746032, 0.08506855849243868, 0.03502822996747475, 0.16848396607822191, 0.16848396607822191, 0.6177745422868137, 0.9694807539940178, 0.846485755134847, 0.18663075257295808, 0.7931806984350718, 0.9306561355320434, 0.9473842200984754, 0.9577405317230996, 0.9088437398348508, 0.02903564981859833, 0.261320848367385, 0.05807129963719666, 0.11614259927439333, 0.3097135980650489, 0.09678549939532777, 0.048392749697663884, 0.02903564981859833, 0.05807129963719666, 0.17396244568610109, 0.2561113783712044, 0.16913015552815386, 0.05798748189536703, 0.18845931615994285, 0.07731664252715605, 0.0821489326851033, 0.9199120575524972, 0.9552561335700962, 0.103988815348038, 0.831910522784304, 0.9446578045753246, 0.16005760513206657, 0.09603456307923994, 0.04801728153961997, 0.2881036892377198, 0.06402304205282662, 0.08002880256603329, 0.27209792872451316, 0.2802191156234716, 0.056043823124694324, 0.3923067618728603, 0.07846135237457205, 0.011208764624938866, 0.17934023399902185, 0.09820544540487063, 0.6874381178340944, 0.1767698017287671, 0.03928217816194825, 0.9478943923577947, 0.049889178545147086, 0.19414653027323303, 0.2184148465573872, 0.19414653027323303, 0.04853663256830826, 0.3154881116940037, 0.9512263855861247, 0.9639666305626432, 0.16421374387763182, 0.8210687193881591, 0.9586462708484397, 0.45865898340857175, 0.2830023514648634, 0.09758701774650463, 0.029276105323951387, 0.12686312307045602, 0.28055898552096364, 0.6546376328822485, 0.38690453299926525, 0.1361330764256674, 0.2436065578143522, 0.10030858262943915, 0.07164898759245653, 0.007164898759245653, 0.05731919007396522, 0.14416171053900179, 0.7688624562080095, 0.048053903513000595, 0.9475133392140785, 0.8554921895468545, 0.43943627819499, 0.2746476738718687, 0.219718139097495, 0.05492953477437375, 0.0219718139097495, 0.923932186984169, 0.07107170669108992, 0.6192017684412773, 0.34400098246737626, 0.8900966886710879, 0.8468220755765992, 0.12097458222522844, 0.9353815597038855, 0.9380000960775807, 0.9562149406591476, 0.44155954300701633, 0.08028355327400297, 0.36127598973301334, 0.1003544415925037, 0.9546646942937645, 0.23304717614906834, 0.067658857591665, 0.202976572774995, 0.03758825421759167, 0.13531771518333, 0.07517650843518334, 0.12028241349629334, 0.04510590506111, 0.09021181012222, 0.24424080921297744, 0.08819806999357518, 0.09498253691615789, 0.08819806999357518, 0.48169715150337217, 0.9375649980856444, 0.20381008018830696, 0.02264556446536744, 0.41894294260929765, 0.0566139111634186, 0.10190504009415348, 0.20381008018830696, 0.13959390414905318, 0.33502536995772764, 0.21404398636188154, 0.01861252055320709, 0.06514382193622481, 0.23265650691508863, 0.0964385372240849, 0.32146179074694964, 0.28931561167225467, 0.05051542426023495, 0.16991551796624482, 0.013776933889154986, 0.05510773555661994, 0.8297898238168849, 0.17684346452186672, 0.21325241309989812, 0.10402556736580396, 0.16123962941699613, 0.2184536914681883, 0.13003195920725494, 0.8907693510944683, 0.09742789777595748, 0.3204124308901252, 0.09345362567628651, 0.5206702001964535, 0.053402071815020866, 0.8777044053379092, 0.19352906353729324, 0.24191132942161656, 0.11289195373008773, 0.3548032831517043, 0.09676453176864662, 0.95766208292651], \"Term\": [\"Ah\", \"Always\", \"America\", \"America\", \"America\", \"Better\", \"Books\", \"Congress\", \"Conscience\", \"England\", \"Except\", \"Experience\", \"Faith\", \"Fiction\", \"Fortunately\", \"Fortune\", \"God\", \"God\", \"God\", \"God\", \"God\", \"God\", \"God\", \"God\", \"Imagination\", \"Iraqi\", \"Knowledge\", \"Let\", \"Let\", \"Let\", \"Life\", \"Life\", \"London\", \"Man\", \"Man\", \"Man\", \"Man\", \"Men\", \"Men\", \"Nothing\", \"Nothing\", \"Nothing\", \"Nothing\", \"One\", \"One\", \"One\", \"One\", \"One\", \"One\", \"One\", \"Science\", \"Though\", \"Time\", \"Truth\", \"Virtue\", \"Whenever\", \"Woman\", \"Women\", \"Women\", \"Words\", \"Work\", \"absolute\", \"aby\", \"account\", \"account\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"action\", \"adore\", \"adversity\", \"advice\", \"afraid\", \"afraid\", \"age\", \"age\", \"agreement\", \"ahead\", \"alike\", \"alone\", \"along\", \"alter\", \"always\", \"always\", \"always\", \"always\", \"always\", \"always\", \"angry\", \"annoy\", \"another\", \"another\", \"another\", \"another\", \"another\", \"another\", \"answer\", \"answer\", \"anything\", \"anything\", \"anything\", \"anything\", \"argument\", \"art\", \"art\", \"art\", \"art\", \"artist\", \"astonish\", \"asylum\", \"attain\", \"attain\", \"attempt\", \"attempt\", \"audience\", \"authority\", \"authority\", \"authority\", \"authority\", \"authority\", \"awake\", \"away\", \"away\", \"away\", \"bad\", \"bad\", \"bad\", \"basis\", \"bear\", \"bear\", \"bear\", \"bear\", \"bear\", \"beauty\", \"beauty\", \"beauty\", \"become\", \"become\", \"become\", \"become\", \"become\", \"become\", \"bed\", \"begin\", \"begin\", \"begin\", \"behind\", \"behind\", \"behold\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"believe\", \"belong\", \"best\", \"best\", \"best\", \"best\", \"best\", \"biography\", \"birth\", \"birth\", \"black\", \"blame\", \"bless\", \"bless\", \"blind\", \"blind\", \"blood\", \"blood\", \"blood\", \"book\", \"book\", \"book\", \"book\", \"book\", \"book\", \"bore\", \"break\", \"break\", \"break\", \"buy\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"capable\", \"capacity\", \"careful\", \"cat\", \"cease\", \"cease\", \"certain\", \"certain\", \"certain\", \"charity\", \"charm\", \"cheer\", \"choice\", \"classify\", \"clothe\", \"clothe\", \"cold\", \"cold\", \"combination\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"comfort\", \"commitment\", \"complaint\", \"compliment\", \"consciousness\", \"consist\", \"consist\", \"consist\", \"contempt\", \"conversation\", \"conversation\", \"conviction\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"count\", \"coward\", \"criminal\", \"current\", \"cynic\", \"dance\", \"dangerous\", \"dangerous\", \"dangerous\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"deal\", \"deceive\", \"delight\", \"delightful\", \"demand\", \"demand\", \"despise\", \"destroy\", \"detect\", \"determine\", \"determine\", \"develop\", \"devil\", \"die\", \"die\", \"die\", \"difference\", \"difference\", \"disappoint\", \"disaster\", \"disposition\", \"divide\", \"do\", \"do\", \"do\", \"do\", \"door\", \"door\", \"drink\", \"drink\", \"drive\", \"due\", \"dull\", \"duty\", \"duty\", \"duty\", \"early\", \"earth\", \"earth\", \"earth\", \"earth\", \"easily\", \"easy\", \"editor\", \"educate\", \"eighteen\", \"else\", \"else\", \"else\", \"else\", \"end\", \"end\", \"end\", \"end\", \"enemy\", \"enemy\", \"enjoy\", \"enjoy\", \"enjoy\", \"envy\", \"equal\", \"equally\", \"error\", \"escape\", \"especially\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"everything\", \"everything\", \"everything\", \"everything\", \"except\", \"except\", \"except\", \"except\", \"except\", \"excess\", \"excuse\", \"exercise\", \"exercise\", \"exist\", \"exist\", \"exist\", \"exist\", \"exist\", \"expect\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"fact\", \"failure\", \"faith\", \"faith\", \"faith\", \"faithful\", \"family\", \"fashion\", \"fashion\", \"fashion\", \"fatal\", \"fiction\", \"fight\", \"fight\", \"fill\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fine\", \"fine\", \"fire\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fish\", \"fish\", \"five\", \"flat\", \"fool\", \"fool\", \"fool\", \"fool\", \"forbid\", \"force\", \"force\", \"force\", \"forget\", \"forget\", \"forgive\", \"forty\", \"forward\", \"four\", \"free\", \"freedom\", \"freedom\", \"freedom\", \"friend\", \"friend\", \"friend\", \"friend\", \"front\", \"full\", \"full\", \"full\", \"full\", \"funeral\", \"future\", \"future\", \"game\", \"game\", \"gaze\", \"genius\", \"genius\", \"genius\", \"genius\", \"genius\", \"get\", \"get\", \"get\", \"get\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"golden\", \"golden\", \"good\", \"good\", \"good\", \"good\", \"gossip\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"greatly\", \"grieve\", \"group\", \"grow\", \"grow\", \"grow\", \"grow\", \"hair\", \"half\", \"half\", \"half\", \"happen\", \"happy\", \"happy\", \"hardly\", \"hardly\", \"harmony\", \"harmony\", \"heart\", \"heart\", \"heart\", \"heaven\", \"heaven\", \"heaven\", \"heroic\", \"hide\", \"hide\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"honesty\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"humanity\", \"humor\", \"humor\", \"hungry\", \"hurt\", \"husband\", \"idea\", \"idea\", \"idea\", \"ignorant\", \"imagine\", \"imagine\", \"imitate\", \"immoral\", \"immortality\", \"importance\", \"important\", \"important\", \"important\", \"important\", \"important\", \"important\", \"impressive\", \"individual\", \"individual\", \"individual\", \"individual\", \"information\", \"information\", \"insane\", \"intellect\", \"intellect\", \"intelligence\", \"intelligence\", \"intention\", \"interfere\", \"inventor\", \"iron\", \"joy\", \"joy\", \"joy\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kindness\", \"know\", \"know\", \"know\", \"know\", \"know\", \"lady\", \"language\", \"language\", \"language\", \"language\", \"large\", \"large\", \"large\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"lay\", \"lay\", \"lead\", \"lead\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"least\", \"least\", \"liberty\", \"lid\", \"lie\", \"lie\", \"lie\", \"lie\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"like\", \"literature\", \"literature\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"live\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"love\", \"love\", \"love\", \"love\", \"lover\", \"luxury\", \"mad\", \"madness\", \"mainly\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"manner\", \"manner\", \"many\", \"many\", \"many\", \"many\", \"many\", \"marriage\", \"marriage\", \"marriage\", \"marry\", \"marry\", \"mask\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"mental\", \"merely\", \"merely\", \"merely\", \"merely\", \"merely\", \"middle\", \"mighty\", \"million\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"mind\", \"minute\", \"minute\", \"miracle\", \"miracle\", \"miss\", \"mode\", \"modern\", \"modern\", \"modern\", \"modern\", \"modern\", \"modern\", \"modern\", \"money\", \"money\", \"money\", \"monkey\", \"monster\", \"moon\", \"moral\", \"moral\", \"moralize\", \"mostly\", \"mother\", \"mother\", \"move\", \"move\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"music\", \"music\", \"music\", \"music\", \"must\", \"must\", \"must\", \"must\", \"must\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"n\", \"name\", \"name\", \"name\", \"natural\", \"natural\", \"natural\", \"nature\", \"nature\", \"nature\", \"nature\", \"nature\", \"nature\", \"nature\", \"necessity\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"neglect\", \"neighbor\", \"neighbor\", \"neither\", \"neither\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"new\", \"new\", \"newspaper\", \"nine\", \"none\", \"none\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"nothing\", \"notice\", \"notion\", \"novel\", \"number\", \"number\", \"number\", \"oblige\", \"obvious\", \"offend\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"oneself\", \"oneself\", \"opinion\", \"opinion\", \"opinion\", \"optimist\", \"original\", \"others\", \"others\", \"others\", \"others\", \"others\", \"others\", \"otherwise\", \"outline\", \"overestimate\", \"painful\", \"partly\", \"party\", \"passion\", \"passion\", \"passion\", \"past\", \"past\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"perfection\", \"perhaps\", \"period\", \"period\", \"person\", \"person\", \"person\", \"person\", \"person\", \"person\", \"personal\", \"personal\", \"pessimist\", \"philosopher\", \"philosopher\", \"physical\", \"pig\", \"place\", \"place\", \"place\", \"place\", \"place\", \"place\", \"play\", \"play\", \"pleasant\", \"pleasure\", \"pleasure\", \"pleasure\", \"pleasure\", \"poetry\", \"poetry\", \"poor\", \"poor\", \"poor\", \"position\", \"possibility\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"pray\", \"prayer\", \"precious\", \"present\", \"present\", \"present\", \"present\", \"president\", \"president\", \"president\", \"president\", \"president\", \"press\", \"prevent\", \"principle\", \"principle\", \"principle\", \"principle\", \"privilege\", \"probably\", \"problem\", \"problem\", \"problem\", \"problem\", \"produce\", \"proper\", \"prove\", \"prove\", \"prove\", \"publisher\", \"punish\", \"punishment\", \"pure\", \"quiet\", \"race\", \"race\", \"race\", \"rarely\", \"read\", \"read\", \"ready\", \"real\", \"real\", \"real\", \"real\", \"really\", \"really\", \"really\", \"really\", \"really\", \"refuge\", \"regret\", \"relief\", \"rely\", \"reputation\", \"request\", \"require\", \"require\", \"require\", \"respectable\", \"rest\", \"rest\", \"reverence\", \"reward\", \"rhyme\", \"rich\", \"rich\", \"rich\", \"rid\", \"risk\", \"river\", \"ruin\", \"rule\", \"rule\", \"rule\", \"sad\", \"sad\", \"saint\", \"savage\", \"save\", \"save\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scarce\", \"school\", \"school\", \"school\", \"school\", \"school\", \"second\", \"second\", \"secret\", \"secret\", \"secure\", \"security\", \"security\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"seem\", \"seem\", \"seem\", \"seem\", \"seem\", \"seem\", \"seem\", \"selfish\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"sense\", \"shallow\", \"shame\", \"sheep\", \"show\", \"show\", \"show\", \"show\", \"sick\", \"sight\", \"sight\", \"sign\", \"sign\", \"silence\", \"simple\", \"simple\", \"sincere\", \"sincerity\", \"sinner\", \"sinner\", \"sir\", \"sit\", \"sit\", \"slave\", \"smile\", \"smoke\", \"solve\", \"someone\", \"someone\", \"something\", \"something\", \"something\", \"something\", \"something\", \"sometimes\", \"sometimes\", \"sometimes\", \"sometimes\", \"sometimes\", \"sorrow\", \"sorrow\", \"soul\", \"soul\", \"soul\", \"soul\", \"soul\", \"soul\", \"speak\", \"speak\", \"speak\", \"speak\", \"speak\", \"speech\", \"speech\", \"speech\", \"spend\", \"spend\", \"standard\", \"star\", \"stave\", \"step\", \"step\", \"stick\", \"stop\", \"stop\", \"storm\", \"story\", \"story\", \"strength\", \"strength\", \"strength\", \"struggle\", \"subject\", \"support\", \"support\", \"support\", \"sure\", \"sure\", \"suspect\", \"swear\", \"sympathy\", \"sympathy\", \"tail\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"tale\", \"talent\", \"talent\", \"talk\", \"talk\", \"tame\", \"taste\", \"taste\", \"taste\", \"teach\", \"teach\", \"teach\", \"tear\", \"tedious\", \"tell\", \"tell\", \"temper\", \"temper\", \"temperament\", \"temptation\", \"ten\", \"test\", \"thee\", \"thee\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"thoroughly\", \"thousand\", \"thousand\", \"thousand\", \"thousand\", \"three\", \"three\", \"three\", \"thy\", \"tie\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"today\", \"today\", \"today\", \"towards\", \"trace\", \"tragedy\", \"tragedy\", \"train\", \"treat\", \"trouble\", \"truly\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"truth\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"u\", \"ugly\", \"unexpected\", \"unhappy\", \"unhappy\", \"universal\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"value\", \"value\", \"value\", \"value\", \"view\", \"view\", \"virtue\", \"virtue\", \"virtue\", \"virtue\", \"virtue\", \"vision\", \"vulgar\", \"wait\", \"wait\", \"walk\", \"want\", \"want\", \"want\", \"want\", \"want\", \"water\", \"water\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"wealth\", \"wealth\", \"wealth\", \"weapon\", \"welcome\", \"well\", \"well\", \"well\", \"well\", \"well\", \"whatever\", \"whatever\", \"whether\", \"whether\", \"wild\", \"win\", \"win\", \"window\", \"wine\", \"winter\", \"wise\", \"wise\", \"wise\", \"wise\", \"wit\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"wonder\", \"word\", \"word\", \"word\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"worthy\", \"would\", \"would\", \"would\", \"would\", \"would\", \"would\", \"write\", \"write\", \"year\", \"year\", \"year\", \"year\", \"yes\", \"young\", \"young\", \"young\", \"young\", \"young\", \"youth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [8, 9, 6, 4, 3, 7, 1, 10, 2, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el100801140825901768169422962\", ldavis_el100801140825901768169422962_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el100801140825901768169422962\", ldavis_el100801140825901768169422962_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el100801140825901768169422962\", ldavis_el100801140825901768169422962_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "7      14.848114        1       1 -0.109996 -0.021130\n",
       "8      14.076502        1       2 -0.106118 -0.005127\n",
       "5      12.276568        1       3 -0.052296 -0.028263\n",
       "3      10.377219        1       4 -0.080832 -0.105629\n",
       "2      10.110779        1       5 -0.076642 -0.026710\n",
       "6       9.132754        1       6 -0.031053  0.138052\n",
       "0       8.338834        1       7  0.049081  0.222431\n",
       "9       8.021156        1       8  0.053719 -0.074648\n",
       "1       6.603219        1       9  0.176309 -0.032086\n",
       "4       6.214856        1      10  0.177828 -0.066889, topic_info=     Category        Freq        Term       Total  loglift  logprob\n",
       "term                                                               \n",
       "84    Default  342.000000        good  342.000000  30.0000  30.0000\n",
       "245   Default  310.000000        know  310.000000  29.0000  29.0000\n",
       "54    Default  569.000000         one  569.000000  28.0000  28.0000\n",
       "953   Default  203.000000        love  203.000000  27.0000  27.0000\n",
       "152   Default  575.000000         man  575.000000  26.0000  26.0000\n",
       "123   Default  147.000000       woman  147.000000  25.0000  25.0000\n",
       "1903  Default   80.000000         age   80.000000  24.0000  24.0000\n",
       "1253  Default   73.000000        talk   73.000000  23.0000  23.0000\n",
       "301   Default  205.000000       great  205.000000  22.0000  22.0000\n",
       "1166  Default   83.000000        tell   83.000000  21.0000  21.0000\n",
       "506   Default  128.000000         old  128.000000  20.0000  20.0000\n",
       "844   Default  158.000000         get  158.000000  19.0000  19.0000\n",
       "764   Default   88.000000         bad   88.000000  18.0000  18.0000\n",
       "229   Default   98.000000  everything   98.000000  17.0000  17.0000\n",
       "283   Default  182.000000        live  182.000000  16.0000  16.0000\n",
       "290   Default   71.000000       write   71.000000  15.0000  15.0000\n",
       "1294  Default  181.000000      always  181.000000  14.0000  14.0000\n",
       "304   Default  246.000000       never  246.000000  13.0000  13.0000\n",
       "312   Default   55.000000        play   55.000000  12.0000  12.0000\n",
       "559   Default  217.000000       world  217.000000  11.0000  11.0000\n",
       "305   Default   65.000000        read   65.000000  10.0000  10.0000\n",
       "1615  Default   63.000000       heart   63.000000   9.0000   9.0000\n",
       "5435  Default   71.000000   president   71.000000   8.0000   8.0000\n",
       "103   Default  192.000000       would  192.000000   7.0000   7.0000\n",
       "148   Default  150.000000        must  150.000000   6.0000   6.0000\n",
       "1124  Default   74.000000        year   74.000000   5.0000   5.0000\n",
       "447   Default   36.000000      secret   36.000000   4.0000   4.0000\n",
       "28    Default  104.000000       human  104.000000   3.0000   3.0000\n",
       "1031  Default   77.000000         lie   77.000000   2.0000   2.0000\n",
       "1022  Default   53.000000         new   53.000000   1.0000   1.0000\n",
       "...       ...         ...         ...         ...      ...      ...\n",
       "963   Topic10   14.980899  literature   18.440694   2.5704  -5.3570\n",
       "678   Topic10   19.039322       fight   24.661926   2.5195  -5.1173\n",
       "1018  Topic10    8.283147      attain    9.780376   2.6121  -5.9496\n",
       "1435  Topic10   17.613164        save   24.851102   2.4340  -5.1951\n",
       "1688  Topic10   16.991903      future   25.702969   2.3644  -5.2310\n",
       "1884  Topic10   18.058344     present   28.799360   2.3115  -5.1702\n",
       "2177  Topic10   12.474119     neither   17.551734   2.4367  -5.5401\n",
       "3154  Topic10   22.533869     America   45.356042   2.0787  -4.9488\n",
       "301   Topic10   58.944061       great  205.124177   1.5312  -3.9872\n",
       "3597  Topic10   12.202035    sympathy   17.887745   2.3957  -5.5622\n",
       "560   Topic10   17.897294        race   34.725855   2.1154  -5.1791\n",
       "28    Topic10   30.638856       human  104.334456   1.5529  -4.6415\n",
       "86    Topic10   17.663174      modern   39.308216   1.9783  -5.1923\n",
       "3956  Topic10   11.274369       today   17.805849   2.3212  -5.6412\n",
       "1708  Topic10   21.867790      become   67.671501   1.6486  -4.9788\n",
       "890   Topic10   20.430795        fact   59.941482   1.7019  -5.0467\n",
       "57    Topic10   14.160722    language   29.783066   2.0348  -5.4133\n",
       "510   Topic10   12.046548       taste   21.573977   2.1955  -5.5750\n",
       "1169  Topic10   18.463895      action   62.239965   1.5630  -5.1480\n",
       "507   Topic10   15.122718      school   38.947976   1.8322  -5.3476\n",
       "499   Topic10   14.212989     consist   35.552273   1.8614  -5.4096\n",
       "1294  Topic10   23.811224      always  181.056534   0.7496  -4.8936\n",
       "56    Topic10   17.634985        word   88.317516   1.1672  -5.1939\n",
       "252   Topic10   19.457990        life  284.767028   0.0948  -5.0955\n",
       "864   Topic10   18.468607       think  221.193582   0.2953  -5.1477\n",
       "197   Topic10   16.845600         see  136.344933   0.6871  -5.2397\n",
       "33    Topic10   14.144561        high   66.082061   1.2367  -5.4145\n",
       "152   Topic10   16.800966         man  575.469181  -0.7555  -5.2423\n",
       "3571  Topic10   12.589462     require   31.163261   1.8718  -5.5309\n",
       "598   Topic10   12.733976      merely   44.994273   1.5160  -5.5195\n",
       "\n",
       "[688 rows x 6 columns], token_table=      Topic      Freq         Term\n",
       "term                              \n",
       "750       7  0.912812           Ah\n",
       "5231      9  0.959613       Always\n",
       "3154      3  0.132287      America\n",
       "3154      5  0.374812      America\n",
       "3154     10  0.507099      America\n",
       "5236      8  0.920922       Better\n",
       "5053      6  0.962710        Books\n",
       "2718      4  0.981976     Congress\n",
       "6667      4  0.940315   Conscience\n",
       "2627      4  0.915876      England\n",
       "18        6  0.873160       Except\n",
       "2886      4  0.956107   Experience\n",
       "2113      1  0.936041        Faith\n",
       "4650      6  0.925160      Fiction\n",
       "7870      2  0.946488  Fortunately\n",
       "1855      6  0.936224      Fortune\n",
       "1597      1  0.046374          God\n",
       "1597      2  0.185494          God\n",
       "1597      3  0.176220          God\n",
       "1597      5  0.111297          God\n",
       "1597      7  0.027824          God\n",
       "1597      8  0.333890          God\n",
       "1597      9  0.092747          God\n",
       "1597     10  0.027824          God\n",
       "2903      2  0.967641  Imagination\n",
       "5493      3  0.945866        Iraqi\n",
       "1188      8  0.902404    Knowledge\n",
       "3604      3  0.172290          Let\n",
       "3604      4  0.310122          Let\n",
       "3604      6  0.516870          Let\n",
       "...     ...       ...          ...\n",
       "100       5  0.018613         work\n",
       "100       8  0.065144         work\n",
       "100       9  0.232657         work\n",
       "559       1  0.096439        world\n",
       "559       2  0.321462        world\n",
       "559       3  0.289316        world\n",
       "559       5  0.050515        world\n",
       "559       6  0.169916        world\n",
       "559       7  0.013777        world\n",
       "559       8  0.055108        world\n",
       "2056      7  0.829790       worthy\n",
       "103       1  0.176843        would\n",
       "103       3  0.213252        would\n",
       "103       4  0.104026        would\n",
       "103       5  0.161240        would\n",
       "103       6  0.218454        would\n",
       "103       8  0.130032        would\n",
       "290       1  0.890769        write\n",
       "290       2  0.097428        write\n",
       "1124      1  0.320412         year\n",
       "1124      6  0.093454         year\n",
       "1124      7  0.520670         year\n",
       "1124      8  0.053402         year\n",
       "751       7  0.877704          yes\n",
       "680       5  0.193529        young\n",
       "680       6  0.241911        young\n",
       "680       7  0.112892        young\n",
       "680       8  0.354803        young\n",
       "680       9  0.096765        young\n",
       "2834      7  0.957662        youth\n",
       "\n",
       "[1349 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[8, 9, 6, 4, 3, 7, 1, 10, 2, 5])"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(aldamodel, acorpus, adictionary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
